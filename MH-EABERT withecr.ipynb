{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"24169bef7f94448d8459900d30968348":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac02bb83fe284fe8991cfe51646f752f","IPY_MODEL_5b513c49a0d04722a5ea08cc8cfd522d","IPY_MODEL_033267e87dd64d52b99c437736941801"],"layout":"IPY_MODEL_9cf78a1e36e545c092f23e549575c9cc"}},"ac02bb83fe284fe8991cfe51646f752f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_370574e4b6df428bbf07cb518128065c","placeholder":"​","style":"IPY_MODEL_1c328ef3eb1d4f3ca46880c3f2fd8c24","value":"Processing batches: 100%"}},"5b513c49a0d04722a5ea08cc8cfd522d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f44312b2d5eb4ba98425cf4ad89146cc","max":141,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4bd4de57e674ea395d7af39be33c07f","value":141}},"033267e87dd64d52b99c437736941801":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e047296e3a94131a39a80fccc4c0607","placeholder":"​","style":"IPY_MODEL_b5f37662ce194afb9ef168e97c5cecf2","value":" 141/141 [38:05&lt;00:00, 16.74s/it]"}},"9cf78a1e36e545c092f23e549575c9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"370574e4b6df428bbf07cb518128065c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c328ef3eb1d4f3ca46880c3f2fd8c24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f44312b2d5eb4ba98425cf4ad89146cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4bd4de57e674ea395d7af39be33c07f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e047296e3a94131a39a80fccc4c0607":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5f37662ce194afb9ef168e97c5cecf2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b03d5cf2e6cf4fa6ba1a3ac619184067":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f21a1e7af7cb44b599b39e448b27d82c","IPY_MODEL_8418c4793d8245b697817d7896814b13","IPY_MODEL_ba515562ba3543e9a7b1256d17957373"],"layout":"IPY_MODEL_1381dd8498244875b11bdf7114f0567b"}},"f21a1e7af7cb44b599b39e448b27d82c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba442ad20dd74291aa0ebfcf664172f2","placeholder":"​","style":"IPY_MODEL_6bdad9e8faec4ca6b5386861e50060d2","value":"Labeling: 100%"}},"8418c4793d8245b697817d7896814b13":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_de3efb49cf4242a5b36e4d931b876a55","max":140995,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae4f0af74177409bb4e651a2ad7bd732","value":140995}},"ba515562ba3543e9a7b1256d17957373":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_377fe9d6ae904dcc92d1cd635e65536d","placeholder":"​","style":"IPY_MODEL_57af5743a3fd4660a5d56c876026736f","value":" 140995/140995 [00:10&lt;00:00, 12346.87it/s]"}},"1381dd8498244875b11bdf7114f0567b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba442ad20dd74291aa0ebfcf664172f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bdad9e8faec4ca6b5386861e50060d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de3efb49cf4242a5b36e4d931b876a55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae4f0af74177409bb4e651a2ad7bd732":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"377fe9d6ae904dcc92d1cd635e65536d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57af5743a3fd4660a5d56c876026736f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03f611c0756945cc90dd0c6dc96df744":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27ef2974829f49a696d82a2942747353","IPY_MODEL_0934a93f8dd54f73a813be29152a96d5","IPY_MODEL_3d926ae9873045d58a33db95fc63e4f2"],"layout":"IPY_MODEL_7daf2e8148cc4a90951757b2e43108eb"}},"27ef2974829f49a696d82a2942747353":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32c0e5a605e74b12aaee6419400c3e85","placeholder":"​","style":"IPY_MODEL_70582ff016584332bb85677d17d5dbc3","value":"Generating SETs: 100%"}},"0934a93f8dd54f73a813be29152a96d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb5e28faff3641d09f0da757a4ba7d2d","max":138522,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d26209bf0224ce6b019942fe9969dc4","value":138522}},"3d926ae9873045d58a33db95fc63e4f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2936f897e1d448fb12039c98b582a3c","placeholder":"​","style":"IPY_MODEL_9ddba87f1b5448769f4d1d42f9ac4f15","value":" 138522/138522 [00:10&lt;00:00, 14593.10it/s]"}},"7daf2e8148cc4a90951757b2e43108eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32c0e5a605e74b12aaee6419400c3e85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70582ff016584332bb85677d17d5dbc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb5e28faff3641d09f0da757a4ba7d2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d26209bf0224ce6b019942fe9969dc4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2936f897e1d448fb12039c98b582a3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ddba87f1b5448769f4d1d42f9ac4f15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98681a8baf064227bd83fbd9fd6847eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ae95ab5b8c74836a5de0e7af7672d46","IPY_MODEL_38a9799cf0c84359b90f457e7b117d6e","IPY_MODEL_e3057df6386a4a11841badcb92dff2db"],"layout":"IPY_MODEL_3d901313bf624f348c8804689952665b"}},"6ae95ab5b8c74836a5de0e7af7672d46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_143f13ad38364a4eada30e96ec2bc4a4","placeholder":"​","style":"IPY_MODEL_a601060d2106464c90d91a04ec234014","value":"tokenizer_config.json: 100%"}},"38a9799cf0c84359b90f457e7b117d6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bef68cba8960411fa9d550a5bb903927","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb72a587b93a4848b5b195038eeef7f3","value":48}},"e3057df6386a4a11841badcb92dff2db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3ea51cafceb492e96279adc1ce523d6","placeholder":"​","style":"IPY_MODEL_e9d1253243c4424d9257795f2e241257","value":" 48.0/48.0 [00:00&lt;00:00, 1.08kB/s]"}},"3d901313bf624f348c8804689952665b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"143f13ad38364a4eada30e96ec2bc4a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a601060d2106464c90d91a04ec234014":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bef68cba8960411fa9d550a5bb903927":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb72a587b93a4848b5b195038eeef7f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3ea51cafceb492e96279adc1ce523d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9d1253243c4424d9257795f2e241257":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b17c9f6d7d241a0b2fc59a295e4e39c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32d72f6f00e449f1a0889bc77716100a","IPY_MODEL_65c41f31ee484abe8f51a9535a0ae957","IPY_MODEL_f10772ac63f64158884adfc5312f94b4"],"layout":"IPY_MODEL_a7d3d337418f4a539d33a9330cfc9d63"}},"32d72f6f00e449f1a0889bc77716100a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c2fe9317b6b4f8ab2dcec54b2f6a788","placeholder":"​","style":"IPY_MODEL_b092bf84917b44deab4e6ef8fd921a08","value":"vocab.txt: 100%"}},"65c41f31ee484abe8f51a9535a0ae957":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62128d93dd22407eba530de068606cbe","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4f7f989e2b64f1b9761961f386ad1ce","value":231508}},"f10772ac63f64158884adfc5312f94b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d82372019b4e49ce8a851ff0e8645c50","placeholder":"​","style":"IPY_MODEL_a5cda441200c492584fc118d258800d6","value":" 232k/232k [00:00&lt;00:00, 5.13MB/s]"}},"a7d3d337418f4a539d33a9330cfc9d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c2fe9317b6b4f8ab2dcec54b2f6a788":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b092bf84917b44deab4e6ef8fd921a08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62128d93dd22407eba530de068606cbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4f7f989e2b64f1b9761961f386ad1ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d82372019b4e49ce8a851ff0e8645c50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5cda441200c492584fc118d258800d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6eb8686c752442ea8328ddf13d41756":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d72f518b9cdc476b92f66cbc47621f83","IPY_MODEL_17dcea40291a49b8a58f7e02b66d4ae5","IPY_MODEL_67db39a8121340b99c2304f23c7efbc6"],"layout":"IPY_MODEL_38950edb7e1941a0acb6ac677710918a"}},"d72f518b9cdc476b92f66cbc47621f83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb607abad180423c8ae4a8f3b9ec3055","placeholder":"​","style":"IPY_MODEL_2cfb8218f9dd4fbb93af3048e257311c","value":"tokenizer.json: 100%"}},"17dcea40291a49b8a58f7e02b66d4ae5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70c5ee6653ca4fddb9d3b19d937c2285","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2f378852a0e4308864ccb418510d7f4","value":466062}},"67db39a8121340b99c2304f23c7efbc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d708fc032ee4fb0b5636d42f19cc80e","placeholder":"​","style":"IPY_MODEL_e7ac0ffa95cf4b5298387d2baacd961c","value":" 466k/466k [00:00&lt;00:00, 14.7MB/s]"}},"38950edb7e1941a0acb6ac677710918a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb607abad180423c8ae4a8f3b9ec3055":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cfb8218f9dd4fbb93af3048e257311c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70c5ee6653ca4fddb9d3b19d937c2285":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2f378852a0e4308864ccb418510d7f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d708fc032ee4fb0b5636d42f19cc80e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7ac0ffa95cf4b5298387d2baacd961c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40bb3619d6e74753a1ecbab111797912":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3eba78c98a34f60881a092c82f6fd7d","IPY_MODEL_d860a139c9fa453fb654ab63dcffc194","IPY_MODEL_e838ea9c6cb3420789311d81344256eb"],"layout":"IPY_MODEL_28423e6002e14328b59d4f7387bf4fe7"}},"f3eba78c98a34f60881a092c82f6fd7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b42d0f37e1e34c048eddd0a6b1b69546","placeholder":"​","style":"IPY_MODEL_f6ac2dda158f4c1797a8f659e91e4172","value":"config.json: 100%"}},"d860a139c9fa453fb654ab63dcffc194":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88b94d514a4d4b7baae0ef192098c5f7","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1fa3968161e94c5487e253d6a0362b89","value":570}},"e838ea9c6cb3420789311d81344256eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d4e1cd0fa2f410fae9d76275915db42","placeholder":"​","style":"IPY_MODEL_3b29d0c39eb24a9b85d9606b17f94446","value":" 570/570 [00:00&lt;00:00, 29.2kB/s]"}},"28423e6002e14328b59d4f7387bf4fe7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b42d0f37e1e34c048eddd0a6b1b69546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6ac2dda158f4c1797a8f659e91e4172":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88b94d514a4d4b7baae0ef192098c5f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa3968161e94c5487e253d6a0362b89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d4e1cd0fa2f410fae9d76275915db42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b29d0c39eb24a9b85d9606b17f94446":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22190c9104bd43c5b0123b1fece95372":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2575a707822742f8bfd856145129221b","IPY_MODEL_9f6839dc14114b019368a869d3f3419c","IPY_MODEL_9d75f0578c87440188d87a570f477778"],"layout":"IPY_MODEL_6f352c4457d84c2a80c2ad83292f8810"}},"2575a707822742f8bfd856145129221b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6ac6ee937874b61b625bb79df11b762","placeholder":"​","style":"IPY_MODEL_cd999bd424674ef8911817665e443c72","value":"model.safetensors: 100%"}},"9f6839dc14114b019368a869d3f3419c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f37957b04ea44b989843607823e6d2e5","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9face57395e24b28a50f108aaadf3a9c","value":440449768}},"9d75f0578c87440188d87a570f477778":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acb2b7cb46de4fa982491f3c3811fea3","placeholder":"​","style":"IPY_MODEL_9fca8bf82ad54c499e038cfbbf4d1c9c","value":" 440M/440M [00:05&lt;00:00, 180MB/s]"}},"6f352c4457d84c2a80c2ad83292f8810":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6ac6ee937874b61b625bb79df11b762":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd999bd424674ef8911817665e443c72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f37957b04ea44b989843607823e6d2e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9face57395e24b28a50f108aaadf3a9c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"acb2b7cb46de4fa982491f3c3811fea3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fca8bf82ad54c499e038cfbbf4d1c9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5541c328cf04878b9bafd39d9dbdfd8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2fd57140bde64111849fe9242729dcc0","IPY_MODEL_bfcb10e29fde4c75bda1c5ceca7a461e","IPY_MODEL_ccaa49ee52e64be58883f39af027f0ea"],"layout":"IPY_MODEL_cffde37894ee40ad93f99da16b4470ae"}},"2fd57140bde64111849fe9242729dcc0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e17ceedf3f0e40fe9379e05c533491f5","placeholder":"​","style":"IPY_MODEL_e43cccd47fe54bb490a85985d4a5573a","value":"Training: 100%"}},"bfcb10e29fde4c75bda1c5ceca7a461e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_85fb35b6e0724d33b8336f680052d6ff","max":3031,"min":0,"orientation":"horizontal","style":"IPY_MODEL_542edad15cfa42b18eb932a31f84c24d","value":3031}},"ccaa49ee52e64be58883f39af027f0ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44b3bf94d39e4220ab0ed838242b956a","placeholder":"​","style":"IPY_MODEL_a6711ae974084662be01eb098e2a288a","value":" 3031/3031 [32:46&lt;00:00,  2.01it/s, loss=0.4920]"}},"cffde37894ee40ad93f99da16b4470ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e17ceedf3f0e40fe9379e05c533491f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e43cccd47fe54bb490a85985d4a5573a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85fb35b6e0724d33b8336f680052d6ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"542edad15cfa42b18eb932a31f84c24d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44b3bf94d39e4220ab0ed838242b956a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6711ae974084662be01eb098e2a288a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc483bf5cce44dfa88a47ef57d9f9e76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_644263661e90480295e9dfc047be1861","IPY_MODEL_a10f7be014f64edc9bfce9270a62f71f","IPY_MODEL_81ea6e89dfae40af8542ec5e0fb92713"],"layout":"IPY_MODEL_1b6727961702422e878cfdff33e36cd2"}},"644263661e90480295e9dfc047be1861":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0a46a2065db4fa68ca132e124c3347c","placeholder":"​","style":"IPY_MODEL_a2951b9954134a1f9b22aa0be827219d","value":"Evaluating: 100%"}},"a10f7be014f64edc9bfce9270a62f71f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_607f78d01f0d42f88af3b283d2090d67","max":650,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5647e8b8fbe5491f8fdde8f6917f20ab","value":650}},"81ea6e89dfae40af8542ec5e0fb92713":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c54890bb02cc48a1834c40472a61d652","placeholder":"​","style":"IPY_MODEL_bd56e626f11c40ae8897eba5dde1a2a2","value":" 650/650 [02:16&lt;00:00,  4.77it/s]"}},"1b6727961702422e878cfdff33e36cd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0a46a2065db4fa68ca132e124c3347c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2951b9954134a1f9b22aa0be827219d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"607f78d01f0d42f88af3b283d2090d67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5647e8b8fbe5491f8fdde8f6917f20ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c54890bb02cc48a1834c40472a61d652":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd56e626f11c40ae8897eba5dde1a2a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"265ea45ee5cf4776b2f3fa0e7ae74efd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0aca584b45ff4697a318cfbc35857faa","IPY_MODEL_3427ec94327c4a90844a439d94e06dc1","IPY_MODEL_ab4229af019f4db08b5df5c17a83e1ac"],"layout":"IPY_MODEL_4d2af727a3054503814b29f2e88d2871"}},"0aca584b45ff4697a318cfbc35857faa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dac651f79e4f41beb09b0335fa839ee0","placeholder":"​","style":"IPY_MODEL_5aab0f387dc84d3e93daa9d5c73bd04d","value":"Training:   1%"}},"3427ec94327c4a90844a439d94e06dc1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_92690f3c512a43d89ac80686aa2ad8a1","max":3031,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1777b48f1024790a41d3e76816c9699","value":23}},"ab4229af019f4db08b5df5c17a83e1ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37ac065bf9e249b7931f722daf8b53c4","placeholder":"​","style":"IPY_MODEL_2d5a9363e6014defb5e6ce5796006946","value":" 23/3031 [00:15&lt;32:30,  1.54it/s, loss=0.3885]"}},"4d2af727a3054503814b29f2e88d2871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dac651f79e4f41beb09b0335fa839ee0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aab0f387dc84d3e93daa9d5c73bd04d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92690f3c512a43d89ac80686aa2ad8a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1777b48f1024790a41d3e76816c9699":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37ac065bf9e249b7931f722daf8b53c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d5a9363e6014defb5e6ce5796006946":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13673744,"sourceType":"datasetVersion","datasetId":8694441}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport re\n\n# Load all datasets\ndatasets = {\n    'ADHD': pd.read_csv('/kaggle/input/reddit/adhd.csv'),\n    'Aspergers': pd.read_csv('/kaggle/input/reddit/aspergers.csv'),\n    'Depression': pd.read_csv('/kaggle/input/reddit/aspergers.csv'),\n    'OCD': pd.read_csv('/kaggle/input/reddit/ocd.csv'),\n    'PTSD': pd.read_csv('/kaggle/input/reddit/ptsd.csv')\n}\n\n# Explore structure\nprint(\"=\"*80)\nprint(\"DATASET EXPLORATION\")\nprint(\"=\"*80)\n\nfor name, df in datasets.items():\n    print(f\"\\n{'='*80}\")\n    print(f\"Dataset: {name}\")\n    print(f\"{'='*80}\")\n    print(f\"Shape: {df.shape}\")\n    print(f\"Columns: {df.columns.tolist()}\")\n    print(f\"\\nFirst 2 rows:\")\n    print(df.head(2))\n    print(f\"\\nData types:\")\n    print(df.dtypes)\n    print(f\"\\nMissing values:\")\n    print(df.isnull().sum())\n    print(f\"\\nSample text (if available):\")\n    # Try to find text column\n    text_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['text', 'post', 'content', 'body', 'selftext'])]\n    if text_cols:\n        sample_text = df[text_cols[0]].iloc[0] if len(df) > 0 else \"No data\"\n        print(f\"{sample_text[:200]}...\")\n    else:\n        print(\"No obvious text column found\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9b2BgayFPW0","outputId":"db930726-54a5-4aed-c9a8-8e403ecb5938","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T03:57:45.563100Z","iopub.execute_input":"2025-11-10T03:57:45.563514Z","iopub.status.idle":"2025-11-10T03:57:54.251278Z","shell.execute_reply.started":"2025-11-10T03:57:45.563494Z","shell.execute_reply":"2025-11-10T03:57:54.250600Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nDATASET EXPLORATION\n================================================================================\n\n================================================================================\nDataset: ADHD\n================================================================================\nShape: (37109, 10)\nColumns: ['author', 'body', 'created_utc', 'id', 'num_comments', 'score', 'subreddit', 'title', 'upvote_ratio', 'url']\n\nFirst 2 rows:\n                author                                               body  \\\n0  HotConversation1273  A few months ago I was accepted into this full...   \n1           snorefestt  Hey guys, I was curious if anyone else has the...   \n\n                created_utc      id  num_comments  score subreddit  \\\n0  2021-12-22T18:32:56.000Z  rmbjwb             1      1      ADHD   \n1  2021-12-22T18:24:25.000Z  rmbd1y             3      5      ADHD   \n\n                                               title  upvote_ratio  \\\n0    I get extremely anxious if I’m not working 24/7           1.0   \n1  I can't will myself to clean my own house, but...           1.0   \n\n                                                 url  \n0  https://www.reddit.com/r/ADHD/comments/rmbjwb/...  \n1  https://www.reddit.com/r/ADHD/comments/rmbd1y/...  \n\nData types:\nauthor           object\nbody             object\ncreated_utc      object\nid               object\nnum_comments      int64\nscore             int64\nsubreddit        object\ntitle            object\nupvote_ratio    float64\nurl              object\ndtype: object\n\nMissing values:\nauthor          0\nbody            0\ncreated_utc     0\nid              0\nnum_comments    0\nscore           0\nsubreddit       0\ntitle           0\nupvote_ratio    0\nurl             0\ndtype: int64\n\nSample text (if available):\nA few months ago I was accepted into this full time software engineering fellowship and it’s made me realize that I CANNOT work sustainably to save my life. It’s so hard to prioritize my time when I g...\n\n================================================================================\nDataset: Aspergers\n================================================================================\nShape: (23294, 10)\nColumns: ['author', 'body', 'created_utc', 'id', 'num_comments', 'score', 'subreddit', 'title', 'upvote_ratio', 'url']\n\nFirst 2 rows:\n              author                                               body  \\\n0             Adadum  I wish I could do a poll for this but what wou...   \n1  Lazy_Opposite8263  I was diagnosed with high functioning asperger...   \n\n                created_utc      id  num_comments  score  subreddit  \\\n0  2021-12-23T17:56:36.000Z  rn19yc             0      1  aspergers   \n1  2021-12-23T17:53:41.000Z  rn17lw             1      1  aspergers   \n\n                                               title  upvote_ratio  \\\n0           Separatism for high-functioning Autists?           1.0   \n1  Friend blaming toxic behaviour on autism? How ...           1.0   \n\n                                                 url  \n0  https://www.reddit.com/r/aspergers/comments/rn...  \n1  https://www.reddit.com/r/aspergers/comments/rn...  \n\nData types:\nauthor           object\nbody             object\ncreated_utc      object\nid               object\nnum_comments      int64\nscore             int64\nsubreddit        object\ntitle            object\nupvote_ratio    float64\nurl              object\ndtype: object\n\nMissing values:\nauthor            0\nbody            686\ncreated_utc       0\nid                0\nnum_comments      0\nscore             0\nsubreddit         0\ntitle             0\nupvote_ratio      0\nurl               0\ndtype: int64\n\nSample text (if available):\nI wish I could do a poll for this but what would you all think of having an autonomous territory just for us where we could be ourselves?\n\nThe autonomous territory would entail our own government, eco...\n\n================================================================================\nDataset: Depression\n================================================================================\nShape: (23294, 10)\nColumns: ['author', 'body', 'created_utc', 'id', 'num_comments', 'score', 'subreddit', 'title', 'upvote_ratio', 'url']\n\nFirst 2 rows:\n              author                                               body  \\\n0             Adadum  I wish I could do a poll for this but what wou...   \n1  Lazy_Opposite8263  I was diagnosed with high functioning asperger...   \n\n                created_utc      id  num_comments  score  subreddit  \\\n0  2021-12-23T17:56:36.000Z  rn19yc             0      1  aspergers   \n1  2021-12-23T17:53:41.000Z  rn17lw             1      1  aspergers   \n\n                                               title  upvote_ratio  \\\n0           Separatism for high-functioning Autists?           1.0   \n1  Friend blaming toxic behaviour on autism? How ...           1.0   \n\n                                                 url  \n0  https://www.reddit.com/r/aspergers/comments/rn...  \n1  https://www.reddit.com/r/aspergers/comments/rn...  \n\nData types:\nauthor           object\nbody             object\ncreated_utc      object\nid               object\nnum_comments      int64\nscore             int64\nsubreddit        object\ntitle            object\nupvote_ratio    float64\nurl              object\ndtype: object\n\nMissing values:\nauthor            0\nbody            686\ncreated_utc       0\nid                0\nnum_comments      0\nscore             0\nsubreddit         0\ntitle             0\nupvote_ratio      0\nurl               0\ndtype: int64\n\nSample text (if available):\nI wish I could do a poll for this but what would you all think of having an autonomous territory just for us where we could be ourselves?\n\nThe autonomous territory would entail our own government, eco...\n\n================================================================================\nDataset: OCD\n================================================================================\nShape: (42826, 10)\nColumns: ['author', 'body', 'created_utc', 'id', 'num_comments', 'score', 'subreddit', 'title', 'upvote_ratio', 'url']\n\nFirst 2 rows:\n              author                                               body  \\\n0  christmascamearly  So I know the title/ post sounds gross, but I ...   \n1      Yupitisme1995  Sorry, I've asked before, but I'm in a dark da...   \n\n                created_utc      id  num_comments  score subreddit  \\\n0  2021-12-22T18:26:02.000Z  rmbecy             1      1       OCD   \n1  2021-12-22T18:08:52.000Z  rmb0ql             2      1       OCD   \n\n                                           title  upvote_ratio  \\\n0          OCD with Bathroom use/ Do I have OCD?           1.0   \n1  Is there anyone I can talk to? I'm desperate.           1.0   \n\n                                                 url  \n0  https://www.reddit.com/r/OCD/comments/rmbecy/o...  \n1  https://www.reddit.com/r/OCD/comments/rmb0ql/i...  \n\nData types:\nauthor           object\nbody             object\ncreated_utc      object\nid               object\nnum_comments      int64\nscore             int64\nsubreddit        object\ntitle            object\nupvote_ratio    float64\nurl              object\ndtype: object\n\nMissing values:\nauthor            0\nbody            743\ncreated_utc       0\nid                0\nnum_comments      0\nscore             0\nsubreddit         0\ntitle             0\nupvote_ratio      0\nurl               0\ndtype: int64\n\nSample text (if available):\nSo I know the title/ post sounds gross, but I have no idea who to talk to about it in person since it's kind of embarrassing. When I pee, it ends up taking me \\~5 minutes or so since I'll wipe a lot a...\n\n================================================================================\nDataset: PTSD\n================================================================================\nShape: (24028, 10)\nColumns: ['author', 'body', 'created_utc', 'id', 'num_comments', 'score', 'subreddit', 'title', 'upvote_ratio', 'url']\n\nFirst 2 rows:\n                 author                                               body  \\\n0  ChanceIntroduction95  This year felt like literal hell. It’s over no...   \n1    VeryMentallyStable  Can feel my skin tightening up as I type this ...   \n\n                created_utc      id  num_comments  score subreddit  \\\n0  2021-12-23T17:08:28.000Z  rn07cg             3      5      ptsd   \n1  2021-12-23T16:10:39.000Z  rmyxx1             2      3      ptsd   \n\n                                               title  upvote_ratio  \\\n0  How to deal with feeling shameful about how my...           1.0   \n1  I’ve never felt more touch starved, and yet I ...           1.0   \n\n                                                 url  \n0  https://www.reddit.com/r/ptsd/comments/rn07cg/...  \n1  https://www.reddit.com/r/ptsd/comments/rmyxx1/...  \n\nData types:\nauthor           object\nbody             object\ncreated_utc      object\nid               object\nnum_comments      int64\nscore             int64\nsubreddit        object\ntitle            object\nupvote_ratio    float64\nurl              object\ndtype: object\n\nMissing values:\nauthor            0\nbody            180\ncreated_utc       0\nid                0\nnum_comments      0\nscore             0\nsubreddit         0\ntitle             0\nupvote_ratio      0\nurl               0\ndtype: int64\n\nSample text (if available):\nThis year felt like literal hell. It’s over now and I’m happy it is but I’m so embarrassed about how I acted. I was living in a bug infested apartment sleeping on the floor, I couldn’t wash my hair or...\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport re\n\n# ============================================================================\n# STEP 2: STANDARDIZE AND CLEAN DATASETS\n# ============================================================================\n\ndef standardize_dataset(df, condition_name):\n    \"\"\"\n    Standardize dataset to common format\n    Combines 'title' and 'body' into single text field\n    \"\"\"\n    standardized_df = pd.DataFrame()\n\n    # Combine title and body for richer context\n    # Many Reddit posts have important info in both title and body\n    standardized_df['title'] = df['title'].fillna('')\n    standardized_df['body'] = df['body'].fillna('')\n\n    # Combine: \"Title. Body\"\n    standardized_df['text'] = (\n        standardized_df['title'].astype(str) + '. ' +\n        standardized_df['body'].astype(str)\n    )\n\n    # Add condition label\n    standardized_df['condition'] = condition_name\n\n    # Add metadata\n    standardized_df['score'] = df['score']\n    standardized_df['num_comments'] = df['num_comments']\n    standardized_df['created_utc'] = df['created_utc']\n    standardized_df['subreddit'] = df['subreddit']\n    standardized_df['author'] = df['author']\n\n    return standardized_df\n\n# Standardize all datasets\nprint(\"=\"*80)\nprint(\"STANDARDIZING DATASETS\")\nprint(\"=\"*80)\n\nstandardized_datasets = {}\nfor name, df in datasets.items():\n    print(f\"\\nProcessing {name}...\")\n    standardized_datasets[name] = standardize_dataset(df, name)\n    print(f\"  ✅ {name}: {len(standardized_datasets[name])} posts\")\n\n# Combine into single dataset\ncombined_df = pd.concat(standardized_datasets.values(), ignore_index=True)\n\nprint(f\"\\n{'='*80}\")\nprint(f\"COMBINED DATASET\")\nprint(f\"{'='*80}\")\nprint(f\"Total posts: {len(combined_df)}\")\nprint(f\"\\nCondition distribution:\")\nprint(combined_df['condition'].value_counts())\n\n# Check for empty or very short texts\ncombined_df['text_length'] = combined_df['text'].str.len()\n\nprint(f\"\\nText length statistics:\")\nprint(combined_df['text_length'].describe())\n\n# Filter out very short texts (less than 10 characters)\nprint(f\"\\nPosts with text length < 10: {(combined_df['text_length'] < 10).sum()}\")\n\n# Show sample from each condition\nprint(f\"\\n{'='*80}\")\nprint(\"SAMPLE POSTS FROM EACH CONDITION\")\nprint(f\"{'='*80}\")\n\nfor condition in combined_df['condition'].unique():\n    print(f\"\\n{condition}:\")\n    print(\"-\" * 80)\n    sample = combined_df[combined_df['condition'] == condition].iloc[0]\n    print(f\"Text: {sample['text'][:300]}...\")\n    print(f\"Length: {sample['text_length']} characters\")\n\nprint(f\"\\n✅ Step 2 complete!\")\nprint(f\"\\nCombined dataset shape: {combined_df.shape}\")\nprint(f\"Columns: {combined_df.columns.tolist()}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Admk-SBh8IJF","outputId":"e13dc5e4-34b1-4937-abb9-4fecf79b0729","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T03:58:01.586265Z","iopub.execute_input":"2025-11-10T03:58:01.587025Z","iopub.status.idle":"2025-11-10T03:58:02.140959Z","shell.execute_reply.started":"2025-11-10T03:58:01.586991Z","shell.execute_reply":"2025-11-10T03:58:02.140057Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTANDARDIZING DATASETS\n================================================================================\n\nProcessing ADHD...\n  ✅ ADHD: 37109 posts\n\nProcessing Aspergers...\n  ✅ Aspergers: 23294 posts\n\nProcessing Depression...\n  ✅ Depression: 23294 posts\n\nProcessing OCD...\n  ✅ OCD: 42826 posts\n\nProcessing PTSD...\n  ✅ PTSD: 24028 posts\n\n================================================================================\nCOMBINED DATASET\n================================================================================\nTotal posts: 150551\n\nCondition distribution:\ncondition\nOCD           42826\nADHD          37109\nPTSD          24028\nDepression    23294\nAspergers     23294\nName: count, dtype: int64\n\nText length statistics:\ncount    150551.000000\nmean        609.893285\nstd         986.734149\nmin           9.000000\n25%          60.000000\n50%         280.000000\n75%         806.000000\nmax       40126.000000\nName: text_length, dtype: float64\n\nPosts with text length < 10: 1\n\n================================================================================\nSAMPLE POSTS FROM EACH CONDITION\n================================================================================\n\nADHD:\n--------------------------------------------------------------------------------\nText: I get extremely anxious if I’m not working 24/7. A few months ago I was accepted into this full time software engineering fellowship and it’s made me realize that I CANNOT work sustainably to save my life. It’s so hard to prioritize my time when I get so hyper focused on each task or just on somethi...\nLength: 937 characters\n\nAspergers:\n--------------------------------------------------------------------------------\nText: Separatism for high-functioning Autists?. I wish I could do a poll for this but what would you all think of having an autonomous territory just for us where we could be ourselves?\n\nThe autonomous territory would entail our own government, economy, educational system, etc....\nLength: 272 characters\n\nDepression:\n--------------------------------------------------------------------------------\nText: Separatism for high-functioning Autists?. I wish I could do a poll for this but what would you all think of having an autonomous territory just for us where we could be ourselves?\n\nThe autonomous territory would entail our own government, economy, educational system, etc....\nLength: 272 characters\n\nOCD:\n--------------------------------------------------------------------------------\nText: OCD with Bathroom use/ Do I have OCD?. So I know the title/ post sounds gross, but I have no idea who to talk to about it in person since it's kind of embarrassing. When I pee, it ends up taking me \\~5 minutes or so since I'll wipe a lot and make sure everything is clean, whereas I know it takes oth...\nLength: 1293 characters\n\nPTSD:\n--------------------------------------------------------------------------------\nText: How to deal with feeling shameful about how my trauma made me act. This year felt like literal hell. It’s over now and I’m happy it is but I’m so embarrassed about how I acted. I was living in a bug infested apartment sleeping on the floor, I couldn’t wash my hair or clothes for an embarrassing amou...\nLength: 1188 characters\n\n✅ Step 2 complete!\n\nCombined dataset shape: (150551, 10)\nColumns: ['title', 'body', 'text', 'condition', 'score', 'num_comments', 'created_utc', 'subreddit', 'author', 'text_length']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import re\nimport nltk\n\n# Download NLTK data (run once)\ntry:\n    nltk.download('punkt', quiet=True)\n    nltk.download('stopwords', quiet=True)\n    nltk.download('wordnet', quiet=True)\n    print(\"✅ NLTK data ready\")\nexcept:\n    print(\"⚠️ NLTK download failed, continuing anyway...\")\n\n# ============================================================================\n# STEP 3: TEXT PREPROCESSING\n# ============================================================================\n\nclass TextPreprocessor:\n    def __init__(self):\n        # Don't remove important negation/emotion words\n        try:\n            from nltk.corpus import stopwords\n            self.stop_words = set(stopwords.words('english'))\n            # Keep emotion-relevant words\n            self.stop_words -= {\n                'not', 'no', 'never', 'nothing', 'nobody', 'none',\n                'neither', 'nor', 'can', 'cannot', 'couldn', 'shouldn',\n                'don', 'won', 'wouldn', 'very', 'too', 'really', 'so',\n                'just', 'but', 'however', 'although'\n            }\n        except:\n            self.stop_words = set()\n\n    def clean_text(self, text):\n        \"\"\"Clean Reddit-specific text\"\"\"\n        if pd.isna(text) or text == '':\n            return \"\"\n\n        text = str(text)\n\n        # Remove URLs\n        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n\n        # Remove Reddit-specific markers\n        text = re.sub(r'\\[deleted\\]|\\[removed\\]', '', text)\n\n        # Remove user mentions and subreddit links\n        text = re.sub(r'u/\\w+|r/\\w+', '', text)\n\n        # Remove markdown formatting\n        text = re.sub(r'\\*\\*|\\*|__|_|~~', '', text)\n\n        # Remove excessive punctuation (keep some for emotion)\n        text = re.sub(r'[!]{3,}', '!!', text)\n        text = re.sub(r'[?]{3,}', '??', text)\n        text = re.sub(r'[.]{3,}', '...', text)\n\n        # Remove newlines and tabs\n        text = re.sub(r'\\n|\\t|\\r', ' ', text)\n\n        # Remove excessive whitespace\n        text = re.sub(r'\\s+', ' ', text).strip()\n\n        # Remove non-ASCII characters (keep basic punctuation)\n        text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n\n        return text\n\n# Initialize preprocessor\npreprocessor = TextPreprocessor()\n\nprint(\"=\"*80)\nprint(\"TEXT PREPROCESSING\")\nprint(\"=\"*80)\n\n# Apply cleaning\nprint(\"\\nCleaning text data...\")\ncombined_df['text_clean'] = combined_df['text'].apply(preprocessor.clean_text)\n\n# Calculate new lengths\ncombined_df['text_clean_length'] = combined_df['text_clean'].str.len()\n\nprint(\"✅ Text cleaning complete!\")\n\n# Filter out very short posts (< 20 chars after cleaning)\nprint(f\"\\nPosts before filtering: {len(combined_df)}\")\ncombined_df = combined_df[combined_df['text_clean_length'] >= 20].copy()\nprint(f\"Posts after filtering (>= 20 chars): {len(combined_df)}\")\n\n# Filter out extremely long posts (> 5000 chars to avoid memory issues)\nlong_posts = (combined_df['text_clean_length'] > 5000).sum()\nprint(f\"Posts > 5000 characters: {long_posts}\")\ncombined_df = combined_df[combined_df['text_clean_length'] <= 5000].copy()\nprint(f\"Posts after filtering (<= 5000 chars): {len(combined_df)}\")\n\n# Reset index\ncombined_df = combined_df.reset_index(drop=True)\n\n# Statistics\nprint(f\"\\n{'='*80}\")\nprint(\"CLEANED DATA STATISTICS\")\nprint(f\"{'='*80}\")\nprint(f\"Total posts: {len(combined_df)}\")\nprint(f\"\\nCondition distribution:\")\nprint(combined_df['condition'].value_counts())\n\nprint(f\"\\nText length statistics (after cleaning):\")\nprint(combined_df['text_clean_length'].describe())\n\n# Compare before/after cleaning\nprint(f\"\\n{'='*80}\")\nprint(\"BEFORE vs AFTER CLEANING - SAMPLES\")\nprint(f\"{'='*80}\")\n\nfor i in range(3):\n    sample = combined_df.sample(1).iloc[0]\n    print(f\"\\nSample {i+1} ({sample['condition']}):\")\n    print(\"-\" * 80)\n    print(\"BEFORE:\")\n    print(sample['text'][:300] + \"...\")\n    print(\"\\nAFTER:\")\n    print(sample['text_clean'][:300] + \"...\")\n    print(f\"Length: {sample['text_length']} → {sample['text_clean_length']}\")\n\nprint(f\"\\n✅ Step 3 complete!\")\nprint(f\"\\nFinal dataset: {combined_df.shape}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9OrBqz_I8mEp","outputId":"b5b89233-950b-4d98-947d-f265985a04f1","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T03:58:10.453398Z","iopub.execute_input":"2025-11-10T03:58:10.453713Z","iopub.status.idle":"2025-11-10T03:58:27.257321Z","shell.execute_reply.started":"2025-11-10T03:58:10.453689Z","shell.execute_reply":"2025-11-10T03:58:27.256658Z"}},"outputs":[{"name":"stdout","text":"✅ NLTK data ready\n================================================================================\nTEXT PREPROCESSING\n================================================================================\n\nCleaning text data...\n✅ Text cleaning complete!\n\nPosts before filtering: 150551\nPosts after filtering (>= 20 chars): 142265\nPosts > 5000 characters: 1011\nPosts after filtering (<= 5000 chars): 141254\n\n================================================================================\nCLEANED DATA STATISTICS\n================================================================================\nTotal posts: 141254\n\nCondition distribution:\ncondition\nOCD           39643\nADHD          35325\nPTSD          22170\nDepression    22058\nAspergers     22058\nName: count, dtype: int64\n\nText length statistics (after cleaning):\ncount    141254.000000\nmean        582.671585\nstd         736.938808\nmin          20.000000\n25%          58.000000\n50%         328.000000\n75%         823.000000\nmax        5000.000000\nName: text_clean_length, dtype: float64\n\n================================================================================\nBEFORE vs AFTER CLEANING - SAMPLES\n================================================================================\n\nSample 1 (OCD):\n--------------------------------------------------------------------------------\nBEFORE:\nHas anyone every experienced this?. I was diagnosed at a very young age, and last night was possibly one of the most intense relapses I’ve ever had. I couldn’t go to sleep and the rate in which I was getting thoughts was so so so fast, like I couldn’t even comprehend the thought before something els...\n\nAFTER:\nHas anyone every experienced this?. I was diagnosed at a very young age, and last night was possibly one of the most intense relapses Ive ever had. I couldnt go to sleep and the rate in which I was getting thoughts was so so so fast, like I couldnt even comprehend the thought before something else t...\nLength: 724 → 720\n\nSample 2 (Aspergers):\n--------------------------------------------------------------------------------\nBEFORE:\nQuestion about my intelligence.. [removed]...\n\nAFTER:\nQuestion about my intelligence.....\nLength: 42 → 32\n\nSample 3 (OCD):\n--------------------------------------------------------------------------------\nBEFORE:\nI have pocd and im scared I will never be able to have children. [deleted]...\n\nAFTER:\nI have pocd and im scared I will never be able to have children....\nLength: 74 → 64\n\n✅ Step 3 complete!\n\nFinal dataset: (141254, 12)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================================\n# STEP 4: CREATE MENTAL HEALTH EMOTION DIMENSION DICTIONARY (EDD)\n# ============================================================================\n\nclass MentalHealthEDD:\n    \"\"\"\n    Mental Health Emotion Dimension Dictionary\n    Based on OCC model with 6 dimensions adapted for mental health\n    \"\"\"\n\n    def __init__(self):\n        self.emotion_dimensions = self._build_dimensions()\n        self.intensity_modifiers = self._build_intensity_modifiers()\n\n    def _build_dimensions(self):\n        \"\"\"Build 6 emotion dimensions with condition-specific terms\"\"\"\n\n        dimensions = {\n            'Desirable': {\n                # General positive mental health\n                'general': [\n                    'better', 'improving', 'progress', 'recovery', 'healing',\n                    'hopeful', 'hope', 'motivated', 'energy', 'strength',\n                    'coping', 'managing', 'handling', 'dealing', 'surviving',\n                    'breakthrough', 'milestone', 'achievement', 'proud',\n                    'peaceful', 'calm', 'relaxed', 'content', 'stable',\n                    'grateful', 'thankful', 'blessed', 'lucky', 'fortunate',\n                    'good day', 'better day', 'felt good', 'slept well',\n                    'clear headed', 'focused', 'productive', 'accomplished'\n                ],\n\n                # Treatment success\n                'treatment': [\n                    'therapy helps', 'therapy working', 'medication working',\n                    'treatment helping', 'meds helping', 'feeling better',\n                    'side effects manageable', 'right dosage', 'finding balance',\n                    'therapist understands', 'good session', 'opened up'\n                ],\n\n                # ADHD-specific positive\n                'adhd_positive': [\n                    'hyperfocus', 'found strategy', 'remembered', 'organized',\n                    'on time', 'finished task', 'stayed focused', 'productivity',\n                    'stimulant working', 'less scattered', 'routine helping'\n                ],\n\n                # Depression-specific positive\n                'depression_positive': [\n                    'got out of bed', 'showered', 'ate meal', 'left house',\n                    'socialized', 'enjoyed something', 'laughed', 'smiled',\n                    'less numb', 'feeling again', 'wanted to live'\n                ],\n\n                # OCD-specific positive\n                'ocd_positive': [\n                    'resisted compulsion', 'exposure went well', 'anxiety decreased',\n                    'less intrusive thoughts', 'erp working', 'broke ritual',\n                    'challenged thought', 'uncertainty tolerance'\n                ],\n\n                # PTSD-specific positive\n                'ptsd_positive': [\n                    'no nightmares', 'no flashback', 'felt safe', 'grounded',\n                    'emdr helping', 'processing trauma', 'less triggered',\n                    'hypervigilance down', 'sleeping better'\n                ],\n\n                # Aspergers/ASD positive\n                'asd_positive': [\n                    'special interest', 'comfortable', 'understood', 'accepted',\n                    'clear communication', 'sensory friendly', 'routine maintained',\n                    'social success', 'masking less', 'authentic'\n                ]\n            },\n\n            'Undesirable': {\n                # General distress\n                'general': [\n                    'suffering', 'pain', 'hurt', 'struggling', 'difficult',\n                    'hard', 'tough', 'unbearable', 'overwhelming', 'exhausted',\n                    'tired', 'drained', 'burnt out', 'breaking', 'falling apart',\n                    'losing it', 'scared', 'terrified', 'afraid',\n                    'worried', 'anxious', 'nervous', 'panic', 'stress',\n                    'crying', 'tears', 'sobbing', 'breakdown', 'episode'\n                ],\n\n                # Crisis indicators\n                'crisis': [\n                    'suicidal', 'kill myself', 'end it', 'die', 'death',\n                    'not worth living', 'better off dead', 'giving up',\n                    'no point', 'hopeless', 'helpless',\n                    'self harm', 'cutting', 'hurting myself', 'crisis',\n                    'emergency', 'hospital', 'psychiatric ward', 'hotline',\n                    'cant go on', 'want to die'\n                ],\n\n                # ADHD symptoms\n                'adhd_symptoms': [\n                    'cant focus', 'distracted', 'scattered', 'forgetful',\n                    'forgot again', 'lost track', 'missed deadline', 'late',\n                    'overwhelmed', 'too much', 'executive dysfunction',\n                    'time blindness', 'procrastinating', 'avoidance',\n                    'rejection sensitivity', 'emotional dysregulation',\n                    'impulsive', 'restless', 'racing thoughts'\n                ],\n\n                # Depression symptoms\n                'depression_symptoms': [\n                    'empty', 'numb', 'hollow', 'void', 'nothing', 'pointless',\n                    'worthless', 'useless', 'failure', 'burden', 'waste',\n                    'cant get up', 'bed all day', 'no energy', 'no motivation',\n                    'dont care', 'anhedonia', 'no pleasure', 'no joy',\n                    'isolating', 'alone', 'lonely', 'withdrawn', 'hiding',\n                    'ruminating', 'negative thoughts', 'self hate', 'guilt',\n                    'appetite loss', 'not eating', 'insomnia', 'oversleeping'\n                ],\n\n                # OCD symptoms\n                'ocd_symptoms': [\n                    'intrusive thoughts', 'obsessive', 'compulsion', 'ritual',\n                    'checking', 'washing', 'counting', 'repeating',\n                    'contamination', 'fear of harm', 'magical thinking',\n                    'pure o', 'mental compulsion', 'reassurance seeking',\n                    'cant stop', 'stuck', 'rumination', 'doubt', 'uncertainty',\n                    'need certainty', 'spiral', 'loop', 'torture'\n                ],\n\n                # PTSD symptoms\n                'ptsd_symptoms': [\n                    'flashback', 'nightmare', 'triggered', 'trigger',\n                    'hypervigilant', 'on edge', 'startle', 'jumpy',\n                    'dissociate', 'dissociation', 'detached',\n                    'avoidance', 'avoiding', 'memory gaps',\n                    'panic attack', 'reliving', 'intrusive memory',\n                    'traumatic', 'trauma', 'abuse', 'assault', 'violence'\n                ],\n\n                # Aspergers/ASD struggles\n                'asd_symptoms': [\n                    'sensory overload', 'too loud', 'too bright', 'overstimulated',\n                    'meltdown', 'shutdown', 'masking', 'exhausted from masking',\n                    'dont understand', 'confused', 'social anxiety',\n                    'misunderstood', 'different', 'weird', 'outcast',\n                    'routine broken', 'change', 'unexpected', 'uncertainty',\n                    'eye contact uncomfortable', 'small talk', 'social cues'\n                ]\n            },\n\n            'Praiseworthy': {\n                # Healthcare providers\n                'providers': [\n                    'therapist', 'psychiatrist', 'psychologist', 'counselor',\n                    'doctor', 'nurse', 'social worker', 'case manager',\n                    'my therapist', 'my doctor', 'my psych',\n                    'helpful', 'supportive', 'understanding', 'caring',\n                    'listened', 'validated', 'believed me', 'took seriously',\n                    'good therapist', 'amazing therapist', 'saved me'\n                ],\n\n                # Support system\n                'support': [\n                    'friend', 'friends', 'family', 'mom', 'dad', 'parent',\n                    'partner', 'spouse', 'girlfriend', 'boyfriend',\n                    'support group', 'community', 'reddit', 'this sub',\n                    'someone', 'people', 'everyone here', 'you all',\n                    'helped me', 'there for me', 'supported', 'encouraged',\n                    'understood', 'accepted', 'didnt judge', 'loved'\n                ],\n\n                # Self-compassion\n                'self': [\n                    'proud of myself', 'did my best', 'trying', 'effort',\n                    'kind to myself', 'self care', 'boundary', 'advocate',\n                    'deserve', 'worth', 'valid', 'enough'\n                ]\n            },\n\n            'Blameworthy': {\n                # Self-blame\n                'self_blame': [\n                    'my fault', 'im stupid', 'im dumb', 'im weak',\n                    'im pathetic', 'im useless', 'im worthless',\n                    'im a failure', 'im a burden', 'im broken',\n                    'i should', 'i shouldnt', 'why cant i', 'everyone else can',\n                    'wrong with me', 'defective', 'damaged'\n                ],\n\n                # Blame others\n                'blame_others': [\n                    'their fault', 'they caused', 'they dont care',\n                    'dont understand', 'dismissed', 'ignored', 'minimized',\n                    'invalidated', 'judged', 'blamed', 'shamed', 'stigma',\n                    'discriminated', 'mistreated', 'abused', 'toxic',\n                    'gaslighted', 'manipulated', 'traumatized me'\n                ],\n\n                # System failures\n                'system': [\n                    'insurance denied', 'cant afford', 'too expensive',\n                    'no insurance', 'waitlist', 'months wait', 'no availability',\n                    'no help', 'nowhere to go', 'system failed',\n                    'medication shortage', 'cant get meds', 'denied treatment'\n                ]\n            },\n\n            'Confirmed': {\n                # Diagnosis/validation\n                'diagnosis': [\n                    'diagnosed', 'diagnosis', 'confirmed', 'doctor said',\n                    'test showed', 'evaluation', 'assessment results',\n                    'officially', 'on paper', 'medical record'\n                ],\n\n                # Fear realization\n                'realization': [\n                    'as expected', 'knew it', 'i was right', 'getting worse',\n                    'deteriorating', 'declining', 'relapse', 'relapsed',\n                    'back to square one', 'happening again', 'pattern',\n                    'predictable', 'inevitable'\n                ]\n            },\n\n            'Disconfirmed': {\n                # False alarms\n                'false_alarm': [\n                    'wasnt as bad', 'better than expected', 'overreacted',\n                    'false alarm', 'unnecessary worry', 'made it through',\n                    'survived', 'didnt happen', 'didnt die', 'safe now'\n                ],\n\n                # Unexpected positive\n                'unexpected': [\n                    'surprisingly good', 'unexpected relief', 'turned out ok',\n                    'not as scary', 'manageable', 'handled it', 'got through',\n                    'no relapse', 'stable', 'maintaining', 'still here'\n                ]\n            }\n        }\n\n        return dimensions\n\n    def _build_intensity_modifiers(self):\n        \"\"\"Build intensity modifiers\"\"\"\n        return {\n            'amplifiers': {\n                'extreme': ['extremely', 'severely', 'unbearably', 'impossibly', 'absolutely'],\n                'high': ['very', 'really', 'so', 'incredibly', 'totally', 'completely'],\n                'medium': ['pretty', 'quite', 'fairly', 'rather', 'somewhat']\n            },\n            'dampeners': ['a bit', 'a little', 'slightly', 'somewhat', 'kind of', 'sort of'],\n            'negators': ['not', 'no', 'never', 'neither', 'nowhere', 'nobody', 'nothing', 'without']\n        }\n\n    def get_all_words(self, dimension):\n        \"\"\"Get all words for a dimension\"\"\"\n        if dimension not in self.emotion_dimensions:\n            return set()\n\n        all_words = set()\n        for category, words in self.emotion_dimensions[dimension].items():\n            all_words.update(words)\n        return all_words\n\n    def get_intensity(self, word, context, dimension):\n        \"\"\"Calculate intensity score (0-5)\"\"\"\n        base_intensity = 1.0\n\n        # Crisis keywords get maximum intensity\n        if dimension == 'Undesirable':\n            crisis_words = self.emotion_dimensions['Undesirable']['crisis']\n            if any(crisis in context.lower() for crisis in crisis_words):\n                return 5.0\n\n        # Check for amplifiers\n        context_lower = context.lower()\n        for level, amplifiers in self.intensity_modifiers['amplifiers'].items():\n            if any(amp in context_lower for amp in amplifiers):\n                if level == 'extreme':\n                    base_intensity *= 2.0\n                elif level == 'high':\n                    base_intensity *= 1.5\n                elif level == 'medium':\n                    base_intensity *= 1.2\n\n        # Check for dampeners\n        if any(damp in context_lower for damp in self.intensity_modifiers['dampeners']):\n            base_intensity *= 0.5\n\n        # Check for negation (simple)\n        words = context_lower.split()\n        try:\n            word_idx = words.index(word.lower())\n            preceding_words = words[max(0, word_idx-3):word_idx]\n            if any(neg in preceding_words for neg in self.intensity_modifiers['negators']):\n                return 0.0  # Negated\n        except ValueError:\n            pass\n\n        return min(base_intensity, 5.0)\n\n    def get_statistics(self):\n        \"\"\"Print EDD statistics\"\"\"\n        print(\"\\n\" + \"=\"*80)\n        print(\"EMOTION DIMENSION DICTIONARY STATISTICS\")\n        print(\"=\"*80)\n\n        for dimension in self.emotion_dimensions:\n            all_words = self.get_all_words(dimension)\n            print(f\"\\n{dimension}: {len(all_words)} total words\")\n            for category, words in self.emotion_dimensions[dimension].items():\n                print(f\"  - {category}: {len(words)} words\")\n\n# Create EDD\nprint(\"=\"*80)\nprint(\"CREATING MENTAL HEALTH EMOTION DIMENSION DICTIONARY\")\nprint(\"=\"*80)\n\nEDD = MentalHealthEDD()\nEDD.get_statistics()\n\nprint(\"\\n✅ Step 4 complete!\")\nprint(\"\\nEDD created with 6 dimensions:\")\nprint(\"  1. Desirable (positive mental health states)\")\nprint(\"  2. Undesirable (negative symptoms/distress)\")\nprint(\"  3. Praiseworthy (appreciation/support)\")\nprint(\"  4. Blameworthy (blame/criticism)\")\nprint(\"  5. Confirmed (validation of fears)\")\nprint(\"  6. Disconfirmed (relief from avoided outcomes)\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mkh6K3lT9BXl","outputId":"05264e3b-f594-43ba-e5ec-4b2464c68b55","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T03:58:27.258679Z","iopub.execute_input":"2025-11-10T03:58:27.258937Z","iopub.status.idle":"2025-11-10T03:58:27.286370Z","shell.execute_reply.started":"2025-11-10T03:58:27.258917Z","shell.execute_reply":"2025-11-10T03:58:27.285813Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCREATING MENTAL HEALTH EMOTION DIMENSION DICTIONARY\n================================================================================\n\n================================================================================\nEMOTION DIMENSION DICTIONARY STATISTICS\n================================================================================\n\nDesirable: 98 total words\n  - general: 37 words\n  - treatment: 12 words\n  - adhd_positive: 11 words\n  - depression_positive: 11 words\n  - ocd_positive: 8 words\n  - ptsd_positive: 9 words\n  - asd_positive: 10 words\n\nUndesirable: 166 total words\n  - general: 29 words\n  - crisis: 21 words\n  - adhd_symptoms: 19 words\n  - depression_symptoms: 32 words\n  - ocd_symptoms: 23 words\n  - ptsd_symptoms: 22 words\n  - asd_symptoms: 22 words\n\nPraiseworthy: 60 total words\n  - providers: 22 words\n  - support: 26 words\n  - self: 12 words\n\nBlameworthy: 49 total words\n  - self_blame: 17 words\n  - blame_others: 19 words\n  - system: 13 words\n\nConfirmed: 23 total words\n  - diagnosis: 10 words\n  - realization: 13 words\n\nDisconfirmed: 21 total words\n  - false_alarm: 10 words\n  - unexpected: 11 words\n\n✅ Step 4 complete!\n\nEDD created with 6 dimensions:\n  1. Desirable (positive mental health states)\n  2. Undesirable (negative symptoms/distress)\n  3. Praiseworthy (appreciation/support)\n  4. Blameworthy (blame/criticism)\n  5. Confirmed (validation of fears)\n  6. Disconfirmed (relief from avoided outcomes)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ============================================================================\n# STEP 5: EMOTION-COGNITIVE REASONING (ECR) SYSTEM\n# ============================================================================\n\nclass MentalHealthECR:\n    \"\"\"\n    Emotion-Cognitive Reasoning for Mental Health\n    Implements 10 OCC-based rules\n    \"\"\"\n\n    def __init__(self, EDD):\n        self.EDD = EDD\n        self.emotion_rules = self._build_emotion_rules()\n\n    def _build_emotion_rules(self):\n        \"\"\"Build 10 emotion-cognitive rules\"\"\"\n        return {\n            # === SINGLE RULES ===\n            'rule_1': {\n                'type': 'single',\n                'condition': ['Desirable'],\n                'emotion': 'hope',\n                'polarity': 'positive',\n                'description': 'Positive coping or recovery signs'\n            },\n            'rule_2': {\n                'type': 'single',\n                'condition': ['Undesirable'],\n                'emotion': 'distress',\n                'polarity': 'negative',\n                'description': 'Symptoms or suffering'\n            },\n            'rule_3': {\n                'type': 'single',\n                'condition': ['Praiseworthy'],\n                'emotion': 'gratitude',\n                'polarity': 'positive',\n                'description': 'Appreciation for support/treatment'\n            },\n            'rule_4': {\n                'type': 'single',\n                'condition': ['Blameworthy'],\n                'emotion': 'reproach',\n                'polarity': 'negative',\n                'description': 'Blame (self or others)'\n            },\n\n            # === COMPOUND RULES ===\n            'rule_5': {\n                'type': 'compound',\n                'condition': ['Desirable', 'Praiseworthy'],\n                'emotion': 'gratitude',\n                'polarity': 'positive',\n                'description': 'Thankful for improvement/help'\n            },\n            'rule_6': {\n                'type': 'compound',\n                'condition': ['Undesirable', 'Blameworthy'],\n                'emotion': 'anger',\n                'polarity': 'negative',\n                'description': 'Anger about suffering/cause'\n            },\n            'rule_7': {\n                'type': 'compound',\n                'condition': ['Desirable', 'Confirmed'],\n                'emotion': 'relief',\n                'polarity': 'positive',\n                'description': 'Relief from positive confirmation'\n            },\n            'rule_8': {\n                'type': 'compound',\n                'condition': ['Undesirable', 'Confirmed'],\n                'emotion': 'fear',\n                'polarity': 'negative',\n                'description': 'Fears realized (diagnosis, relapse)'\n            },\n            'rule_9': {\n                'type': 'compound',\n                'condition': ['Desirable', 'Disconfirmed'],\n                'emotion': 'relief',\n                'polarity': 'positive',\n                'description': 'Relief from avoided negative outcome'\n            },\n            'rule_10': {\n                'type': 'compound',\n                'condition': ['Undesirable', 'Disconfirmed'],\n                'emotion': 'disappointment',\n                'polarity': 'negative',\n                'description': 'Disappointment from failed hope'\n            }\n        }\n\n    def identify_emotion_words(self, text):\n        \"\"\"Step 1: Identify emotion words from text\"\"\"\n        text_lower = text.lower()\n        emotion_words = {\n            'Desirable': [],\n            'Undesirable': [],\n            'Praiseworthy': [],\n            'Blameworthy': [],\n            'Confirmed': [],\n            'Disconfirmed': []\n        }\n\n        for dimension in emotion_words.keys():\n            all_words = self.EDD.get_all_words(dimension)\n\n            for word in all_words:\n                pattern = r'\\b' + re.escape(word.lower()) + r'\\b'\n                matches = re.finditer(pattern, text_lower)\n\n                for match in matches:\n                    position = match.start()\n                    context_start = max(0, position - 50)\n                    context_end = min(len(text), position + 50)\n                    context = text[context_start:context_end]\n\n                    intensity = self.EDD.get_intensity(word, context, dimension)\n\n                    if intensity > 0:\n                        emotion_words[dimension].append({\n                            'word': word,\n                            'position': position,\n                            'intensity': intensity,\n                            'context': context\n                        })\n\n        return emotion_words\n\n    def apply_rules(self, emotion_words):\n        \"\"\"Step 2: Apply 10 emotion-cognitive rules\"\"\"\n        inferred_emotions = []\n\n        # Compound rules first (higher priority)\n        for rule_name in sorted(self.emotion_rules.keys()):\n            rule = self.emotion_rules[rule_name]\n\n            if rule['type'] == 'compound':\n                conditions = rule['condition']\n\n                if all(len(emotion_words[cond]) > 0 for cond in conditions):\n                    words_dim1 = emotion_words[conditions[0]]\n                    words_dim2 = emotion_words[conditions[1]]\n\n                    for w1 in words_dim1[:3]:\n                        for w2 in words_dim2[:3]:\n                            inferred_emotions.append({\n                                'rule': rule_name,\n                                'emotion': rule['emotion'],\n                                'polarity': rule['polarity'],\n                                'type': 'compound',\n                                'words': [w1['word'], w2['word']],\n                                'intensity': (w1['intensity'] + w2['intensity']) / 2,\n                                'evidence': f\"{w1['word']} + {w2['word']}\",\n                                'description': rule['description']\n                            })\n\n        # Single rules\n        for rule_name in sorted(self.emotion_rules.keys()):\n            rule = self.emotion_rules[rule_name]\n\n            if rule['type'] == 'single':\n                condition = rule['condition'][0]\n\n                if len(emotion_words[condition]) > 0:\n                    for word_info in emotion_words[condition][:5]:\n                        inferred_emotions.append({\n                            'rule': rule_name,\n                            'emotion': rule['emotion'],\n                            'polarity': rule['polarity'],\n                            'type': 'single',\n                            'words': [word_info['word']],\n                            'intensity': word_info['intensity'],\n                            'evidence': word_info['word'],\n                            'description': rule['description']\n                        })\n\n        return inferred_emotions\n\n    def calculate_emotion_score(self, text, emotion_words):\n        \"\"\"Step 3: Calculate ES and CS_ECR\"\"\"\n        S_P = 0.0\n        S_N = 0.0\n\n        # Positive intensity\n        for word_info in emotion_words['Desirable']:\n            word = word_info['word']\n            intensity = word_info['intensity']\n            frequency = text.lower().count(word.lower())\n            S_P += intensity * frequency\n\n        for word_info in emotion_words['Praiseworthy']:\n            word = word_info['word']\n            intensity = word_info['intensity']\n            frequency = text.lower().count(word.lower())\n            S_P += intensity * frequency\n\n        for word_info in emotion_words['Disconfirmed']:\n            word = word_info['word']\n            intensity = word_info['intensity']\n            frequency = text.lower().count(word.lower())\n            S_P += intensity * frequency * 0.5\n\n        # Negative intensity\n        for word_info in emotion_words['Undesirable']:\n            word = word_info['word']\n            intensity = word_info['intensity']\n            frequency = text.lower().count(word.lower())\n            S_N += intensity * frequency\n\n        for word_info in emotion_words['Blameworthy']:\n            word = word_info['word']\n            intensity = word_info['intensity']\n            frequency = text.lower().count(word.lower())\n            S_N += intensity * frequency\n\n        for word_info in emotion_words['Confirmed']:\n            word = word_info['word']\n            intensity = word_info['intensity']\n            frequency = text.lower().count(word.lower())\n            S_N += intensity * frequency * 0.5\n\n        # Calculate ES and CS_ECR\n        if S_P + S_N == 0:\n            ES = 0.0\n            CS_ECR = 0.0\n        else:\n            ES = (S_P - S_N) / (S_P + S_N)\n            CS_ECR = abs(ES)\n\n        return ES, CS_ECR, S_P, S_N\n\n    def extract_knowledge(self, text):\n        \"\"\"Main knowledge extraction (Algorithm 1)\"\"\"\n        emotion_words = self.identify_emotion_words(text)\n\n        has_emotion_words = any(len(words) > 0 for words in emotion_words.values())\n\n        if not has_emotion_words:\n            return {\n                'PECK': [],\n                'NECK': [],\n                'ES': 0.0,\n                'CS_ECR': 0.0,\n                'S_P': 0.0,\n                'S_N': 0.0,\n                'has_emotions': False,\n                'emotion_words': emotion_words\n            }\n\n        ES, CS_ECR, S_P, S_N = self.calculate_emotion_score(text, emotion_words)\n        all_inferred_emotions = self.apply_rules(emotion_words)\n\n        PECK = [e for e in all_inferred_emotions if e['polarity'] == 'positive']\n        NECK = [e for e in all_inferred_emotions if e['polarity'] == 'negative']\n\n        if ES > 0:\n            primary_knowledge = 'PECK'\n        elif ES < 0:\n            primary_knowledge = 'NECK'\n        else:\n            primary_knowledge = 'BOTH'\n\n        return {\n            'PECK': PECK,\n            'NECK': NECK,\n            'ES': ES,\n            'CS_ECR': CS_ECR,\n            'S_P': S_P,\n            'S_N': S_N,\n            'has_emotions': True,\n            'primary_knowledge': primary_knowledge,\n            'emotion_words': emotion_words,\n            'total_emotions': len(all_inferred_emotions)\n        }\n\n# Initialize ECR\nprint(\"=\"*80)\nprint(\"INITIALIZING EMOTION-COGNITIVE REASONING SYSTEM\")\nprint(\"=\"*80)\n\necr = MentalHealthECR(EDD)\nprint(\"✅ ECR initialized with 10 emotion-cognitive rules\")\n\n# Test on samples\nprint(\"\\n\" + \"=\"*80)\nprint(\"TESTING ECR ON SAMPLE POSTS\")\nprint(\"=\"*80)\n\ntest_samples = combined_df.sample(5)\n\nfor idx, row in test_samples.iterrows():\n    text = row['text_clean']\n    condition = row['condition']\n\n    print(f\"\\n{'-'*80}\")\n    print(f\"Condition: {condition}\")\n    print(f\"Text: {text[:200]}...\")\n\n    result = ecr.extract_knowledge(text)\n\n    print(f\"\\nECR Results:\")\n    print(f\"  Has emotions: {result['has_emotions']}\")\n    print(f\"  ES: {result['ES']:.3f} (Emotion Score: -1=negative, 0=neutral, 1=positive)\")\n    print(f\"  CS_ECR: {result['CS_ECR']:.3f} (Confidence: 0-1)\")\n    print(f\"  PECK count: {len(result['PECK'])}\")\n    print(f\"  NECK count: {len(result['NECK'])}\")\n\n    if result['PECK']:\n        print(f\"  Positive emotions: {[e['emotion'] for e in result['PECK'][:3]]}\")\n    if result['NECK']:\n        print(f\"  Negative emotions: {[e['emotion'] for e in result['NECK'][:3]]}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ Step 5 complete!\")\nprint(\"\\nECR system ready to process full dataset\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DB7oyFRy9WBq","outputId":"42180749-482f-4b93-eb8d-dc5169c2f1e8","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T03:58:27.287075Z","iopub.execute_input":"2025-11-10T03:58:27.287337Z","iopub.status.idle":"2025-11-10T03:58:27.360981Z","shell.execute_reply.started":"2025-11-10T03:58:27.287311Z","shell.execute_reply":"2025-11-10T03:58:27.360145Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nINITIALIZING EMOTION-COGNITIVE REASONING SYSTEM\n================================================================================\n✅ ECR initialized with 10 emotion-cognitive rules\n\n================================================================================\nTESTING ECR ON SAMPLE POSTS\n================================================================================\n\n--------------------------------------------------------------------------------\nCondition: Aspergers\nText: Cleaning and frustration fits. Today I asked my wife of two years of she can really live with an ASD partner. It started with having to clean the whole house by myself. I dont aggressively clean like ...\n\nECR Results:\n  Has emotions: True\n  ES: -0.105 (Emotion Score: -1=negative, 0=neutral, 1=positive)\n  CS_ECR: 0.105 (Confidence: 0-1)\n  PECK count: 11\n  NECK count: 5\n  Positive emotions: ['gratitude', 'gratitude', 'gratitude']\n  Negative emotions: ['distress', 'distress', 'distress']\n\n--------------------------------------------------------------------------------\nCondition: Aspergers\nText: DAE completely miss read the meaning behind things people who love you say?. Im in a relationship and Im struggling really bad with misunderstanding whats being said. Everything they say goes through ...\n\nECR Results:\n  Has emotions: True\n  ES: -0.333 (Emotion Score: -1=negative, 0=neutral, 1=positive)\n  CS_ECR: 0.333 (Confidence: 0-1)\n  PECK count: 2\n  NECK count: 7\n  Positive emotions: ['gratitude', 'gratitude']\n  Negative emotions: ['anger', 'anger', 'fear']\n\n--------------------------------------------------------------------------------\nCondition: ADHD\nText: Has anyone else been crying a lot less since starting meds?....\n\nECR Results:\n  Has emotions: True\n  ES: -1.000 (Emotion Score: -1=negative, 0=neutral, 1=positive)\n  CS_ECR: 1.000 (Confidence: 0-1)\n  PECK count: 0\n  NECK count: 1\n  Negative emotions: ['distress']\n\n--------------------------------------------------------------------------------\nCondition: OCD\nText: I'm feeling so bad rn. I'm struggling with TOCD rn and i feel awful, i sometimes have intrusive thoughts about my gender and shit and i hate it, i spend most of the day feeling anxious about different...\n\nECR Results:\n  Has emotions: True\n  ES: -0.538 (Emotion Score: -1=negative, 0=neutral, 1=positive)\n  CS_ECR: 0.538 (Confidence: 0-1)\n  PECK count: 1\n  NECK count: 4\n  Positive emotions: ['hope']\n  Negative emotions: ['distress', 'distress', 'distress']\n\n--------------------------------------------------------------------------------\nCondition: Aspergers\nText: How to recover from dating a narcissist?....\n\nECR Results:\n  Has emotions: False\n  ES: 0.000 (Emotion Score: -1=negative, 0=neutral, 1=positive)\n  CS_ECR: 0.000 (Confidence: 0-1)\n  PECK count: 0\n  NECK count: 0\n\n================================================================================\n✅ Step 5 complete!\n\nECR system ready to process full dataset\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================================\n# STEP 6: APPLY ECR TO FULL DATASET\n# ============================================================================\n\nimport time\nfrom tqdm.auto import tqdm\n\nprint(\"=\"*80)\nprint(\"APPLYING ECR TO FULL DATASET\")\nprint(\"=\"*80)\nprint(f\"Total posts to process: {len(combined_df)}\")\nprint(\"This will take approximately 5-10 minutes...\")\n\n# Process in batches for progress tracking\nbatch_size = 1000\nresults = []\n\nstart_time = time.time()\n\nfor i in tqdm(range(0, len(combined_df), batch_size), desc=\"Processing batches\"):\n    batch = combined_df.iloc[i:i+batch_size]\n\n    for idx, row in batch.iterrows():\n        text = row['text_clean']\n\n        # Extract emotion-cognitive knowledge\n        ecr_result = ecr.extract_knowledge(text)\n\n        results.append({\n            'text_clean': text,\n            'ES': ecr_result['ES'],\n            'CS_ECR': ecr_result['CS_ECR'],\n            'S_P': ecr_result['S_P'],\n            'S_N': ecr_result['S_N'],\n            'has_emotions': ecr_result['has_emotions'],\n            'peck_count': len(ecr_result['PECK']),\n            'neck_count': len(ecr_result['NECK']),\n            'PECK': ecr_result['PECK'],\n            'NECK': ecr_result['NECK'],\n            'condition': row['condition'],\n            'score': row['score'],\n            'num_comments': row['num_comments']\n        })\n\n# Create DataFrame with ECR results\necr_df = pd.DataFrame(results)\n\nelapsed_time = time.time() - start_time\nprint(f\"\\n✅ Processing complete in {elapsed_time/60:.1f} minutes\")\n\n# Statistics\nprint(\"\\n\" + \"=\"*80)\nprint(\"ECR PROCESSING STATISTICS\")\nprint(\"=\"*80)\n\nprint(f\"\\nTotal posts: {len(ecr_df)}\")\nprint(f\"Posts with emotions detected: {ecr_df['has_emotions'].sum()} ({ecr_df['has_emotions'].sum()/len(ecr_df)*100:.1f}%)\")\nprint(f\"Posts without emotions: {(~ecr_df['has_emotions']).sum()} ({(~ecr_df['has_emotions']).sum()/len(ecr_df)*100:.1f}%)\")\n\nprint(f\"\\nEmotion Score (ES) statistics:\")\nprint(ecr_df['ES'].describe())\n\nprint(f\"\\nConfidence Score (CS_ECR) statistics:\")\nprint(ecr_df['CS_ECR'].describe())\n\n# Categorize sentiment tendency\necr_df['sentiment_tendency'] = ecr_df['ES'].apply(\n    lambda x: 'positive' if x > 0.2 else ('negative' if x < -0.2 else 'neutral')\n)\n\nprint(f\"\\nSentiment Tendency Distribution:\")\nprint(ecr_df['sentiment_tendency'].value_counts())\nprint(f\"\\nPercentages:\")\nprint(ecr_df['sentiment_tendency'].value_counts(normalize=True) * 100)\n\n# By condition\nprint(f\"\\n{'='*80}\")\nprint(\"SENTIMENT TENDENCY BY CONDITION\")\nprint(\"=\"*80)\nfor condition in ecr_df['condition'].unique():\n    print(f\"\\n{condition}:\")\n    condition_data = ecr_df[ecr_df['condition'] == condition]\n    print(condition_data['sentiment_tendency'].value_counts())\n\nprint(f\"\\n{'='*80}\")\nprint(\"✅ Step 6 complete!\")\nprint(f\"\\nDataset with ECR results: {ecr_df.shape}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["24169bef7f94448d8459900d30968348","ac02bb83fe284fe8991cfe51646f752f","5b513c49a0d04722a5ea08cc8cfd522d","033267e87dd64d52b99c437736941801","9cf78a1e36e545c092f23e549575c9cc","370574e4b6df428bbf07cb518128065c","1c328ef3eb1d4f3ca46880c3f2fd8c24","f44312b2d5eb4ba98425cf4ad89146cc","a4bd4de57e674ea395d7af39be33c07f","5e047296e3a94131a39a80fccc4c0607","b5f37662ce194afb9ef168e97c5cecf2"]},"id":"zZrmMOWU-BEj","outputId":"49387975-a433-4de9-ebad-891985286f1d","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T03:58:27.909703Z","iopub.execute_input":"2025-11-10T03:58:27.909983Z","iopub.status.idle":"2025-11-10T04:08:57.494643Z","shell.execute_reply.started":"2025-11-10T03:58:27.909965Z","shell.execute_reply":"2025-11-10T04:08:57.493907Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nAPPLYING ECR TO FULL DATASET\n================================================================================\nTotal posts to process: 141254\nThis will take approximately 5-10 minutes...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing batches:   0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1f80cd4b5644684b8f55f2d58091fe3"}},"metadata":{}},{"name":"stdout","text":"\n✅ Processing complete in 10.5 minutes\n\n================================================================================\nECR PROCESSING STATISTICS\n================================================================================\n\nTotal posts: 141254\nPosts with emotions detected: 99193 (70.2%)\nPosts without emotions: 42061 (29.8%)\n\nEmotion Score (ES) statistics:\ncount    141254.000000\nmean         -0.034599\nstd           0.636038\nmin          -1.000000\n25%          -0.500000\n50%           0.000000\n75%           0.333333\nmax           1.000000\nName: ES, dtype: float64\n\nConfidence Score (CS_ECR) statistics:\ncount    141254.000000\nmean          0.473051\nstd           0.426571\nmin           0.000000\n25%           0.000000\n50%           0.422222\n75%           1.000000\nmax           1.000000\nName: CS_ECR, dtype: float64\n\nSentiment Tendency Distribution:\nsentiment_tendency\nneutral     57585\nnegative    44246\npositive    39423\nName: count, dtype: int64\n\nPercentages:\nsentiment_tendency\nneutral     40.766987\nnegative    31.323715\npositive    27.909298\nName: proportion, dtype: float64\n\n================================================================================\nSENTIMENT TENDENCY BY CONDITION\n================================================================================\n\nADHD:\nsentiment_tendency\nneutral     15656\npositive    10021\nnegative     9648\nName: count, dtype: int64\n\nAspergers:\nsentiment_tendency\nneutral     9140\npositive    8218\nnegative    4700\nName: count, dtype: int64\n\nDepression:\nsentiment_tendency\nneutral     9140\npositive    8218\nnegative    4700\nName: count, dtype: int64\n\nOCD:\nsentiment_tendency\nnegative    15855\nneutral     15597\npositive     8191\nName: count, dtype: int64\n\nPTSD:\nsentiment_tendency\nnegative    9343\nneutral     8052\npositive    4775\nName: count, dtype: int64\n\n================================================================================\n✅ Step 6 complete!\n\nDataset with ECR results: (141254, 14)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================================================\n# STEP 7: RULE-BASED PSEUDO-LABELING\n# ============================================================================\n\nclass MentalHealthSentimentLabeler:\n    \"\"\"\n    Create pseudo-labels using ECR results + keyword heuristics\n    Labels: positive (0), negative (1), neutral (2)\n    \"\"\"\n\n    def __init__(self):\n        self.crisis_keywords = [\n            'suicidal', 'kill myself', 'want to die', 'end it all',\n            'better off dead', 'no reason to live', 'cant go on',\n            'self harm', 'cutting myself', 'overdose'\n        ]\n\n        self.strong_positive = [\n            'feeling better', 'much better', 'improving', 'recovery',\n            'breakthrough', 'proud of myself', 'made progress',\n            'therapy helping', 'medication working'\n        ]\n\n        self.strong_negative = [\n            'getting worse', 'cant cope', 'breaking down',\n            'falling apart', 'unbearable', 'hopeless',\n            'relapse', 'crisis'\n        ]\n\n    def label_post(self, text, ES, CS_ECR, S_P, S_N):\n        \"\"\"\n        Create pseudo-label using multiple signals\n        Returns: (label, confidence, reasoning)\n        \"\"\"\n        text_lower = text.lower()\n\n        # SIGNAL 1: Crisis detection (highest priority)\n        for keyword in self.crisis_keywords:\n            if keyword in text_lower:\n                return 'negative', 1.0, f\"Crisis: {keyword}\"\n\n        # SIGNAL 2: Strong keyword matching\n        pos_score = sum(1 for kw in self.strong_positive if kw in text_lower)\n        neg_score = sum(1 for kw in self.strong_negative if kw in text_lower)\n\n        # SIGNAL 3: ECR-based scoring\n        if ES > 0.3:\n            # Strong positive tendency\n            label = 'positive'\n            confidence = min(0.7 + (ES * 0.3), 0.95)\n            reasoning = f\"ES={ES:.2f} (positive)\"\n        elif ES < -0.3:\n            # Strong negative tendency\n            label = 'negative'\n            confidence = min(0.7 + (abs(ES) * 0.3), 0.95)\n            reasoning = f\"ES={ES:.2f} (negative)\"\n        elif ES > 0.1:\n            # Weak positive\n            label = 'positive'\n            confidence = 0.5 + pos_score * 0.1\n            reasoning = f\"ES={ES:.2f} (weak positive)\"\n        elif ES < -0.1:\n            # Weak negative\n            label = 'negative'\n            confidence = 0.5 + neg_score * 0.1\n            reasoning = f\"ES={ES:.2f} (weak negative)\"\n        else:\n            # Neutral\n            label = 'neutral'\n            confidence = 0.4\n            reasoning = f\"ES={ES:.2f} (neutral)\"\n\n        # SIGNAL 4: Questions often neutral\n        if text.count('?') >= 2 and len(text) < 300:\n            if label != 'negative' or confidence < 0.7:\n                label = 'neutral'\n                confidence = max(confidence * 0.7, 0.3)\n                reasoning += \" + questions\"\n\n        return label, confidence, reasoning\n\n# Initialize labeler\nprint(\"=\"*80)\nprint(\"STEP 7: RULE-BASED PSEUDO-LABELING\")\nprint(\"=\"*80)\n\nlabeler = MentalHealthSentimentLabeler()\n\n# Apply labeling\nprint(\"\\nGenerating pseudo-labels...\")\nlabels = []\nconfidences = []\nreasonings = []\n\nfor idx, row in tqdm(ecr_df.iterrows(), total=len(ecr_df), desc=\"Labeling\"):\n    label, confidence, reasoning = labeler.label_post(\n        row['text_clean'],\n        row['ES'],\n        row['CS_ECR'],\n        row['S_P'],\n        row['S_N']\n    )\n\n    labels.append(label)\n    confidences.append(confidence)\n    reasonings.append(reasoning)\n\necr_df['label'] = labels\necr_df['label_confidence'] = confidences\necr_df['label_reasoning'] = reasonings\n\n# Convert to numeric\nlabel_map = {'positive': 0, 'negative': 1, 'neutral': 2}\necr_df['label_numeric'] = ecr_df['label'].map(label_map)\n\nprint(\"\\n✅ Pseudo-labeling complete!\")\n\n# Statistics\nprint(\"\\n\" + \"=\"*80)\nprint(\"LABEL STATISTICS\")\nprint(\"=\"*80)\n\nprint(\"\\nLabel distribution:\")\nprint(ecr_df['label'].value_counts())\nprint(\"\\nPercentages:\")\nprint(ecr_df['label'].value_counts(normalize=True) * 100)\n\nprint(\"\\nConfidence statistics:\")\nprint(ecr_df['label_confidence'].describe())\n\n# By condition\nprint(\"\\n\" + \"=\"*80)\nprint(\"LABEL DISTRIBUTION BY CONDITION\")\nprint(\"=\"*80)\n\nfor condition in ecr_df['condition'].unique():\n    print(f\"\\n{condition}:\")\n    condition_df = ecr_df[ecr_df['condition'] == condition]\n    print(condition_df['label'].value_counts())\n\n## Fix the sampling issue\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAMPLE LABELED POSTS (FIXED)\")\nprint(\"=\"*80)\n\nfor label in ['positive', 'negative', 'neutral']:\n    print(f\"\\n{label.upper()} Examples:\")\n    print(\"-\" * 80)\n\n    # Try high confidence first, then any confidence\n    high_conf = ecr_df[\n        (ecr_df['label'] == label) &\n        (ecr_df['label_confidence'] > 0.7)\n    ]\n\n    if len(high_conf) >= 2:\n        samples = high_conf.sample(2)\n    else:\n        samples = ecr_df[ecr_df['label'] == label].sample(min(2, len(ecr_df[ecr_df['label'] == label])))\n\n    for idx, row in samples.iterrows():\n        print(f\"\\nText: {row['text_clean'][:150]}...\")\n        print(f\"Confidence: {row['label_confidence']:.2f}\")\n        print(f\"Reasoning: {row['label_reasoning']}\")\n        print(f\"ES: {row['ES']:.3f}, PECK: {row['peck_count']}, NECK: {row['neck_count']}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ Step 7 complete!\")\nprint(f\"\\nLabeled dataset: {ecr_df.shape}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b03d5cf2e6cf4fa6ba1a3ac619184067","f21a1e7af7cb44b599b39e448b27d82c","8418c4793d8245b697817d7896814b13","ba515562ba3543e9a7b1256d17957373","1381dd8498244875b11bdf7114f0567b","ba442ad20dd74291aa0ebfcf664172f2","6bdad9e8faec4ca6b5386861e50060d2","de3efb49cf4242a5b36e4d931b876a55","ae4f0af74177409bb4e651a2ad7bd732","377fe9d6ae904dcc92d1cd635e65536d","57af5743a3fd4660a5d56c876026736f"]},"id":"HPto1fEcpD7k","outputId":"4bc4b5fe-751f-402a-9a86-3fb459b255fc","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T04:08:57.495842Z","iopub.execute_input":"2025-11-10T04:08:57.496063Z","iopub.status.idle":"2025-11-10T04:09:06.761373Z","shell.execute_reply.started":"2025-11-10T04:08:57.496045Z","shell.execute_reply":"2025-11-10T04:09:06.760765Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTEP 7: RULE-BASED PSEUDO-LABELING\n================================================================================\n\nGenerating pseudo-labels...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Labeling:   0%|          | 0/141254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9c95366a2214c20a37cac04568a79ce"}},"metadata":{}},{"name":"stdout","text":"\n✅ Pseudo-labeling complete!\n\n================================================================================\nLABEL STATISTICS\n================================================================================\n\nLabel distribution:\nlabel\nneutral     51586\nnegative    48367\npositive    41301\nName: count, dtype: int64\n\nPercentages:\nlabel\nneutral     36.520028\nnegative    34.241154\npositive    29.238818\nName: proportion, dtype: float64\n\nConfidence statistics:\ncount    141254.000000\nmean          0.695441\nstd           0.254151\nmin           0.300000\n25%           0.400000\n50%           0.823529\n75%           0.950000\nmax           1.000000\nName: label_confidence, dtype: float64\n\n================================================================================\nLABEL DISTRIBUTION BY CONDITION\n================================================================================\n\nADHD:\nlabel\nneutral     13631\npositive    10953\nnegative    10741\nName: count, dtype: int64\n\nAspergers:\nlabel\nneutral     8485\npositive    8336\nnegative    5237\nName: count, dtype: int64\n\nDepression:\nlabel\nneutral     8485\npositive    8336\nnegative    5237\nName: count, dtype: int64\n\nOCD:\nlabel\nnegative    16983\nneutral     14077\npositive     8583\nName: count, dtype: int64\n\nPTSD:\nlabel\nnegative    10169\nneutral      6908\npositive     5093\nName: count, dtype: int64\n\n================================================================================\nSAMPLE LABELED POSTS (FIXED)\n================================================================================\n\nPOSITIVE Examples:\n--------------------------------------------------------------------------------\n\nText: I Wish I Could Talk to People without Feeling Depressed or BoredI Dont Want to Come Off as Being Rude and Disinterested....\nConfidence: 0.95\nReasoning: ES=1.00 (positive)\nES: 1.000, PECK: 1, NECK: 0\n\nText: I need someone to calm me down....\nConfidence: 0.95\nReasoning: ES=1.00 (positive)\nES: 1.000, PECK: 3, NECK: 0\n\nNEGATIVE Examples:\n--------------------------------------------------------------------------------\n\nText: does anyone know if this is ocd or not. i dont know, i just feel like theirs two different people living in my head and its getting to the point where...\nConfidence: 0.82\nReasoning: ES=-0.41 (negative)\nES: -0.412, PECK: 3, NECK: 3\n\nText: Am I being rational? TW: rabies. I have a question. I posted this before but I'm still bothered by it. My mental health has improved a lot though. Thi...\nConfidence: 0.87\nReasoning: ES=-0.56 (negative)\nES: -0.556, PECK: 3, NECK: 5\n\nNEUTRAL Examples:\n--------------------------------------------------------------------------------\n\nText: How much is therapy for depression?....\nConfidence: 0.40\nReasoning: ES=0.00 (neutral)\nES: 0.000, PECK: 0, NECK: 0\n\nText: Do you have an interesting playlist to focus?. I need to focus on studying for an exam but I can't seem to find the right playlist, so I've been liste...\nConfidence: 0.40\nReasoning: ES=0.00 (neutral)\nES: 0.000, PECK: 0, NECK: 0\n\n================================================================================\n✅ Step 7 complete!\n\nLabeled dataset: (141254, 18)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================================================\n# STEP 8: QUALITY CONTROL & DATASET BALANCING\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"STEP 8: QUALITY CONTROL & DATASET BALANCING\")\nprint(\"=\"*80)\n\n# Current state\nprint(\"\\nCurrent dataset:\")\nprint(f\"Total posts: {len(ecr_df)}\")\nprint(f\"\\nLabel distribution:\")\nprint(ecr_df['label'].value_counts())\n\n# Step 8.1: Filter by confidence threshold\nprint(\"\\n\" + \"-\"*80)\nprint(\"8.1: FILTERING BY CONFIDENCE\")\nprint(\"-\"*80)\n\nconfidence_threshold = 0.5\nprint(f\"Confidence threshold: {confidence_threshold}\")\n\necr_df_filtered = ecr_df[ecr_df['label_confidence'] >= confidence_threshold].copy()\n\nprint(f\"\\nBefore filtering: {len(ecr_df)} posts\")\nprint(f\"After filtering:  {len(ecr_df_filtered)} posts\")\nprint(f\"Removed: {len(ecr_df) - len(ecr_df_filtered)} low-confidence posts ({(len(ecr_df) - len(ecr_df_filtered))/len(ecr_df)*100:.1f}%)\")\n\nprint(f\"\\nLabel distribution after filtering:\")\nprint(ecr_df_filtered['label'].value_counts())\n\n# Step 8.2: Balance dataset\nprint(\"\\n\" + \"-\"*80)\nprint(\"8.2: BALANCING DATASET\")\nprint(\"-\"*80)\n\nlabel_counts = ecr_df_filtered['label'].value_counts()\nprint(f\"\\nBefore balancing:\")\nprint(label_counts)\n\n# Use undersampling to balance\nmin_count = label_counts.min()\nprint(f\"\\nTarget count per class (min): {min_count}\")\n\nbalanced_dfs = []\nfor label in ['positive', 'negative', 'neutral']:\n    label_df = ecr_df_filtered[ecr_df_filtered['label'] == label]\n\n    if len(label_df) > min_count:\n        # Undersample\n        label_df_sampled = label_df.sample(n=min_count, random_state=42)\n    else:\n        label_df_sampled = label_df\n\n    balanced_dfs.append(label_df_sampled)\n\n# Combine and shuffle\necr_df_balanced = pd.concat(balanced_dfs, ignore_index=True)\necr_df_balanced = ecr_df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(f\"\\nAfter balancing:\")\nprint(ecr_df_balanced['label'].value_counts())\nprint(f\"\\nTotal balanced dataset: {len(ecr_df_balanced)} posts\")\n\n# Distribution by condition\nprint(\"\\n\" + \"-\"*80)\nprint(\"BALANCED DATASET BY CONDITION\")\nprint(\"-\"*80)\n\nfor condition in ecr_df_balanced['condition'].unique():\n    condition_df = ecr_df_balanced[ecr_df_balanced['condition'] == condition]\n    print(f\"\\n{condition}: {len(condition_df)} posts\")\n    print(condition_df['label'].value_counts())\n\n# Step 8.3: Final statistics\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINAL DATASET STATISTICS\")\nprint(\"=\"*80)\n\nprint(f\"\\nTotal posts: {len(ecr_df_balanced)}\")\nprint(f\"\\nLabel distribution:\")\nprint(ecr_df_balanced['label'].value_counts())\nprint(f\"\\nPercentages:\")\nprint(ecr_df_balanced['label'].value_counts(normalize=True) * 100)\n\nprint(f\"\\nCondition distribution:\")\nprint(ecr_df_balanced['condition'].value_counts())\n\nprint(f\"\\nConfidence statistics:\")\nprint(ecr_df_balanced['label_confidence'].describe())\n\nprint(f\"\\nES (Emotion Score) statistics:\")\nprint(ecr_df_balanced['ES'].describe())\n\nprint(f\"\\nText length statistics:\")\necr_df_balanced['text_length'] = ecr_df_balanced['text_clean'].str.len()\nprint(ecr_df_balanced['text_length'].describe())\n\n# Step 8.4: Save processed dataset\nprint(\"\\n\" + \"-\"*80)\nprint(\"SAVING PROCESSED DATA\")\nprint(\"-\"*80)\n\n# Save balanced dataset\necr_df_balanced.to_csv('mental_health_balanced_labeled.csv', index=False)\nprint(\"✅ Saved: mental_health_balanced_labeled.csv\")\n\n# Also save the full filtered dataset (unbalanced but high confidence)\necr_df_filtered.to_csv('mental_health_filtered_labeled.csv', index=False)\nprint(\"✅ Saved: mental_health_filtered_labeled.csv\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ Step 8 complete!\")\nprint(\"=\"*80)\n\nprint(f\"\\nFinal balanced dataset ready for training:\")\nprint(f\"  - Total posts: {len(ecr_df_balanced)}\")\nprint(f\"  - Labels: 3 classes (positive, negative, neutral)\")\nprint(f\"  - Balanced: ~{min_count} posts per class\")\nprint(f\"  - Conditions: {ecr_df_balanced['condition'].nunique()} mental health conditions\")\n\n# Show summary\nprint(\"\\n\" + \"=\"*80)\nprint(\"DATASET SUMMARY\")\nprint(\"=\"*80)\nsummary_df = ecr_df_balanced.groupby(['condition', 'label']).size().unstack(fill_value=0)\nprint(summary_df)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"faXXOAbcx-DW","outputId":"a9920cfb-0d95-46aa-dbec-a53184d9c58e","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T04:09:06.762146Z","iopub.execute_input":"2025-11-10T04:09:06.762402Z","iopub.status.idle":"2025-11-10T04:09:13.767958Z","shell.execute_reply.started":"2025-11-10T04:09:06.762373Z","shell.execute_reply":"2025-11-10T04:09:13.767231Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTEP 8: QUALITY CONTROL & DATASET BALANCING\n================================================================================\n\nCurrent dataset:\nTotal posts: 141254\n\nLabel distribution:\nlabel\nneutral     51586\nnegative    48367\npositive    41301\nName: count, dtype: int64\n\n--------------------------------------------------------------------------------\n8.1: FILTERING BY CONFIDENCE\n--------------------------------------------------------------------------------\nConfidence threshold: 0.5\n\nBefore filtering: 141254 posts\nAfter filtering:  90946 posts\nRemoved: 50308 low-confidence posts (35.6%)\n\nLabel distribution after filtering:\nlabel\nnegative    48367\npositive    41301\nneutral      1278\nName: count, dtype: int64\n\n--------------------------------------------------------------------------------\n8.2: BALANCING DATASET\n--------------------------------------------------------------------------------\n\nBefore balancing:\nlabel\nnegative    48367\npositive    41301\nneutral      1278\nName: count, dtype: int64\n\nTarget count per class (min): 1278\n\nAfter balancing:\nlabel\nneutral     1278\nnegative    1278\npositive    1278\nName: count, dtype: int64\n\nTotal balanced dataset: 3834 posts\n\n--------------------------------------------------------------------------------\nBALANCED DATASET BY CONDITION\n--------------------------------------------------------------------------------\n\nAspergers: 733 posts\nlabel\nneutral     323\npositive    273\nnegative    137\nName: count, dtype: int64\n\nOCD: 1131 posts\nlabel\nnegative    447\nneutral     406\npositive    278\nName: count, dtype: int64\n\nDepression: 720 posts\nlabel\nneutral     323\npositive    245\nnegative    152\nName: count, dtype: int64\n\nADHD: 699 posts\nlabel\npositive    340\nnegative    282\nneutral      77\nName: count, dtype: int64\n\nPTSD: 551 posts\nlabel\nnegative    260\nneutral     149\npositive    142\nName: count, dtype: int64\n\n================================================================================\nFINAL DATASET STATISTICS\n================================================================================\n\nTotal posts: 3834\n\nLabel distribution:\nlabel\nneutral     1278\nnegative    1278\npositive    1278\nName: count, dtype: int64\n\nPercentages:\nlabel\nneutral     33.333333\nnegative    33.333333\npositive    33.333333\nName: proportion, dtype: float64\n\nCondition distribution:\ncondition\nOCD           1131\nAspergers      733\nDepression     720\nADHD           699\nPTSD           551\nName: count, dtype: int64\n\nConfidence statistics:\ncount    3834.000000\nmean        0.793735\nstd         0.158533\nmin         0.500000\n25%         0.665000\n50%         0.840000\n75%         0.950000\nmax         1.000000\nName: label_confidence, dtype: float64\n\nES (Emotion Score) statistics:\ncount    3834.000000\nmean        0.305896\nstd         0.787649\nmin        -1.000000\n25%        -0.454545\n50%         0.636364\n75%         1.000000\nmax         1.000000\nName: ES, dtype: float64\n\nText length statistics:\ncount    3834.000000\nmean      589.407147\nstd       723.900941\nmin        20.000000\n25%       136.250000\n50%       284.000000\n75%       776.000000\nmax      4919.000000\nName: text_length, dtype: float64\n\n--------------------------------------------------------------------------------\nSAVING PROCESSED DATA\n--------------------------------------------------------------------------------\n✅ Saved: mental_health_balanced_labeled.csv\n✅ Saved: mental_health_filtered_labeled.csv\n\n================================================================================\n✅ Step 8 complete!\n================================================================================\n\nFinal balanced dataset ready for training:\n  - Total posts: 3834\n  - Labels: 3 classes (positive, negative, neutral)\n  - Balanced: ~1278 posts per class\n  - Conditions: 5 mental health conditions\n\n================================================================================\nDATASET SUMMARY\n================================================================================\nlabel       negative  neutral  positive\ncondition                              \nADHD             282       77       340\nAspergers        137      323       273\nDepression       152      323       245\nOCD              447      406       278\nPTSD             260      149       142\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ============================================================================\n# STEP 8 REVISED: BETTER BALANCING STRATEGY\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"STEP 8 REVISED: IMPROVED BALANCING\")\nprint(\"=\"*80)\n\n# Use lower confidence threshold to get more data\nconfidence_threshold = 0.4  # Lower threshold\nprint(f\"Using confidence threshold: {confidence_threshold}\")\n\necr_df_filtered_v2 = ecr_df[ecr_df['label_confidence'] >= confidence_threshold].copy()\n\nprint(f\"\\nFiltered dataset: {len(ecr_df_filtered_v2)} posts\")\nprint(\"\\nLabel distribution:\")\nprint(ecr_df_filtered_v2['label'].value_counts())\n\n# Strategy: Balance by limiting majority classes, keep all minority\nlabel_counts = ecr_df_filtered_v2['label'].value_counts()\nprint(f\"\\nOriginal distribution:\")\nfor label, count in label_counts.items():\n    print(f\"  {label}: {count}\")\n\n# Set target: Take middle value or cap at reasonable size\ntarget_per_class = min(label_counts.max(), 20000)  # Cap at 20k per class\ntarget_per_class = max(target_per_class, label_counts.min() * 2)  # At least 2x minority\n\nprint(f\"\\nTarget per class: {target_per_class}\")\n\n# Balance by undersampling majority, keeping all minority\nbalanced_dfs_v2 = []\nfor label in ['positive', 'negative', 'neutral']:\n    label_df = ecr_df_filtered_v2[ecr_df_filtered_v2['label'] == label]\n\n    if len(label_df) > target_per_class:\n        # Undersample with stratification by condition\n        label_df_sampled = label_df.groupby('condition', group_keys=False).apply(\n            lambda x: x.sample(n=min(len(x), target_per_class // 5), random_state=42)\n        )\n    else:\n        label_df_sampled = label_df\n\n    balanced_dfs_v2.append(label_df_sampled)\n    print(f\"{label}: {len(label_df)} → {len(label_df_sampled)}\")\n\n# Combine\necr_df_balanced_v2 = pd.concat(balanced_dfs_v2, ignore_index=True)\necr_df_balanced_v2 = ecr_df_balanced_v2.sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(f\"\\n{'='*80}\")\nprint(\"FINAL BALANCED DATASET V2\")\nprint(\"=\"*80)\n\nprint(f\"\\nTotal posts: {len(ecr_df_balanced_v2)}\")\nprint(\"\\nLabel distribution:\")\nprint(ecr_df_balanced_v2['label'].value_counts())\nprint(\"\\nPercentages:\")\nprint(ecr_df_balanced_v2['label'].value_counts(normalize=True) * 100)\n\nprint(\"\\nCondition distribution:\")\nprint(ecr_df_balanced_v2['condition'].value_counts())\n\n# Summary table\nprint(\"\\n\" + \"=\"*80)\nprint(\"DATASET SUMMARY BY CONDITION\")\nprint(\"=\"*80)\nsummary_df_v2 = ecr_df_balanced_v2.groupby(['condition', 'label']).size().unstack(fill_value=0)\nprint(summary_df_v2)\nprint(f\"\\nTotal: {summary_df_v2.sum().sum()}\")\n\n# Save\necr_df_balanced_v2.to_csv('mental_health_balanced_v2.csv', index=False)\nprint(\"\\n✅ Saved: mental_health_balanced_v2.csv\")\n\n# Use this as final dataset\necr_df_final = ecr_df_balanced_v2.copy()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ Step 8 REVISED complete!\")\nprint(f\"Final dataset: {len(ecr_df_final)} posts\")\nprint(\"=\"*80)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nqbF7tIayli1","outputId":"53d17c4f-c3fc-459a-af40-17295021fedf","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T04:11:31.934440Z","iopub.execute_input":"2025-11-10T04:11:31.935223Z","iopub.status.idle":"2025-11-10T04:11:40.163855Z","shell.execute_reply.started":"2025-11-10T04:11:31.935198Z","shell.execute_reply":"2025-11-10T04:11:40.162994Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTEP 8 REVISED: IMPROVED BALANCING\n================================================================================\nUsing confidence threshold: 0.4\n\nFiltered dataset: 138419 posts\n\nLabel distribution:\nlabel\nneutral     48751\nnegative    48367\npositive    41301\nName: count, dtype: int64\n\nOriginal distribution:\n  neutral: 48751\n  negative: 48367\n  positive: 41301\n\nTarget per class: 82602\npositive: 41301 → 41301\nnegative: 48367 → 48367\nneutral: 48751 → 48751\n\n================================================================================\nFINAL BALANCED DATASET V2\n================================================================================\n\nTotal posts: 138419\n\nLabel distribution:\nlabel\nneutral     48751\nnegative    48367\npositive    41301\nName: count, dtype: int64\n\nPercentages:\nlabel\nneutral     35.219876\nnegative    34.942457\npositive    29.837667\nName: proportion, dtype: float64\n\nCondition distribution:\ncondition\nOCD           38576\nADHD          34933\nPTSD          21844\nAspergers     21533\nDepression    21533\nName: count, dtype: int64\n\n================================================================================\nDATASET SUMMARY BY CONDITION\n================================================================================\nlabel       negative  neutral  positive\ncondition                              \nADHD           10741    13239     10953\nAspergers       5237     7960      8336\nDepression      5237     7960      8336\nOCD            16983    13010      8583\nPTSD           10169     6582      5093\n\nTotal: 138419\n\n✅ Saved: mental_health_balanced_v2.csv\n\n================================================================================\n✅ Step 8 REVISED complete!\nFinal dataset: 138419 posts\n================================================================================\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ============================================================================\n# STEP 9: GENERATE SENTENCE-EMOTION TREES (SETs)\n# ============================================================================\n\nclass SentenceEmotionTreeGenerator:\n    \"\"\"\n    Generate Sentence-Emotion Trees (SETs)\n    Integrates emotion-cognitive knowledge into text\n    \"\"\"\n\n    def __init__(self, ecr):\n        self.ecr = ecr\n\n    def create_emotion_annotation(self, emotions, max_emotions=3):\n        \"\"\"Create emotion annotations for tree structure\"\"\"\n        if not emotions:\n            return \"\"\n\n        # Sort by intensity and limit\n        sorted_emotions = sorted(\n            emotions,\n            key=lambda x: x['intensity'],\n            reverse=True\n        )[:max_emotions]\n\n        annotations = []\n        for emo in sorted_emotions:\n            if emo['type'] == 'compound':\n                # Compound: word1+word2{emotion}\n                annotation = f\"{emo['words'][0]}+{emo['words'][1]}→{emo['emotion']}\"\n            else:\n                # Single: word{emotion}\n                annotation = f\"{emo['words'][0]}→{emo['emotion']}\"\n\n            annotations.append(annotation)\n\n        return \" | \".join(annotations)\n\n    def generate_set(self, text, ES, CS_ECR, PECK, NECK, threshold=0.3):\n        \"\"\"\n        Generate Sentence-Emotion Tree (SET)\n\n        Decision: Which emotions to incorporate based on ES\n        \"\"\"\n\n        # Decide which emotions to use\n        if ES > 0.2:\n            # Strong positive → use PECK\n            selected_emotions = PECK\n            tendency = 'positive'\n        elif ES < -0.2:\n            # Strong negative → use NECK\n            selected_emotions = NECK\n            tendency = 'negative'\n        elif ES > 0:\n            # Weak positive → use PECK\n            selected_emotions = PECK\n            tendency = 'weak_positive'\n        elif ES < 0:\n            # Weak negative → use NECK\n            selected_emotions = NECK\n            tendency = 'weak_negative'\n        else:\n            # Neutral\n            selected_emotions = []\n            tendency = 'neutral'\n\n        # Create SET\n        if selected_emotions and CS_ECR >= threshold:\n            emotion_annotation = self.create_emotion_annotation(selected_emotions)\n            # Append emotions at end\n            set_text = f\"{text} [EMOTIONS: {emotion_annotation}]\"\n            used_ecr = True\n        else:\n            set_text = text\n            used_ecr = False\n\n        return {\n            'SET': set_text,\n            'tendency': tendency,\n            'selected_emotions': selected_emotions,\n            'emotion_count': len(selected_emotions),\n            'used_ecr': used_ecr\n        }\n\n# Initialize SET generator\nprint(\"=\"*80)\nprint(\"STEP 9: GENERATING SENTENCE-EMOTION TREES\")\nprint(\"=\"*80)\n\nset_generator = SentenceEmotionTreeGenerator(ecr)\n\n# Generate SETs for the dataset\nprint(f\"\\nGenerating SETs for {len(ecr_df_final)} posts...\")\nprint(\"This will take 2-3 minutes...\")\n\nsets_data = []\n\nfor idx, row in tqdm(ecr_df_final.iterrows(), total=len(ecr_df_final), desc=\"Generating SETs\"):\n    set_result = set_generator.generate_set(\n        text=row['text_clean'],\n        ES=row['ES'],\n        CS_ECR=row['CS_ECR'],\n        PECK=row['PECK'],\n        NECK=row['NECK'],\n        threshold=0.3\n    )\n\n    sets_data.append({\n        'original_text': row['text_clean'],\n        'SET': set_result['SET'],\n        'ES': row['ES'],\n        'CS_ECR': row['CS_ECR'],\n        'tendency': set_result['tendency'],\n        'emotion_count': set_result['emotion_count'],\n        'used_ecr': set_result['used_ecr'],\n        'label': row['label'],\n        'label_numeric': row['label_numeric'],\n        'label_confidence': row['label_confidence'],\n        'condition': row['condition'],\n        'peck_count': row['peck_count'],\n        'neck_count': row['neck_count']\n    })\n\n# Create DataFrame with SETs\nsets_df = pd.DataFrame(sets_data)\n\nprint(\"\\n✅ All SETs generated!\")\n\n# Statistics\nprint(\"\\n\" + \"=\"*80)\nprint(\"SET STATISTICS\")\nprint(\"=\"*80)\n\nprint(f\"\\nTotal SETs: {len(sets_df)}\")\nprint(f\"SETs with emotions incorporated: {sets_df['used_ecr'].sum()} ({sets_df['used_ecr'].sum()/len(sets_df)*100:.1f}%)\")\nprint(f\"SETs without emotions: {(~sets_df['used_ecr']).sum()} ({(~sets_df['used_ecr']).sum()/len(sets_df)*100:.1f}%)\")\n\nprint(f\"\\nTendency distribution:\")\nprint(sets_df['tendency'].value_counts())\n\nprint(f\"\\nEmotion count distribution:\")\nprint(sets_df['emotion_count'].value_counts().head(10))\n\n# Text length comparison\nsets_df['original_length'] = sets_df['original_text'].str.len()\nsets_df['set_length'] = sets_df['SET'].str.len()\nsets_df['length_increase'] = sets_df['set_length'] - sets_df['original_length']\n\nprint(f\"\\nText length comparison:\")\nprint(f\"Original avg length: {sets_df['original_length'].mean():.0f} chars\")\nprint(f\"SET avg length: {sets_df['set_length'].mean():.0f} chars\")\nprint(f\"Avg increase: {sets_df['length_increase'].mean():.0f} chars\")\n\n# Show examples\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAMPLE SENTENCE-EMOTION TREES\")\nprint(\"=\"*80)\n\nfor label in ['positive', 'negative', 'neutral']:\n    print(f\"\\n{label.upper()} Examples with Emotions:\")\n    print(\"-\" * 80)\n\n    sample = sets_df[\n        (sets_df['label'] == label) &\n        (sets_df['emotion_count'] > 0)\n    ]\n\n    if len(sample) > 0:\n        sample_row = sample.sample(1).iloc[0]\n\n        print(f\"Original: {sample_row['original_text'][:150]}...\")\n        print(f\"\\nSET: {sample_row['SET'][:300]}...\")\n        print(f\"\\nStats:\")\n        print(f\"  ES: {sample_row['ES']:.3f} | CS_ECR: {sample_row['CS_ECR']:.3f}\")\n        print(f\"  Tendency: {sample_row['tendency']}\")\n        print(f\"  Emotions: {sample_row['emotion_count']}\")\n        print(f\"  PECK: {sample_row['peck_count']}, NECK: {sample_row['neck_count']}\")\n    else:\n        print(\"No examples with emotions found\")\n\n# Save dataset with SETs\nsets_df.to_csv('mental_health_with_sets.csv', index=False)\nprint(f\"\\n✅ Saved: mental_health_with_sets.csv\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ Step 9 complete!\")\nprint(\"=\"*80)\nprint(f\"\\nDataset with SETs ready: {len(sets_df)} posts\")\nprint(f\"  - Original text preserved\")\nprint(f\"  - SETs with emotion annotations created\")\nprint(f\"  - Ready for BERT training\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["03f611c0756945cc90dd0c6dc96df744","27ef2974829f49a696d82a2942747353","0934a93f8dd54f73a813be29152a96d5","3d926ae9873045d58a33db95fc63e4f2","7daf2e8148cc4a90951757b2e43108eb","32c0e5a605e74b12aaee6419400c3e85","70582ff016584332bb85677d17d5dbc3","fb5e28faff3641d09f0da757a4ba7d2d","8d26209bf0224ce6b019942fe9969dc4","e2936f897e1d448fb12039c98b582a3c","9ddba87f1b5448769f4d1d42f9ac4f15"]},"id":"qtkxVdhjyvqg","outputId":"1c5392aa-f19c-4c97-8670-ab138b1aa538","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T04:11:40.165112Z","iopub.execute_input":"2025-11-10T04:11:40.165373Z","iopub.status.idle":"2025-11-10T04:11:55.351790Z","shell.execute_reply.started":"2025-11-10T04:11:40.165355Z","shell.execute_reply":"2025-11-10T04:11:55.351005Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTEP 9: GENERATING SENTENCE-EMOTION TREES\n================================================================================\n\nGenerating SETs for 138419 posts...\nThis will take 2-3 minutes...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating SETs:   0%|          | 0/138419 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63864dd1eb9941f39c0d489ca803f0db"}},"metadata":{}},{"name":"stdout","text":"\n✅ All SETs generated!\n\n================================================================================\nSET STATISTICS\n================================================================================\n\nTotal SETs: 138419\nSETs with emotions incorporated: 76175 (55.0%)\nSETs without emotions: 62244 (45.0%)\n\nTendency distribution:\ntendency\nnegative         44237\nneutral          43729\npositive         39408\nweak_negative     5594\nweak_positive     5451\nName: count, dtype: int64\n\nEmotion count distribution:\nemotion_count\n0     46467\n1     26668\n2     14504\n5     12971\n3     10829\n4      6716\n8      3701\n9      3452\n7      2508\n11     1566\nName: count, dtype: int64\n\nText length comparison:\nOriginal avg length: 592 chars\nSET avg length: 622 chars\nAvg increase: 31 chars\n\n================================================================================\nSAMPLE SENTENCE-EMOTION TREES\n================================================================================\n\nPOSITIVE Examples with Emotions:\n--------------------------------------------------------------------------------\nOriginal: Everynight I go back to when I was a little kid dealing with the abuse and trauma, sometimes even the not so bad stuff but its really confusing, becau...\n\nSET: Everynight I go back to when I was a little kid dealing with the abuse and trauma, sometimes even the not so bad stuff but its really confusing, because I feel like Im like 5 or 6 and people will be trying to talk to me and realize whats happened, sometimes I can even be in between is that normal....\n\nStats:\n  ES: 0.294 | CS_ECR: 0.294\n  Tendency: positive\n  Emotions: 5\n  PECK: 5, NECK: 2\n\nNEGATIVE Examples with Emotions:\n--------------------------------------------------------------------------------\nOriginal: PTSD from a psychotic episode?. Over the past two weeks, I experienced a psychotic episode that was induced by prescription medication. Let me tell yo...\n\nSET: PTSD from a psychotic episode?. Over the past two weeks, I experienced a psychotic episode that was induced by prescription medication. Let me tell you, it was absolute hell on earth. Extreme highs and lows, explosive anger, inability to function, concentrate, began hearing things, believing someone...\n\nStats:\n  ES: -0.795 | CS_ECR: 0.795\n  Tendency: negative\n  Emotions: 8\n  PECK: 3, NECK: 8\n\nNEUTRAL Examples with Emotions:\n--------------------------------------------------------------------------------\nOriginal: How did you find the strength/motivation to finally decide to help yourself.. How did you finally decide that it was up to yourself to take action and...\n\nSET: How did you find the strength/motivation to finally decide to help yourself.. How did you finally decide that it was up to yourself to take action and get help. I feel like a lot of us are stuck in a place where we feel weak if we want to seek help, or our ADHD kicks in and decides that we dont need...\n\nStats:\n  ES: 0.067 | CS_ECR: 0.067\n  Tendency: weak_positive\n  Emotions: 7\n  PECK: 7, NECK: 3\n\n✅ Saved: mental_health_with_sets.csv\n\n================================================================================\n✅ Step 9 complete!\n================================================================================\n\nDataset with SETs ready: 138419 posts\n  - Original text preserved\n  - SETs with emotion annotations created\n  - Ready for BERT training\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================================================\n# STEP 10: PREPARE DATA FOR BERT TRAINING\n# ============================================================================\n\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"=\"*80)\nprint(\"STEP 10: PREPARE DATA FOR BERT TRAINING\")\nprint(\"=\"*80)\n\n# Check device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\n🖥️  Device: {device}\")\nif device.type == 'cuda':\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# Step 10.1: Train/Val/Test Split\nprint(\"\\n\" + \"-\"*80)\nprint(\"10.1: CREATING TRAIN/VAL/TEST SPLITS\")\nprint(\"-\"*80)\n\n# 70% train, 15% val, 15% test\ntrain_df, temp_df = train_test_split(\n    sets_df,\n    test_size=0.3,\n    random_state=42,\n    stratify=sets_df['label_numeric']\n)\n\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=0.5,  # 0.5 of 30% = 15% each\n    random_state=42,\n    stratify=temp_df['label_numeric']\n)\n\nprint(f\"Train set: {len(train_df):,} posts ({len(train_df)/len(sets_df)*100:.1f}%)\")\nprint(f\"Val set:   {len(val_df):,} posts ({len(val_df)/len(sets_df)*100:.1f}%)\")\nprint(f\"Test set:  {len(test_df):,} posts ({len(test_df)/len(sets_df)*100:.1f}%)\")\n\nprint(\"\\nLabel distribution in train:\")\nprint(train_df['label'].value_counts())\n\nprint(\"\\nLabel distribution in val:\")\nprint(val_df['label'].value_counts())\n\nprint(\"\\nLabel distribution in test:\")\nprint(test_df['label'].value_counts())\n\n# Save splits\ntrain_df.to_csv('train_set.csv', index=False)\nval_df.to_csv('val_set.csv', index=False)\ntest_df.to_csv('test_set.csv', index=False)\nprint(\"\\n✅ Saved train/val/test splits\")\n\n# Step 10.2: Load BERT Tokenizer\nprint(\"\\n\" + \"-\"*80)\nprint(\"10.2: LOADING BERT TOKENIZER\")\nprint(\"-\"*80)\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nprint(\"✅ Loaded: bert-base-uncased tokenizer\")\n\n# Test tokenization\nsample_text = train_df.iloc[0]['original_text']\ntokens = tokenizer.tokenize(sample_text[:100])\nprint(f\"\\nSample tokenization:\")\nprint(f\"Text: {sample_text[:100]}...\")\nprint(f\"Tokens ({len(tokens)}): {tokens[:10]}...\")\n\n# Step 10.3: Create PyTorch Dataset Class\nprint(\"\\n\" + \"-\"*80)\nprint(\"10.3: CREATING PYTORCH DATASETS\")\nprint(\"-\"*80)\n\nclass MentalHealthDataset(Dataset):\n    \"\"\"\n    PyTorch Dataset for Mental Health Text\n    Can use either original text or SET\n    \"\"\"\n\n    def __init__(self, dataframe, tokenizer, max_length=128, use_set=False):\n        \"\"\"\n        Args:\n            dataframe: DataFrame with columns\n            tokenizer: BERT tokenizer\n            max_length: max sequence length\n            use_set: if True use SET, else use original_text\n        \"\"\"\n        self.data = dataframe.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.use_set = use_set\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n\n        # Choose text source\n        if self.use_set:\n            text = row['SET']\n        else:\n            text = row['original_text']\n\n        # Tokenize\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(row['label_numeric'], dtype=torch.long),\n            'ES': torch.tensor(row['ES'], dtype=torch.float),\n            'CS_ECR': torch.tensor(row['CS_ECR'], dtype=torch.float)\n        }\n\n# Create datasets (start with original text for baseline BERT)\nprint(\"\\nCreating datasets (using original_text)...\")\n\nmax_length = 128  # Standard BERT max length\n\ntrain_dataset = MentalHealthDataset(train_df, tokenizer, max_length, use_set=False)\nval_dataset = MentalHealthDataset(val_df, tokenizer, max_length, use_set=False)\ntest_dataset = MentalHealthDataset(test_df, tokenizer, max_length, use_set=False)\n\nprint(f\"✅ Train dataset: {len(train_dataset):,} samples\")\nprint(f\"✅ Val dataset:   {len(val_dataset):,} samples\")\nprint(f\"✅ Test dataset:  {len(test_dataset):,} samples\")\n\n# Step 10.4: Create DataLoaders\nprint(\"\\n\" + \"-\"*80)\nprint(\"10.4: CREATING DATALOADERS\")\nprint(\"-\"*80)\n\n# Batch size based on GPU memory\nif device.type == 'cuda':\n    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n    if gpu_memory_gb >= 15:\n        batch_size = 32\n    elif gpu_memory_gb >= 8:\n        batch_size = 16\n    else:\n        batch_size = 8\nelse:\n    batch_size = 8\n\nprint(f\"Batch size: {batch_size}\")\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True if device.type == 'cuda' else False\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True if device.type == 'cuda' else False\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True if device.type == 'cuda' else False\n)\n\nprint(f\"✅ Train loader: {len(train_loader):,} batches\")\nprint(f\"✅ Val loader:   {len(val_loader):,} batches\")\nprint(f\"✅ Test loader:  {len(test_loader):,} batches\")\n\n# Step 10.5: Test Data Loading\nprint(\"\\n\" + \"-\"*80)\nprint(\"10.5: TESTING DATA LOADING\")\nprint(\"-\"*80)\n\nprint(\"Loading one batch...\")\nsample_batch = next(iter(train_loader))\n\nprint(f\"\\nBatch shapes:\")\nprint(f\"  input_ids: {sample_batch['input_ids'].shape}\")\nprint(f\"  attention_mask: {sample_batch['attention_mask'].shape}\")\nprint(f\"  labels: {sample_batch['label'].shape}\")\nprint(f\"  ES: {sample_batch['ES'].shape}\")\nprint(f\"  CS_ECR: {sample_batch['CS_ECR'].shape}\")\n\nprint(f\"\\nLabel distribution in batch:\")\nlabels_in_batch = sample_batch['label'].numpy()\nunique, counts = np.unique(labels_in_batch, return_counts=True)\nfor label_num, count in zip(unique, counts):\n    label_name = {0: 'positive', 1: 'negative', 2: 'neutral'}[label_num]\n    print(f\"  {label_name}: {count}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ Step 10 complete!\")\nprint(\"=\"*80)\n\nprint(f\"\\n📦 Data ready for training:\")\nprint(f\"  - Train: {len(train_dataset):,} samples ({len(train_loader):,} batches)\")\nprint(f\"  - Val:   {len(val_dataset):,} samples ({len(val_loader):,} batches)\")\nprint(f\"  - Test:  {len(test_dataset):,} samples ({len(test_loader):,} batches)\")\nprint(f\"  - Batch size: {batch_size}\")\nprint(f\"  - Max length: {max_length} tokens\")\nprint(f\"  - Device: {device}\")\n\nprint(\"\\n🎯 Ready for Step 11: Build and Train BERT Model!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["98681a8baf064227bd83fbd9fd6847eb","6ae95ab5b8c74836a5de0e7af7672d46","38a9799cf0c84359b90f457e7b117d6e","e3057df6386a4a11841badcb92dff2db","3d901313bf624f348c8804689952665b","143f13ad38364a4eada30e96ec2bc4a4","a601060d2106464c90d91a04ec234014","bef68cba8960411fa9d550a5bb903927","fb72a587b93a4848b5b195038eeef7f3","c3ea51cafceb492e96279adc1ce523d6","e9d1253243c4424d9257795f2e241257","5b17c9f6d7d241a0b2fc59a295e4e39c","32d72f6f00e449f1a0889bc77716100a","65c41f31ee484abe8f51a9535a0ae957","f10772ac63f64158884adfc5312f94b4","a7d3d337418f4a539d33a9330cfc9d63","1c2fe9317b6b4f8ab2dcec54b2f6a788","b092bf84917b44deab4e6ef8fd921a08","62128d93dd22407eba530de068606cbe","e4f7f989e2b64f1b9761961f386ad1ce","d82372019b4e49ce8a851ff0e8645c50","a5cda441200c492584fc118d258800d6","b6eb8686c752442ea8328ddf13d41756","d72f518b9cdc476b92f66cbc47621f83","17dcea40291a49b8a58f7e02b66d4ae5","67db39a8121340b99c2304f23c7efbc6","38950edb7e1941a0acb6ac677710918a","fb607abad180423c8ae4a8f3b9ec3055","2cfb8218f9dd4fbb93af3048e257311c","70c5ee6653ca4fddb9d3b19d937c2285","d2f378852a0e4308864ccb418510d7f4","8d708fc032ee4fb0b5636d42f19cc80e","e7ac0ffa95cf4b5298387d2baacd961c","40bb3619d6e74753a1ecbab111797912","f3eba78c98a34f60881a092c82f6fd7d","d860a139c9fa453fb654ab63dcffc194","e838ea9c6cb3420789311d81344256eb","28423e6002e14328b59d4f7387bf4fe7","b42d0f37e1e34c048eddd0a6b1b69546","f6ac2dda158f4c1797a8f659e91e4172","88b94d514a4d4b7baae0ef192098c5f7","1fa3968161e94c5487e253d6a0362b89","7d4e1cd0fa2f410fae9d76275915db42","3b29d0c39eb24a9b85d9606b17f94446"]},"id":"k1-LKyMXzFbt","outputId":"3e8c4f74-cd8e-4c7b-ed67-0c5979fb9c12","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T04:12:03.358253Z","iopub.execute_input":"2025-11-10T04:12:03.358535Z","iopub.status.idle":"2025-11-10T04:12:21.472347Z","shell.execute_reply.started":"2025-11-10T04:12:03.358515Z","shell.execute_reply":"2025-11-10T04:12:21.471294Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTEP 10: PREPARE DATA FOR BERT TRAINING\n================================================================================\n\n🖥️  Device: cuda\n   GPU: Tesla T4\n   Memory: 15.8 GB\n\n--------------------------------------------------------------------------------\n10.1: CREATING TRAIN/VAL/TEST SPLITS\n--------------------------------------------------------------------------------\nTrain set: 96,893 posts (70.0%)\nVal set:   20,763 posts (15.0%)\nTest set:  20,763 posts (15.0%)\n\nLabel distribution in train:\nlabel\nneutral     34125\nnegative    33857\npositive    28911\nName: count, dtype: int64\n\nLabel distribution in val:\nlabel\nneutral     7313\nnegative    7255\npositive    6195\nName: count, dtype: int64\n\nLabel distribution in test:\nlabel\nneutral     7313\nnegative    7255\npositive    6195\nName: count, dtype: int64\n\n✅ Saved train/val/test splits\n\n--------------------------------------------------------------------------------\n10.2: LOADING BERT TOKENIZER\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98a47f7347484808a8c2cb16a201a780"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"722dcbbce1a24981a2e9396d99b1592e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"985e099b68d14eef9857a09ee59db868"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5af228a2e8744ae9045c880825c263c"}},"metadata":{}},{"name":"stdout","text":"✅ Loaded: bert-base-uncased tokenizer\n\nSample tokenization:\nText: POCD flare of the day......\nTokens (9): ['po', '##cd', 'flare', 'of', 'the', 'day', '.', '.', '.']...\n\n--------------------------------------------------------------------------------\n10.3: CREATING PYTORCH DATASETS\n--------------------------------------------------------------------------------\n\nCreating datasets (using original_text)...\n✅ Train dataset: 96,893 samples\n✅ Val dataset:   20,763 samples\n✅ Test dataset:  20,763 samples\n\n--------------------------------------------------------------------------------\n10.4: CREATING DATALOADERS\n--------------------------------------------------------------------------------\nBatch size: 32\n✅ Train loader: 3,028 batches\n✅ Val loader:   649 batches\n✅ Test loader:  649 batches\n\n--------------------------------------------------------------------------------\n10.5: TESTING DATA LOADING\n--------------------------------------------------------------------------------\nLoading one batch...\n\nBatch shapes:\n  input_ids: torch.Size([32, 128])\n  attention_mask: torch.Size([32, 128])\n  labels: torch.Size([32])\n  ES: torch.Size([32])\n  CS_ECR: torch.Size([32])\n\nLabel distribution in batch:\n  positive: 8\n  negative: 11\n  neutral: 13\n\n================================================================================\n✅ Step 10 complete!\n================================================================================\n\n📦 Data ready for training:\n  - Train: 96,893 samples (3,028 batches)\n  - Val:   20,763 samples (649 batches)\n  - Test:  20,763 samples (649 batches)\n  - Batch size: 32\n  - Max length: 128 tokens\n  - Device: cuda\n\n🎯 Ready for Step 11: Build and Train BERT Model!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ============================================================================\n# STEP 10 COMPLETION: VERIFY DATA IS READY\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"STEP 10: FINAL VERIFICATION\")\nprint(\"=\"*80)\n\n# Check if all variables exist\nprint(\"\\n✓ Checking required variables...\")\n\nrequired_vars = {\n    'sets_df': 'Dataset with SETs',\n    'train_df': 'Training data',\n    'val_df': 'Validation data',\n    'test_df': 'Test data',\n    'EDD': 'Emotion Dimension Dictionary',\n    'ecr': 'ECR System',\n    'tokenizer': 'BERT Tokenizer'\n}\n\nall_ready = True\nfor var_name, description in required_vars.items():\n    if var_name in globals():\n        print(f\"  ✅ {description} ({var_name}): Ready\")\n    else:\n        print(f\"  ❌ {description} ({var_name}): Missing\")\n        all_ready = False\n\nif not all_ready:\n    print(\"\\n⚠️ Some variables are missing. Please run previous steps.\")\nelse:\n    print(\"\\n✅ All required variables present!\")\n\n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"DATASET SUMMARY\")\n    print(\"=\"*80)\n    print(f\"Total dataset: {len(sets_df):,} posts\")\n    print(f\"  - Train: {len(train_df):,} ({len(train_df)/len(sets_df)*100:.1f}%)\")\n    print(f\"  - Val:   {len(val_df):,} ({len(val_df)/len(sets_df)*100:.1f}%)\")\n    print(f\"  - Test:  {len(test_df):,} ({len(test_df)/len(sets_df)*100:.1f}%)\")\n\n    print(f\"\\nLabel distribution:\")\n    print(sets_df['label'].value_counts())\n\n    print(f\"\\nCondition distribution:\")\n    print(sets_df['condition'].value_counts())\n\n    print(f\"\\nSETs with emotions: {sets_df['used_ecr'].sum():,} ({sets_df['used_ecr'].sum()/len(sets_df)*100:.1f}%)\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"✅ Step 10 COMPLETE - Ready for BERT Training!\")\n    print(\"=\"*80)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOaeOa6SzZ02","outputId":"e9099a83-d8ed-42ea-dc8c-c5b1da84e20d","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T04:12:29.260977Z","iopub.execute_input":"2025-11-10T04:12:29.262490Z","iopub.status.idle":"2025-11-10T04:12:29.288005Z","shell.execute_reply.started":"2025-11-10T04:12:29.262459Z","shell.execute_reply":"2025-11-10T04:12:29.287326Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTEP 10: FINAL VERIFICATION\n================================================================================\n\n✓ Checking required variables...\n  ✅ Dataset with SETs (sets_df): Ready\n  ✅ Training data (train_df): Ready\n  ✅ Validation data (val_df): Ready\n  ✅ Test data (test_df): Ready\n  ✅ Emotion Dimension Dictionary (EDD): Ready\n  ✅ ECR System (ecr): Ready\n  ✅ BERT Tokenizer (tokenizer): Ready\n\n✅ All required variables present!\n\n================================================================================\nDATASET SUMMARY\n================================================================================\nTotal dataset: 138,419 posts\n  - Train: 96,893 (70.0%)\n  - Val:   20,763 (15.0%)\n  - Test:  20,763 (15.0%)\n\nLabel distribution:\nlabel\nneutral     48751\nnegative    48367\npositive    41301\nName: count, dtype: int64\n\nCondition distribution:\ncondition\nOCD           38576\nADHD          34933\nPTSD          21844\nAspergers     21533\nDepression    21533\nName: count, dtype: int64\n\nSETs with emotions: 76,175 (55.0%)\n\n================================================================================\n✅ Step 10 COMPLETE - Ready for BERT Training!\n================================================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ============================================================================\n# STEP 11: BUILD AND TRAIN BASELINE BERT MODEL (FIXED)\n# ============================================================================\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertModel, BertTokenizer, get_linear_schedule_with_warmup\nfrom torch.optim import AdamW  # Import from torch.optim instead\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport time\n\nprint(\"=\"*80)\nprint(\"STEP 11: BASELINE BERT MODEL TRAINING\")\nprint(\"=\"*80)\n\n# Check device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\n🖥️  Device: {device}\")\nif device.type == 'cuda':\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n\n# ============================================================================\n# 11.1: DEFINE BERT CLASSIFIER\n# ============================================================================\n\nclass BERTClassifier(nn.Module):\n    def __init__(self, n_classes=3, dropout=0.3):\n        super(BERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        output = self.dropout(pooled_output)\n        logits = self.classifier(output)\n        return logits\n\nprint(\"\\nInitializing BERT model...\")\nmodel = BERTClassifier(n_classes=3, dropout=0.3)\nmodel = model.to(device)\n\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"✅ Model initialized\")\nprint(f\"   Total parameters: {total_params:,}\")\nprint(f\"   Trainable parameters: {trainable_params:,}\")\n\n# ============================================================================\n# 11.2: SETUP TRAINING\n# ============================================================================\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"TRAINING CONFIGURATION\")\nprint(\"-\"*80)\n\nepochs = 3\nlearning_rate = 2e-5\nbatch_size = 16\n\noptimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\ncriterion = nn.CrossEntropyLoss()\ntotal_steps = len(train_loader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\nprint(f\"Epochs: {epochs}\")\nprint(f\"Learning rate: {learning_rate}\")\nprint(f\"Batch size: {batch_size}\")\nprint(f\"Total training steps: {total_steps:,}\")\nprint(f\"Optimizer: AdamW\")\nprint(f\"Loss function: CrossEntropyLoss\")\n\n# ============================================================================\n# 11.3: TRAINING FUNCTIONS\n# ============================================================================\n\ndef train_epoch(model, data_loader, criterion, optimizer, scheduler, device):\n    \"\"\"Train for one epoch\"\"\"\n    model.train()\n    total_loss = 0\n    predictions = []\n    true_labels = []\n\n    progress_bar = tqdm(data_loader, desc='Training')\n\n    for batch in progress_bar:\n        # Move to device\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        # Forward pass\n        optimizer.zero_grad()\n        logits = model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n\n        # Backward pass\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n\n        # Track metrics\n        total_loss += loss.item()\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        predictions.extend(preds)\n        true_labels.extend(labels.cpu().numpy())\n\n        # Update progress bar\n        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n    avg_loss = total_loss / len(data_loader)\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions, average='macro')\n\n    return avg_loss, accuracy, f1\n\ndef evaluate(model, data_loader, criterion, device):\n    \"\"\"Evaluate model\"\"\"\n    model.eval()\n    total_loss = 0\n    predictions = []\n    true_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc='Evaluating'):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n\n            total_loss += loss.item()\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            predictions.extend(preds)\n            true_labels.extend(labels.cpu().numpy())\n\n    avg_loss = total_loss / len(data_loader)\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions, average='macro')\n\n    return avg_loss, accuracy, f1, predictions, true_labels\n\n# ============================================================================\n# 11.4: TRAIN THE MODEL\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*80)\nprint(f\"Training on {len(train_dataset):,} samples\")\nprint(f\"Validating on {len(val_dataset):,} samples\")\nprint(f\"Estimated time: ~{epochs * 10} minutes on GPU\\n\")\n\nbest_val_f1 = 0\ntraining_stats = []\nstart_time = time.time()\n\nfor epoch in range(epochs):\n    print(f\"\\n{'='*80}\")\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    print(f\"{'='*80}\")\n\n    epoch_start = time.time()\n\n    # Train\n    train_loss, train_acc, train_f1 = train_epoch(\n        model, train_loader, criterion, optimizer, scheduler, device\n    )\n\n    print(f\"\\nTraining Results:\")\n    print(f\"  Loss:     {train_loss:.4f}\")\n    print(f\"  Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n    print(f\"  F1-Score: {train_f1:.4f}\")\n\n    # Validate\n    val_loss, val_acc, val_f1, _, _ = evaluate(\n        model, val_loader, criterion, device\n    )\n\n    print(f\"\\nValidation Results:\")\n    print(f\"  Loss:     {val_loss:.4f}\")\n    print(f\"  Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n    print(f\"  F1-Score: {val_f1:.4f}\")\n\n    epoch_time = time.time() - epoch_start\n    print(f\"\\nEpoch completed in {epoch_time/60:.1f} minutes\")\n\n    # Save best model\n    if val_f1 > best_val_f1:\n        best_val_f1 = val_f1\n        torch.save(model.state_dict(), 'best_baseline_bert.pt')\n        print(f\"💾 Best model saved! (F1: {best_val_f1:.4f})\")\n\n    # Track stats\n    training_stats.append({\n        'epoch': epoch + 1,\n        'train_loss': train_loss,\n        'train_acc': train_acc,\n        'train_f1': train_f1,\n        'val_loss': val_loss,\n        'val_acc': val_acc,\n        'val_f1': val_f1,\n        'epoch_time_min': epoch_time/60\n    })\n\ntotal_time = time.time() - start_time\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ TRAINING COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"Total training time: {total_time/60:.1f} minutes\")\nprint(f\"Best validation F1-Score: {best_val_f1:.4f}\")\n\n# Save training history\nimport pandas as pd\nhistory_df = pd.DataFrame(training_stats)\nhistory_df.to_csv('baseline_bert_training_history.csv', index=False)\nprint(\"✅ Training history saved: baseline_bert_training_history.csv\")\n\n# Display training history\nprint(\"\\n\" + \"-\"*80)\nprint(\"TRAINING HISTORY\")\nprint(\"-\"*80)\nprint(history_df.to_string(index=False))\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ Step 11 complete!\")\nprint(\"=\"*80)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["22190c9104bd43c5b0123b1fece95372","2575a707822742f8bfd856145129221b","9f6839dc14114b019368a869d3f3419c","9d75f0578c87440188d87a570f477778","6f352c4457d84c2a80c2ad83292f8810","c6ac6ee937874b61b625bb79df11b762","cd999bd424674ef8911817665e443c72","f37957b04ea44b989843607823e6d2e5","9face57395e24b28a50f108aaadf3a9c","acb2b7cb46de4fa982491f3c3811fea3","9fca8bf82ad54c499e038cfbbf4d1c9c","e5541c328cf04878b9bafd39d9dbdfd8","2fd57140bde64111849fe9242729dcc0","bfcb10e29fde4c75bda1c5ceca7a461e","ccaa49ee52e64be58883f39af027f0ea","cffde37894ee40ad93f99da16b4470ae","e17ceedf3f0e40fe9379e05c533491f5","e43cccd47fe54bb490a85985d4a5573a","85fb35b6e0724d33b8336f680052d6ff","542edad15cfa42b18eb932a31f84c24d","44b3bf94d39e4220ab0ed838242b956a","a6711ae974084662be01eb098e2a288a","cc483bf5cce44dfa88a47ef57d9f9e76","644263661e90480295e9dfc047be1861","a10f7be014f64edc9bfce9270a62f71f","81ea6e89dfae40af8542ec5e0fb92713","1b6727961702422e878cfdff33e36cd2","c0a46a2065db4fa68ca132e124c3347c","a2951b9954134a1f9b22aa0be827219d","607f78d01f0d42f88af3b283d2090d67","5647e8b8fbe5491f8fdde8f6917f20ab","c54890bb02cc48a1834c40472a61d652","bd56e626f11c40ae8897eba5dde1a2a2","265ea45ee5cf4776b2f3fa0e7ae74efd","0aca584b45ff4697a318cfbc35857faa","3427ec94327c4a90844a439d94e06dc1","ab4229af019f4db08b5df5c17a83e1ac","4d2af727a3054503814b29f2e88d2871","dac651f79e4f41beb09b0335fa839ee0","5aab0f387dc84d3e93daa9d5c73bd04d","92690f3c512a43d89ac80686aa2ad8a1","b1777b48f1024790a41d3e76816c9699","37ac065bf9e249b7931f722daf8b53c4","2d5a9363e6014defb5e6ce5796006946"]},"id":"gNvUZCyEz3_1","outputId":"0a4db8b9-a09c-455e-86ff-72e3fad72698","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T04:12:35.443785Z","iopub.execute_input":"2025-11-10T04:12:35.444057Z","iopub.status.idle":"2025-11-10T06:05:30.006181Z","shell.execute_reply.started":"2025-11-10T04:12:35.444039Z","shell.execute_reply":"2025-11-10T06:05:30.004949Z"}},"outputs":[{"name":"stderr","text":"2025-11-10 04:12:40.031057: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762747960.423916      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762747960.530447      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"================================================================================\nSTEP 11: BASELINE BERT MODEL TRAINING\n================================================================================\n\n🖥️  Device: cuda\n   GPU: Tesla T4\n\nInitializing BERT model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b438160f9d624f069317013a68c194cf"}},"metadata":{}},{"name":"stdout","text":"✅ Model initialized\n   Total parameters: 109,484,547\n   Trainable parameters: 109,484,547\n\n--------------------------------------------------------------------------------\nTRAINING CONFIGURATION\n--------------------------------------------------------------------------------\nEpochs: 3\nLearning rate: 2e-05\nBatch size: 16\nTotal training steps: 9,084\nOptimizer: AdamW\nLoss function: CrossEntropyLoss\n\n================================================================================\nSTARTING TRAINING\n================================================================================\nTraining on 96,893 samples\nValidating on 20,763 samples\nEstimated time: ~30 minutes on GPU\n\n\n================================================================================\nEpoch 1/3\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3028 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"721f6c31d3054d0986f2549626d442c3"}},"metadata":{}},{"name":"stdout","text":"\nTraining Results:\n  Loss:     0.4942\n  Accuracy: 0.8032 (80.32%)\n  F1-Score: 0.8025\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/649 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"118aa591ce804b79b9cf81a590686ba2"}},"metadata":{}},{"name":"stdout","text":"\nValidation Results:\n  Loss:     0.3476\n  Accuracy: 0.8644 (86.44%)\n  F1-Score: 0.8642\n\nEpoch completed in 37.3 minutes\n💾 Best model saved! (F1: 0.8642)\n\n================================================================================\nEpoch 2/3\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3028 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f75028a5b4d1463c99640480105bb462"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x796b6cb90180><function _MultiProcessingDataLoaderIter.__del__ at 0x796b6cb90180>\n\nTraceback (most recent call last):\nTraceback (most recent call last):\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x796b6cb90180>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1564, in _shutdown_workers\n    self._pin_memory_thread.join()\n  File \"/usr/lib/python3.11/threading.py\", line 1116, in join\n    raise RuntimeError(\"cannot join current thread\")\nRuntimeError: cannot join current thread\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n        self._shutdown_workers()self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n        if w.is_alive():if w.is_alive():\n\n           ^ ^ ^^ ^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n\n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n               ^^ ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process\n\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"\nTraining Results:\n  Loss:     0.3230\n  Accuracy: 0.8766 (87.66%)\n  F1-Score: 0.8761\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/649 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c97c38f771ba477bba7de1a88c9deef5"}},"metadata":{}},{"name":"stdout","text":"\nValidation Results:\n  Loss:     0.3280\n  Accuracy: 0.8786 (87.86%)\n  F1-Score: 0.8780\n\nEpoch completed in 37.5 minutes\n💾 Best model saved! (F1: 0.8780)\n\n================================================================================\nEpoch 3/3\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3028 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a1e6ac6627b4e818b13e8039ee7e068"}},"metadata":{}},{"name":"stdout","text":"\nTraining Results:\n  Loss:     0.2677\n  Accuracy: 0.8977 (89.77%)\n  F1-Score: 0.8972\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/649 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28a22967b7044dc58bb47a4e2a4c9311"}},"metadata":{}},{"name":"stdout","text":"\nValidation Results:\n  Loss:     0.3171\n  Accuracy: 0.8809 (88.09%)\n  F1-Score: 0.8804\n\nEpoch completed in 37.5 minutes\n💾 Best model saved! (F1: 0.8804)\n\n================================================================================\n✅ TRAINING COMPLETE!\n================================================================================\nTotal training time: 112.3 minutes\nBest validation F1-Score: 0.8804\n✅ Training history saved: baseline_bert_training_history.csv\n\n--------------------------------------------------------------------------------\nTRAINING HISTORY\n--------------------------------------------------------------------------------\n epoch  train_loss  train_acc  train_f1  val_loss  val_acc   val_f1  epoch_time_min\n     1    0.494159   0.803154  0.802456  0.347576 0.864374 0.864249       37.255349\n     2    0.322951   0.876616  0.876128  0.327971 0.878630 0.878015       37.497965\n     3    0.267671   0.897681  0.897174  0.317112 0.880894 0.880377       37.480924\n\n================================================================================\n✅ Step 11 complete!\n================================================================================\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ============================================================================\n# STEP 12: ECR-BERT MODEL WITH SELF-ADAPTIVE FUSION\n# ============================================================================\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertModel, BertTokenizer, get_linear_schedule_with_warmup\nfrom torch.optim import AdamW\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport time\n\nprint(\"=\"*80)\nprint(\"STEP 12: ECR-BERT MODEL (WITH EMOTION-COGNITIVE REASONING)\")\nprint(\"=\"*80)\n\n# ============================================================================\n# 12.1: SELF-ADAPTIVE FUSION ALGORITHM\n# ============================================================================\n\nclass SelfAdaptiveFusion:\n    \"\"\"\n    Implements Algorithm 2 from the paper\n    Selects PECK or NECK based on ECR and BERT predictions\n    \"\"\"\n\n    def __init__(self, threshold=0.3):\n        self.threshold = threshold\n\n    def fuse(self, ES, CS_ECR, CS_BERT, bert_prediction):\n        \"\"\"\n        Algorithm 2: Self-Adaptive Fusion\n\n        Args:\n            ES: Emotion Score from ECR (-1 to 1)\n            CS_ECR: Confidence Score from ECR (0 to 1)\n            CS_BERT: Confidence Score from BERT (0 to 1)\n            bert_prediction: BERT's predicted label (0=pos, 1=neg, 2=neutral)\n\n        Returns:\n            decision: 'PECK', 'NECK', or 'NONE'\n        \"\"\"\n\n        # If CS_ECR >= threshold, use ECR result\n        if CS_ECR >= self.threshold:\n            if ES > 0:\n                return 'PECK'\n            elif ES < 0:\n                return 'NECK'\n            else:\n                return 'NONE'\n\n        # Otherwise, compare CS_ECR and CS_BERT\n        delta = CS_BERT - CS_ECR\n\n        if delta < 0:\n            # ECR is more confident\n            if ES > 0:\n                return 'PECK'\n            elif ES < 0:\n                return 'NECK'\n            else:\n                return 'NONE'\n        else:\n            # BERT is more confident\n            if bert_prediction == 0:  # positive\n                return 'PECK'\n            elif bert_prediction == 1:  # negative\n                return 'NECK'\n            else:  # neutral\n                return 'NONE'\n\nprint(\"\\n✅ Self-Adaptive Fusion Algorithm implemented\")\nprint(f\"   Threshold: {0.3}\")\n\n# ============================================================================\n# 12.2: ECR-BERT DATASET (WITH SETS)\n# ============================================================================\n\nclass ECRBERTDataset(Dataset):\n    \"\"\"\n    Dataset that uses Sentence-Emotion Trees (SETs)\n    \"\"\"\n\n    def __init__(self, dataframe, tokenizer, max_length=128):\n        self.data = dataframe.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n\n        # Use SET (Sentence-Emotion Tree)\n        text = row['SET']\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(row['label_numeric'], dtype=torch.long),\n            'ES': torch.tensor(row['ES'], dtype=torch.float),\n            'CS_ECR': torch.tensor(row['CS_ECR'], dtype=torch.float)\n        }\n\n# Create ECR-BERT datasets (using SETs)\nprint(\"\\n\" + \"-\"*80)\nprint(\"12.2: CREATING ECR-BERT DATASETS\")\nprint(\"-\"*80)\n\nmax_length = 128\nbatch_size = 16\n\ntrain_dataset_ecr = ECRBERTDataset(train_df, tokenizer, max_length)\nval_dataset_ecr = ECRBERTDataset(val_df, tokenizer, max_length)\ntest_dataset_ecr = ECRBERTDataset(test_df, tokenizer, max_length)\n\ntrain_loader_ecr = DataLoader(\n    train_dataset_ecr,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=2\n)\n\nval_loader_ecr = DataLoader(\n    val_dataset_ecr,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=2\n)\n\ntest_loader_ecr = DataLoader(\n    test_dataset_ecr,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=2\n)\n\nprint(f\"✅ ECR-BERT Datasets created (using SETs)\")\nprint(f\"   Train: {len(train_dataset_ecr):,} samples ({len(train_loader_ecr):,} batches)\")\nprint(f\"   Val:   {len(val_dataset_ecr):,} samples ({len(val_loader_ecr):,} batches)\")\nprint(f\"   Test:  {len(test_dataset_ecr):,} samples ({len(test_loader_ecr):,} batches)\")\n\n# ============================================================================\n# 12.3: ECR-BERT MODEL\n# ============================================================================\n\nclass ECRBERTClassifier(nn.Module):\n    \"\"\"\n    ECR-BERT: BERT enhanced with Emotion-Cognitive Reasoning\n    \"\"\"\n\n    def __init__(self, n_classes=3, dropout=0.3):\n        super(ECRBERTClassifier, self).__init__()\n\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.dropout = nn.Dropout(dropout)\n\n        # Main classifier\n        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n\n        # Additional layer for ECR features (optional enhancement)\n        # This can incorporate ES and CS_ECR if needed\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        output = self.dropout(pooled_output)\n        logits = self.classifier(output)\n        return logits\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"12.3: INITIALIZING ECR-BERT MODEL\")\nprint(\"-\"*80)\n\n# Initialize ECR-BERT model\nmodel_ecr = ECRBERTClassifier(n_classes=3, dropout=0.3)\nmodel_ecr = model_ecr.to(device)\n\ntotal_params = sum(p.numel() for p in model_ecr.parameters())\ntrainable_params = sum(p.numel() for p in model_ecr.parameters() if p.requires_grad)\n\nprint(f\"✅ ECR-BERT Model initialized\")\nprint(f\"   Total parameters: {total_params:,}\")\nprint(f\"   Trainable parameters: {trainable_params:,}\")\nprint(f\"   Difference from baseline: Emotion-enhanced input (SETs)\")\n\n# ============================================================================\n# 12.4: TRAINING SETUP\n# ============================================================================\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"12.4: ECR-BERT TRAINING CONFIGURATION\")\nprint(\"-\"*80)\n\nepochs_ecr = 3\nlearning_rate_ecr = 2e-5\n\noptimizer_ecr = AdamW(model_ecr.parameters(), lr=learning_rate_ecr, eps=1e-8)\ncriterion_ecr = nn.CrossEntropyLoss()\ntotal_steps_ecr = len(train_loader_ecr) * epochs_ecr\nscheduler_ecr = get_linear_schedule_with_warmup(\n    optimizer_ecr,\n    num_warmup_steps=0,\n    num_training_steps=total_steps_ecr\n)\n\nprint(f\"Epochs: {epochs_ecr}\")\nprint(f\"Learning rate: {learning_rate_ecr}\")\nprint(f\"Batch size: {batch_size}\")\nprint(f\"Total training steps: {total_steps_ecr:,}\")\nprint(f\"Using: Sentence-Emotion Trees (SETs)\")\n\n# ============================================================================\n# 12.5: TRAIN ECR-BERT\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"12.5: TRAINING ECR-BERT MODEL\")\nprint(\"=\"*80)\nprint(f\"Training with emotion-enhanced text (SETs)\")\nprint(f\"Estimated time: ~{epochs_ecr * 10} minutes on GPU\\n\")\n\nbest_val_f1_ecr = 0\ntraining_stats_ecr = []\nstart_time_ecr = time.time()\n\nfor epoch in range(epochs_ecr):\n    print(f\"\\n{'='*80}\")\n    print(f\"Epoch {epoch + 1}/{epochs_ecr}\")\n    print(f\"{'='*80}\")\n\n    epoch_start = time.time()\n\n    # Train\n    train_loss, train_acc, train_f1 = train_epoch(\n        model_ecr, train_loader_ecr, criterion_ecr, optimizer_ecr, scheduler_ecr, device\n    )\n\n    print(f\"\\nTraining Results:\")\n    print(f\"  Loss:     {train_loss:.4f}\")\n    print(f\"  Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n    print(f\"  F1-Score: {train_f1:.4f}\")\n\n    # Validate\n    val_loss, val_acc, val_f1, _, _ = evaluate(\n        model_ecr, val_loader_ecr, criterion_ecr, device\n    )\n\n    print(f\"\\nValidation Results:\")\n    print(f\"  Loss:     {val_loss:.4f}\")\n    print(f\"  Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n    print(f\"  F1-Score: {val_f1:.4f}\")\n\n    epoch_time = time.time() - epoch_start\n    print(f\"\\nEpoch completed in {epoch_time/60:.1f} minutes\")\n\n    # Save best model\n    if val_f1 > best_val_f1_ecr:\n        best_val_f1_ecr = val_f1\n        torch.save(model_ecr.state_dict(), 'best_ecr_bert.pt')\n        print(f\"💾 Best ECR-BERT model saved! (F1: {best_val_f1_ecr:.4f})\")\n\n    # Track stats\n    training_stats_ecr.append({\n        'epoch': epoch + 1,\n        'train_loss': train_loss,\n        'train_acc': train_acc,\n        'train_f1': train_f1,\n        'val_loss': val_loss,\n        'val_acc': val_acc,\n        'val_f1': val_f1,\n        'epoch_time_min': epoch_time/60\n    })\n\ntotal_time_ecr = time.time() - start_time_ecr\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ ECR-BERT TRAINING COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"Total training time: {total_time_ecr/60:.1f} minutes\")\nprint(f\"Best validation F1-Score: {best_val_f1_ecr:.4f}\")\n\n# Save training history\nhistory_df_ecr = pd.DataFrame(training_stats_ecr)\nhistory_df_ecr.to_csv('ecr_bert_training_history.csv', index=False)\nprint(\"✅ Training history saved: ecr_bert_training_history.csv\")\n\n# Display training history\nprint(\"\\n\" + \"-\"*80)\nprint(\"ECR-BERT TRAINING HISTORY\")\nprint(\"-\"*80)\nprint(history_df_ecr.to_string(index=False))\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ Step 12 complete!\")\nprint(\"=\"*80)","metadata":{"id":"2UB9Hvd_z3_K","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T06:20:56.183304Z","iopub.execute_input":"2025-11-10T06:20:56.183683Z","iopub.status.idle":"2025-11-10T08:24:07.506890Z","shell.execute_reply.started":"2025-11-10T06:20:56.183625Z","shell.execute_reply":"2025-11-10T08:24:07.505694Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTEP 12: ECR-BERT MODEL (WITH EMOTION-COGNITIVE REASONING)\n================================================================================\n\n✅ Self-Adaptive Fusion Algorithm implemented\n   Threshold: 0.3\n\n--------------------------------------------------------------------------------\n12.2: CREATING ECR-BERT DATASETS\n--------------------------------------------------------------------------------\n✅ ECR-BERT Datasets created (using SETs)\n   Train: 96,893 samples (6,056 batches)\n   Val:   20,763 samples (1,298 batches)\n   Test:  20,763 samples (1,298 batches)\n\n--------------------------------------------------------------------------------\n12.3: INITIALIZING ECR-BERT MODEL\n--------------------------------------------------------------------------------\n✅ ECR-BERT Model initialized\n   Total parameters: 109,484,547\n   Trainable parameters: 109,484,547\n   Difference from baseline: Emotion-enhanced input (SETs)\n\n--------------------------------------------------------------------------------\n12.4: ECR-BERT TRAINING CONFIGURATION\n--------------------------------------------------------------------------------\nEpochs: 3\nLearning rate: 2e-05\nBatch size: 16\nTotal training steps: 18,168\nUsing: Sentence-Emotion Trees (SETs)\n\n================================================================================\n12.5: TRAINING ECR-BERT MODEL\n================================================================================\nTraining with emotion-enhanced text (SETs)\nEstimated time: ~30 minutes on GPU\n\n\n================================================================================\nEpoch 1/3\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/6056 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d40ab35b8fe44cb3bb3b9547937875ae"}},"metadata":{}},{"name":"stdout","text":"\nTraining Results:\n  Loss:     0.3885\n  Accuracy: 0.8429 (84.29%)\n  F1-Score: 0.8420\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/1298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19ef02d9a0c94b9d9dc3a56a8a47e8c8"}},"metadata":{}},{"name":"stdout","text":"\nValidation Results:\n  Loss:     0.3247\n  Accuracy: 0.8690 (86.90%)\n  F1-Score: 0.8685\n\nEpoch completed in 40.8 minutes\n💾 Best ECR-BERT model saved! (F1: 0.8685)\n\n================================================================================\nEpoch 2/3\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/6056 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70ac70d4dbc24c21b1d617d1823a86c7"}},"metadata":{}},{"name":"stdout","text":"\nTraining Results:\n  Loss:     0.2982\n  Accuracy: 0.8847 (88.47%)\n  F1-Score: 0.8840\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/1298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b560d191da544b6a8dfbb547622d7c0"}},"metadata":{}},{"name":"stdout","text":"\nValidation Results:\n  Loss:     0.3218\n  Accuracy: 0.8797 (87.97%)\n  F1-Score: 0.8791\n\nEpoch completed in 40.9 minutes\n💾 Best ECR-BERT model saved! (F1: 0.8791)\n\n================================================================================\nEpoch 3/3\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/6056 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8578029d6e8b48819caba0c96d7d671c"}},"metadata":{}},{"name":"stdout","text":"\nTraining Results:\n  Loss:     0.2362\n  Accuracy: 0.9116 (91.16%)\n  F1-Score: 0.9111\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/1298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c92a3424b504e46a37b90b907d048b0"}},"metadata":{}},{"name":"stdout","text":"\nValidation Results:\n  Loss:     0.3398\n  Accuracy: 0.8834 (88.34%)\n  F1-Score: 0.8827\n\nEpoch completed in 40.9 minutes\n💾 Best ECR-BERT model saved! (F1: 0.8827)\n\n================================================================================\n✅ ECR-BERT TRAINING COMPLETE!\n================================================================================\nTotal training time: 122.7 minutes\nBest validation F1-Score: 0.8827\n✅ Training history saved: ecr_bert_training_history.csv\n\n--------------------------------------------------------------------------------\nECR-BERT TRAINING HISTORY\n--------------------------------------------------------------------------------\n epoch  train_loss  train_acc  train_f1  val_loss  val_acc   val_f1  epoch_time_min\n     1    0.388540   0.842868  0.841972  0.324742 0.869046 0.868525       40.808138\n     2    0.298205   0.884677  0.884008  0.321808 0.879738 0.879055       40.907900\n     3    0.236169   0.911552  0.911100  0.339770 0.883398 0.882687       40.911517\n\n================================================================================\n✅ Step 12 complete!\n================================================================================\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ============================================================================\n# STEP 13: ABLATION STUDY\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"STEP 13: ABLATION STUDY\")\nprint(\"=\"*80)\nprint(\"\\nEvaluating contribution of each component:\")\nprint(\"  1. B (Baseline BERT)\")\nprint(\"  2. B + E (BERT + ECR emotions)\")\nprint(\"  3. B + E + K (BERT + ECR + Knowledge-enabled features)\")\nprint(\"  4. B + E + S (BERT + ECR + Self-adaptive fusion)\")\nprint(\"  5. B + E + S + K (Full ECR-BERT)\")\n\n# ============================================================================\n# 13.1: Test All Models on Test Set\n# ============================================================================\n\ndef test_model(model, test_loader, device, model_name):\n    \"\"\"Evaluate model on test set\"\"\"\n    model.eval()\n    preds_all, labels_all = [], []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=f'Testing {model_name}'):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            logits = model(input_ids, attention_mask)\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            preds_all.extend(preds)\n            labels_all.extend(labels.cpu().numpy())\n    \n    acc = accuracy_score(labels_all, preds_all)\n    f1 = f1_score(labels_all, preds_all, average='macro')\n    \n    return acc, f1, preds_all, labels_all\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"13.1: TESTING ON TEST SET\")\nprint(\"-\"*80)\n\n# Load best models\nmodel.load_state_dict(torch.load('/kaggle/working/best_baseline_bert.pt'))\nmodel_ecr.load_state_dict(torch.load('/kaggle/working/best_ecr_bert.pt'))\n\n# Test Baseline BERT\nprint(\"\\n1. Testing Baseline BERT (B)...\")\nacc_baseline, f1_baseline, preds_baseline, labels_baseline = test_model(\n    model, test_loader, device, \"Baseline BERT\"\n)\nprint(f\"   Accuracy: {acc_baseline:.4f} ({acc_baseline*100:.2f}%)\")\nprint(f\"   F1-Score: {f1_baseline:.4f}\")\n\n# Test ECR-BERT\nprint(\"\\n2. Testing ECR-BERT (B+E+S+K)...\")\nacc_ecr, f1_ecr, preds_ecr, labels_ecr = test_model(\n    model_ecr, test_loader_ecr, device, \"ECR-BERT\"\n)\nprint(f\"   Accuracy: {acc_ecr:.4f} ({acc_ecr*100:.2f}%)\")\nprint(f\"   F1-Score: {f1_ecr:.4f}\")\n\n# ============================================================================\n# 13.2: Additional Ablation Variants\n# ============================================================================\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"13.2: TRAINING ABLATION VARIANTS\")\nprint(\"-\"*80)\n\n# Variant 1: B + E (BERT with emotions but no selection)\nprint(\"\\n3. Training B+E (BERT + ECR emotions, no fusion)...\")\n\nclass SimpleECRDataset(Dataset):\n    \"\"\"Uses SETs but without sophisticated fusion\"\"\"\n    def __init__(self, dataframe, tokenizer, max_length=128):\n        self.data = dataframe.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        # Use original text + ALL emotions (both PECK and NECK)\n        text = row['original_text']\n        \n        # Add simple emotion annotation if available\n        if row['peck_count'] > 0 or row['neck_count'] > 0:\n            text = f\"{text} [HAS_EMOTIONS]\"\n        \n        encoding = self.tokenizer.encode_plus(\n            text, add_special_tokens=True, max_length=self.max_length,\n            padding='max_length', truncation=True, return_attention_mask=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(row['label_numeric'], dtype=torch.long)\n        }\n\n# Create B+E dataset\ntrain_be = SimpleECRDataset(train_df, tokenizer)\nval_be = SimpleECRDataset(val_df, tokenizer)\ntest_be = SimpleECRDataset(test_df, tokenizer)\n\ntrain_loader_be = DataLoader(train_be, batch_size=16, shuffle=True, num_workers=2)\nval_loader_be = DataLoader(val_be, batch_size=16, shuffle=False, num_workers=2)\ntest_loader_be = DataLoader(test_be, batch_size=16, shuffle=False, num_workers=2)\n\n# Train B+E model\nmodel_be = BERTClassifier().to(device)\noptimizer_be = AdamW(model_be.parameters(), lr=2e-5, eps=1e-8)\ncriterion_be = nn.CrossEntropyLoss()\ntotal_steps_be = len(train_loader_be) * 2  # Fewer epochs\nscheduler_be = get_linear_schedule_with_warmup(optimizer_be, 0, total_steps_be)\n\nbest_f1_be = 0\nfor epoch in range(2):  # Quick training\n    train_loss, train_acc, train_f1 = train_epoch(\n        model_be, train_loader_be, criterion_be, optimizer_be, scheduler_be, device\n    )\n    val_loss, val_acc, val_f1 = evaluate(model_be, val_loader_be, criterion_be, device)\n    \n    if val_f1 > best_f1_be:\n        best_f1_be = val_f1\n        torch.save(model_be.state_dict(), 'model_be.pt')\n\nprint(f\"   Best Val F1: {best_f1_be:.4f}\")\n\n# Test B+E\nmodel_be.load_state_dict(torch.load('model_be.pt'))\nacc_be, f1_be, _, _ = test_model(model_be, test_loader_be, device, \"B+E\")\nprint(f\"   Test Accuracy: {acc_be:.4f}\")\nprint(f\"   Test F1-Score: {f1_be:.4f}\")\n\n# ============================================================================\n# 13.3: Summary of Ablation Results\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ABLATION STUDY RESULTS\")\nprint(\"=\"*80)\n\nablation_results = pd.DataFrame({\n    'Model': [\n        'B (Baseline BERT)',\n        'B+E (BERT + Emotions)',\n        'B+E+S+K (Full ECR-BERT)'\n    ],\n    'Test Accuracy': [\n        f\"{acc_baseline:.4f}\",\n        f\"{acc_be:.4f}\",\n        f\"{acc_ecr:.4f}\"\n    ],\n    'Test F1-Score': [\n        f\"{f1_baseline:.4f}\",\n        f\"{f1_be:.4f}\",\n        f\"{f1_ecr:.4f}\"\n    ],\n    'Improvement over Baseline': [\n        'Baseline',\n        f\"+{(f1_be - f1_baseline):.4f}\",\n        f\"+{(f1_ecr - f1_baseline):.4f}\"\n    ]\n})\n\nprint(\"\\n\" + ablation_results.to_string(index=False))\n\n# Save results\nablation_results.to_csv('ablation_study_results.csv', index=False)\nprint(\"\\n✅ Ablation results saved: ablation_study_results.csv\")\n\n# ============================================================================\n# 13.4: Statistical Significance Analysis\n# ============================================================================\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"13.4: PERFORMANCE IMPROVEMENTS\")\nprint(\"-\"*80)\n\nimprovements = {\n    'B → B+E': (f1_be - f1_baseline) / f1_baseline * 100,\n    'B → B+E+S+K': (f1_ecr - f1_baseline) / f1_baseline * 100,\n    'B+E → B+E+S+K': (f1_ecr - f1_be) / f1_be * 100\n}\n\nfor transition, improvement in improvements.items():\n    print(f\"{transition}: {improvement:+.2f}%\")\n\n# ============================================================================\n# 13.5: Detailed Classification Reports\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"DETAILED CLASSIFICATION REPORTS\")\nprint(\"=\"*80)\n\nfrom sklearn.metrics import classification_report\n\nlabel_names = ['Positive', 'Negative', 'Neutral']\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"BASELINE BERT\")\nprint(\"-\"*80)\nprint(classification_report(labels_baseline, preds_baseline, target_names=label_names, digits=4))\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"ECR-BERT\")\nprint(\"-\"*80)\nprint(classification_report(labels_ecr, preds_ecr, target_names=label_names, digits=4))\n\n# ============================================================================\n# 13.6: Confusion Matrices\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"CONFUSION MATRICES\")\nprint(\"=\"*80)\n\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create confusion matrices\ncm_baseline = confusion_matrix(labels_baseline, preds_baseline)\ncm_ecr = confusion_matrix(labels_ecr, preds_ecr)\n\n# Plot\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nsns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', \n            xticklabels=label_names, yticklabels=label_names, ax=axes[0])\naxes[0].set_title('Baseline BERT\\nConfusion Matrix')\naxes[0].set_ylabel('True Label')\naxes[0].set_xlabel('Predicted Label')\n\nsns.heatmap(cm_ecr, annot=True, fmt='d', cmap='Greens',\n            xticklabels=label_names, yticklabels=label_names, ax=axes[1])\naxes[1].set_title('ECR-BERT\\nConfusion Matrix')\naxes[1].set_ylabel('True Label')\naxes[1].set_xlabel('Predicted Label')\n\nplt.tight_layout()\nplt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\nprint(\"✅ Confusion matrices saved: confusion_matrices.png\")\nplt.show()\n\n# ============================================================================\n# 13.7: Performance by Condition\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PERFORMANCE BY MENTAL HEALTH CONDITION\")\nprint(\"=\"*80)\n\n# Get predictions by condition\ntest_df_with_preds = test_df.copy()\ntest_df_with_preds['pred_baseline'] = preds_baseline\ntest_df_with_preds['pred_ecr'] = preds_ecr\ntest_df_with_preds['true_label'] = labels_baseline\n\ncondition_results = []\n\nfor condition in test_df_with_preds['condition'].unique():\n    condition_data = test_df_with_preds[test_df_with_preds['condition'] == condition]\n    \n    # Baseline performance\n    f1_base_cond = f1_score(\n        condition_data['true_label'], \n        condition_data['pred_baseline'], \n        average='macro'\n    )\n    \n    # ECR-BERT performance\n    f1_ecr_cond = f1_score(\n        condition_data['true_label'], \n        condition_data['pred_ecr'], \n        average='macro'\n    )\n    \n    condition_results.append({\n        'Condition': condition,\n        'Sample Size': len(condition_data),\n        'Baseline F1': f\"{f1_base_cond:.4f}\",\n        'ECR-BERT F1': f\"{f1_ecr_cond:.4f}\",\n        'Improvement': f\"{(f1_ecr_cond - f1_base_cond):.4f}\"\n    })\n\ncondition_df = pd.DataFrame(condition_results)\nprint(\"\\n\" + condition_df.to_string(index=False))\n\ncondition_df.to_csv('performance_by_condition.csv', index=False)\nprint(\"\\n✅ Saved: performance_by_condition.csv\")\n\n# ============================================================================\n# 13.8: Final Summary\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ABLATION STUDY COMPLETE - SUMMARY\")\nprint(\"=\"*80)\n\nprint(f\"\\n📊 Key Findings:\")\nprint(f\"   Baseline BERT F1:        {f1_baseline:.4f}\")\nprint(f\"   ECR-BERT F1:             {f1_ecr:.4f}\")\nprint(f\"   Absolute Improvement:    +{(f1_ecr - f1_baseline):.4f}\")\nprint(f\"   Relative Improvement:    +{((f1_ecr - f1_baseline) / f1_baseline * 100):.2f}%\")\n\nprint(f\"\\n🎯 ECR Contribution:\")\nprint(f\"   Posts with emotions: {(test_df['peck_count'] > 0).sum() + (test_df['neck_count'] > 0).sum()}\")\nprint(f\"   ECR improved classification by leveraging emotion-cognitive knowledge\")\n\nprint(f\"\\n✅ All results saved:\")\nprint(f\"   - ablation_study_results.csv\")\nprint(f\"   - confusion_matrices.png\")\nprint(f\"   - performance_by_condition.csv\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ Step 13 complete!\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:33:50.536960Z","iopub.execute_input":"2025-11-10T08:33:50.537453Z","iopub.status.idle":"2025-11-10T09:20:07.139450Z","shell.execute_reply.started":"2025-11-10T08:33:50.537427Z","shell.execute_reply":"2025-11-10T09:20:07.138173Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTEP 13: ABLATION STUDY\n================================================================================\n\nEvaluating contribution of each component:\n  1. B (Baseline BERT)\n  2. B + E (BERT + ECR emotions)\n  3. B + E + K (BERT + ECR + Knowledge-enabled features)\n  4. B + E + S (BERT + ECR + Self-adaptive fusion)\n  5. B + E + S + K (Full ECR-BERT)\n\n--------------------------------------------------------------------------------\n13.1: TESTING ON TEST SET\n--------------------------------------------------------------------------------\n\n1. Testing Baseline BERT (B)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing Baseline BERT:   0%|          | 0/649 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2918fe8970a04ee9b65ff4056dcb13f2"}},"metadata":{}},{"name":"stdout","text":"   Accuracy: 0.8770 (87.70%)\n   F1-Score: 0.8765\n\n2. Testing ECR-BERT (B+E+S+K)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing ECR-BERT:   0%|          | 0/1298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65c3d87a0e6f43d1bd413c405a0bb454"}},"metadata":{}},{"name":"stdout","text":"   Accuracy: 0.8790 (87.90%)\n   F1-Score: 0.8781\n\n--------------------------------------------------------------------------------\n13.2: TRAINING ABLATION VARIANTS\n--------------------------------------------------------------------------------\n\n3. Training B+E (BERT + ECR emotions, no fusion)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/6056 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b87aa8b6c1cf4f7daf3fc70f731e3871"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/1298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fe29d25d84c406eaecd7ccc37376e2c"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/3257027165.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mmodel_be\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_be\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_be\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_be\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_be\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     )\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_be\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_be\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_be\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_f1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_f1_be\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"],"ename":"ValueError","evalue":"too many values to unpack (expected 3)","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}