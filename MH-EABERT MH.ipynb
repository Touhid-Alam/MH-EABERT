{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13609732,"sourceType":"datasetVersion","datasetId":8648726}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/mental-health'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom typing import List, Dict, Any\n\n# ====================================================================\n# STEP 1: DATA LOADING, CONSOLIDATION, AND ROBUST CLEANING\n# ====================================================================\n\n# 1.1 Define the list of file paths (ensure these paths are correct in your Kaggle environment)\nfile_paths = [\n    '/kaggle/input/mental-health/ptsd.csv',\n    '/kaggle/input/mental-health/adhd.csv',\n    '/kaggle/input/mental-health/aspergers.csv',\n    '/kaggle/input/mental-health/ocd.csv',\n    '/kaggle/input/mental-health/depression.csv'\n]\n\nTEXT_COL = 'body' # The column containing the main message\n\nall_data: List[pd.DataFrame] = []\nprint(\"--- Starting Data Loading and Consolidation ---\")\n\nfor path in file_paths:\n    try:\n        # Load the CSV\n        df = pd.read_csv(path)\n        # Add a source column\n        df['source'] = path.split('/')[-1].replace('.csv', '')\n        \n        # Standardize the text column name\n        if TEXT_COL not in df.columns:\n            print(f\"Warning: '{TEXT_COL}' not found in {path}. Skipping this file.\")\n            continue\n            \n        df.rename(columns={TEXT_COL: 'text_raw'}, inplace=True)\n        all_data.append(df)\n        print(f\"Loaded {path} with {len(df)} initial rows.\")\n        \n    except FileNotFoundError:\n        print(f\"File not found: {path}\")\n    except Exception as e:\n        print(f\"Error loading {path}: {e}\")\n\nif not all_data:\n    raise ValueError(\"No data files were loaded successfully. Please check your Kaggle file paths.\")\n\ndf_combined = pd.concat(all_data, ignore_index=True)\nprint(f\"\\nTotal rows after consolidation: {len(df_combined)}\")\n\n# 1.2 Robust Cleaning and Null/Empty Body Removal (Crucial step based on your instruction)\ninitial_rows = len(df_combined)\n\n# Convert to string and handle standard missing values (NaN, None)\ndf_combined['text_raw'] = df_combined['text_raw'].astype(str)\n\n# Identify rows where the body is Null, empty, or just whitespace\ndf_combined.replace('', np.nan, inplace=True) # Replace empty strings with NaN\ndf_combined.dropna(subset=['text_raw'], inplace=True) # Drop NaN values\n\n# Remove rows where the content is just whitespace\ndf_combined = df_combined[df_combined['text_raw'].str.strip().astype(bool)]\n\nfinal_rows = len(df_combined)\nprint(f\"Rows removed due to null/empty body: {initial_rows - final_rows}\")\nprint(f\"Final rows for analysis: {final_rows}\")\n\n\n# 1.3 & 1.4 General Preprocessing (Cleaning and Lowercasing)\ndef clean_text(text: str) -> str:\n    \"\"\"Performs basic cleaning and lowercasing.\"\"\"\n    text = text.lower()\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Remove URLs\n    text = re.sub(r'@\\w+', '', text) # Remove mentions/user handles\n    text = re.sub(r'[^a-z\\s]', '', text) # Remove punctuation and numbers (keeping only letters and spaces)\n    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n    return text\n\ndf_combined['text_cleaned'] = df_combined['text_raw'].apply(clean_text)\ndf_combined['tokens'] = df_combined['text_cleaned'].apply(lambda x: x.split())\n\n# 1.5 Placeholder for Target Variable (Sentiment) - You need to define this!\n# Since your original data only has disorder labels, you must create a sentiment label.\n# For simplicity, let's assume ALL posts are 'Negative' (1) and we will only look \n# for 'Positive' (0) if there are explicitly supportive/recovery-focused posts later.\n# For now, we will use a binary classification.\n\ndf_combined['sentiment_label'] = 1 # Default to Negative (1)\n# NOTE: If your data contains explicit labels (e.g., 'Positive', 'Neutral', 'Negative') use that column.\n# If you need to include 'Neutral' (2), you must have a way to identify it. \n\n\nprint(\"\\n--- Sample of Cleaned Data ---\")\nprint(df_combined[['source', 'text_raw', 'text_cleaned', 'sentiment_label']].head())\n\n# Save the resulting DataFrame for the next step (ECR Module)\ndf_combined.to_csv('cleaned_mental_health_data.csv', index=False)\nprint(\"\\nCleaned data saved to 'cleaned_mental_health_data.csv'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T14:33:13.274198Z","iopub.execute_input":"2025-11-04T14:33:13.274448Z","iopub.status.idle":"2025-11-04T14:33:36.703650Z","shell.execute_reply.started":"2025-11-04T14:33:13.274428Z","shell.execute_reply":"2025-11-04T14:33:36.702854Z"}},"outputs":[{"name":"stdout","text":"--- Starting Data Loading and Consolidation ---\nLoaded /kaggle/input/mental-health/ptsd.csv with 24028 initial rows.\nLoaded /kaggle/input/mental-health/adhd.csv with 37109 initial rows.\nLoaded /kaggle/input/mental-health/aspergers.csv with 23294 initial rows.\nLoaded /kaggle/input/mental-health/ocd.csv with 42826 initial rows.\nLoaded /kaggle/input/mental-health/depression.csv with 24031 initial rows.\n\nTotal rows after consolidation: 151288\nRows removed due to null/empty body: 0\nFinal rows for analysis: 151288\n\n--- Sample of Cleaned Data ---\n  source                                           text_raw  \\\n0   ptsd  This year felt like literal hell. It’s over no...   \n1   ptsd  Can feel my skin tightening up as I type this ...   \n2   ptsd  I shout at my animals sometimes when they do s...   \n3   ptsd  I'm really struggling with my past and it's pr...   \n4   ptsd                                   On Snapchat call   \n\n                                        text_cleaned  sentiment_label  \n0  this year felt like literal hell its over now ...                1  \n1  can feel my skin tightening up as i type this ...                1  \n2  i shout at my animals sometimes when they do s...                1  \n3  im really struggling with my past and its prob...                1  \n4                                   on snapchat call                1  \n\nCleaned data saved to 'cleaned_mental_health_data.csv'.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom typing import List, Dict, Any, Tuple\n\n# ====================================================================\n# STEP 2.1: LOAD CLEANED DATA FROM STEP 1\n# ====================================================================\n\ntry:\n    df_combined = pd.read_csv('cleaned_mental_health_data.csv')\n    # Convert tokens back from string (how CSV saves lists) to actual lists\n    df_combined['tokens'] = df_combined['tokens'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    print(f\"Loaded data for ECR from 'cleaned_mental_health_data.csv' with {len(df_combined)} rows.\")\nexcept FileNotFoundError:\n    print(\"Error: 'cleaned_mental_health_data.csv' not found. Please ensure Step 1 was run successfully.\")\n    # Exit or use a mock DataFrame if needed for demonstration\n    raise\n\n# ====================================================================\n# STEP 2.2: DEFINE ECR COMPONENTS (EDD AND FUNCTIONS)\n# ====================================================================\n\n# 2.2.1: Define the Emotion Dimension Dictionary (EDD) with Intensity Scores\n# Scores are numerical intensity values, used for ES calculation.\nEDD = {\n    'Desirable': {'hope': 0.8, 'recovery': 0.9, 'better': 0.7, 'progress': 0.7, 'support': 0.8, 'relief': 0.6, 'calm': 0.6, 'managed': 0.7, 'accepting': 0.5, 'proud': 0.9},\n    'Undesirable': {'anxiety': -0.9, 'fear': -0.9, 'hopeless': -1.0, 'struggle': -0.7, 'overwhelmed': -0.8, 'guilt': -0.7, 'pining': -0.6, 'depressed': -1.0, 'suicidal': -1.0, 'panic': -0.9, 'trauma': -0.8},\n    'Praiseworthy': {'selfcompassion': 0.9, 'advocating': 0.8, 'acceptinghelp': 0.9, 'kind': 0.7, 'brave': 0.8, 'trying': 0.6},\n    'Blameworthy': {'selfhate': -1.0, 'selfblame': -0.9, 'avoidance': -0.8, 'stigma': -0.9, 'fail': -0.8, 'wrong': -0.7},\n    'Confirmed': {'validated': 0.7, 'working': 0.6, 'confirmed': 0.5, 'true': 0.5, 'diagnosis': 0.4},\n    'Disconfirmed': {'misdiagnosed': -0.7, 'notworking': -0.8, 'relapse': -0.9, 'failed': -0.8, 'misunderstood': -0.7}\n}\n\n# 2.2.2: ECR Functions (Simplified OCC Rules)\ndef perform_ecr(text_tokens: List[str], EDD: Dict[str, Dict[str, float]]) -> Tuple[List[Any], List[Any]]:\n    \"\"\"Applies the simplified 10 OCC rules to infer emotion-cognitive knowledge (ECK).\"\"\"\n    \n    # Map tokens to their dimensions and intensity\n    dim_map = {}\n    for token in text_tokens:\n        for dim, words in EDD.items():\n            if token in words:\n                dim_map[token] = {'dim': dim, 'intensity': words[token]}\n                break\n\n    PECK = []\n    NECK = []\n    \n    def find_word_in_dim(dim_name: str, tokens_to_check: List[str]) -> str | None:\n        \"\"\"Helper to find the first token of a given dimension not yet used.\"\"\"\n        return next((token for token in tokens_to_check if token in dim_map and dim_map[token]['dim'] == dim_name), None)\n\n    unique_tokens = list(dim_map.keys())\n    tokens_used = set()\n\n    # --- Compound Rules (Rules 5-10) - Higher Priority ---\n    \n    # Compound checks require multiple tokens; simplify by iterating over all unique tokens for potential pairings.\n    \n    # R6: Undesirable + Blameworthy -> Anger/Reproach (NECK)\n    u_token = find_word_in_dim('Undesirable', unique_tokens)\n    b_token = find_word_in_dim('Blameworthy', unique_tokens)\n    if u_token and b_token and u_token not in tokens_used and b_token not in tokens_used:\n        NECK.append([u_token, b_token, 'Anger/Self-Reproach'])\n        tokens_used.add(u_token)\n        tokens_used.add(b_token)\n\n    # R5: Desirable + Praiseworthy -> Gratitude/Pride (PECK)\n    d_token = find_word_in_dim('Desirable', unique_tokens)\n    p_token = find_word_in_dim('Praiseworthy', unique_tokens)\n    if d_token and p_token and d_token not in tokens_used and p_token not in tokens_used:\n        PECK.append([d_token, p_token, 'Gratitude/Pride'])\n        tokens_used.add(d_token)\n        tokens_used.add(p_token)\n\n    # R7: Desirable + Confirmed -> Satisfaction (PECK)\n    c_token = find_word_in_dim('Confirmed', unique_tokens)\n    if d_token and c_token and d_token not in tokens_used and c_token not in tokens_used:\n        PECK.append([d_token, c_token, 'Satisfaction'])\n        tokens_used.add(d_token)\n        tokens_used.add(c_token)\n            \n    # R8: Undesirable + Confirmed -> Fear-Confirmed (NECK)\n    if u_token and c_token and u_token not in tokens_used and c_token not in tokens_used:\n        NECK.append([u_token, c_token, 'Fear-Confirmed'])\n        tokens_used.add(u_token)\n        tokens_used.add(c_token)\n\n    # R9: Desirable + Disconfirmed -> Relief (PECK)\n    dc_token = find_word_in_dim('Disconfirmed', unique_tokens)\n    if d_token and dc_token and d_token not in tokens_used and dc_token not in tokens_used:\n        PECK.append([d_token, dc_token, 'Relief'])\n        tokens_used.add(d_token)\n        tokens_used.add(dc_token)\n\n    # R10: Undesirable + Disconfirmed -> Disappointment (NECK)\n    if u_token and dc_token and u_token not in tokens_used and dc_token not in tokens_used:\n        NECK.append([u_token, dc_token, 'Disappointment'])\n        tokens_used.add(u_token)\n        tokens_used.add(dc_token)\n        \n    # --- Single Rules (Rules 1-4) - Fallback for unused tokens ---\n    for token in unique_tokens:\n        if token not in tokens_used:\n            dim = dim_map[token]['dim']\n            \n            # R1: Desirable -> Joy\n            if dim == 'Desirable':\n                PECK.append([token, 'Joy'])\n            # R2: Undesirable -> Distress\n            elif dim == 'Undesirable':\n                NECK.append([token, 'Distress'])\n            # R3: Praiseworthy -> Admiration\n            elif dim == 'Praiseworthy':\n                PECK.append([token, 'Admiration'])\n            # R4: Blameworthy -> Reproach\n            elif dim == 'Blameworthy':\n                NECK.append([token, 'Reproach'])\n                \n    return PECK, NECK\n\n\n# 2.2.3: Calculate ES and CS_ECR\ndef calculate_es_cs(text_tokens: List[str], EDD: Dict[str, Dict[str, float]]) -> Tuple[float, float]:\n    \"\"\"Calculates Emotion Score (ES) and ECR Confidence Score (CS_ECR) based on word intensity.\"\"\"\n    S_P = 0.0 # Positive Sentiment Intensity Sum\n    S_N = 0.0 # Negative Sentiment Intensity Sum\n    \n    for token in text_tokens:\n        for words in EDD.values():\n            if token in words:\n                intensity = words[token]\n                if intensity > 0:\n                    S_P += intensity\n                elif intensity < 0:\n                    # S_N is the sum of ABSOLUTE negative intensity (Eq. 12)\n                    S_N += abs(intensity)\n                break\n                \n    # ES (Eq. 13) and CS_ECR (Eq. 14)\n    ES = (S_P - S_N) / (S_P + S_N) if (S_P + S_N) > 0 else 0.0\n    CS_ECR = abs(ES)\n    \n    return ES, CS_ECR\n\n# ====================================================================\n# STEP 2.3: APPLY ECR TO THE DATA\n# ====================================================================\n\nprint(\"\\n--- Applying ECR to data (calculating ES, CS_ECR, PECK, NECK) ---\")\n\n# Apply ES/CS calculation\ndf_combined[['ES', 'CS_ECR']] = df_combined['tokens'].apply(\n    lambda x: pd.Series(calculate_es_cs(x, EDD))\n)\n\n# Apply ECR rule-based knowledge extraction\ndf_combined[['PECK', 'NECK']] = df_combined['tokens'].apply(\n    lambda x: pd.Series(perform_ecr(x, EDD))\n)\n\n# ====================================================================\n# STEP 2.4: SAVE PROCESSED DATA FOR STEP 3\n# ====================================================================\n\noutput_cols = ['source', 'text_raw', 'text_cleaned', 'tokens', 'sentiment_label', 'ES', 'CS_ECR', 'PECK', 'NECK']\nprint(\"\\n--- Sample of ECR Processed Data ---\")\nprint(df_combined[output_cols].head())\n\ndf_combined[output_cols].to_csv('ecr_processed_mental_health_data.csv', index=False)\nprint(\"\\nProcessed data saved to 'ecr_processed_mental_health_data.csv'.\")\nprint(\"Proceed to Step 3: Self-Adaptive Fusion (SAFA) and BERT Integration.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T14:33:36.704833Z","iopub.execute_input":"2025-11-04T14:33:36.705043Z","iopub.status.idle":"2025-11-04T14:34:48.142643Z","shell.execute_reply.started":"2025-11-04T14:33:36.705025Z","shell.execute_reply":"2025-11-04T14:34:48.141982Z"}},"outputs":[{"name":"stdout","text":"Loaded data for ECR from 'cleaned_mental_health_data.csv' with 151288 rows.\n\n--- Applying ECR to data (calculating ES, CS_ECR, PECK, NECK) ---\n\n--- Sample of ECR Processed Data ---\n  source                                           text_raw  \\\n0   ptsd  This year felt like literal hell. It’s over no...   \n1   ptsd  Can feel my skin tightening up as I type this ...   \n2   ptsd  I shout at my animals sometimes when they do s...   \n3   ptsd  I'm really struggling with my past and it's pr...   \n4   ptsd                                   On Snapchat call   \n\n                                        text_cleaned  \\\n0  this year felt like literal hell its over now ...   \n1  can feel my skin tightening up as i type this ...   \n2  i shout at my animals sometimes when they do s...   \n3  im really struggling with my past and its prob...   \n4                                   on snapchat call   \n\n                                              tokens  sentiment_label   ES  \\\n0  [this, year, felt, like, literal, hell, its, o...                1  0.0   \n1  [can, feel, my, skin, tightening, up, as, i, t...                1  0.0   \n2  [i, shout, at, my, animals, sometimes, when, t...                1  0.0   \n3  [im, really, struggling, with, my, past, and, ...                1 -0.6   \n4                               [on, snapchat, call]                1  0.0   \n\n   CS_ECR                  PECK  \\\n0     0.0                    []   \n1     0.0       [[better, Joy]]   \n2     0.0  [[kind, Admiration]]   \n3     0.6     [[recovery, Joy]]   \n4     0.0                    []   \n\n                                                NECK  \n0                                                 []  \n1                                [[wrong, Reproach]]  \n2                                [[wrong, Reproach]]  \n3  [[anxiety, Distress], [panic, Distress], [fear...  \n4                                                 []  \n\nProcessed data saved to 'ecr_processed_mental_health_data.csv'.\nProceed to Step 3: Self-Adaptive Fusion (SAFA) and BERT Integration.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom typing import List, Dict, Any, Tuple\nfrom sklearn.preprocessing import MinMaxScaler\n\n# ====================================================================\n# STEP 3.1: LOAD ECR PROCESSED DATA FROM STEP 2\n# ====================================================================\n\ntry:\n    df_combined = pd.read_csv('ecr_processed_mental_health_data.csv')\n    # Convert 'tokens', 'PECK', 'NECK' back from string to actual lists/objects\n    df_combined['tokens'] = df_combined['tokens'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    df_combined['PECK'] = df_combined['PECK'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    df_combined['NECK'] = df_combined['NECK'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    print(f\"Loaded ECR processed data for SAFA from 'ecr_processed_mental_health_data.csv' with {len(df_combined)} rows.\")\nexcept FileNotFoundError:\n    print(\"Error: 'ecr_processed_mental_health_data.csv' not found. Please ensure Step 2 was run successfully.\")\n    raise\n\n# ====================================================================\n# STEP 3.2: SIMULATE BERT SENTIMENT PREDICTION (Placeholder for actual BERT)\n# ====================================================================\n\n# In a real scenario, you would train a BERT model on 'text_cleaned'\n# to get sentiment_label_bert and CS_BERT.\n# For now, we'll simulate it based on your existing 'sentiment_label'\n# and generate a random confidence score.\n\ndef simulate_bert_prediction(sentiment_label: int, es_score: float) -> Tuple[int, float]:\n    \"\"\"\n    Simulates BERT's sentiment prediction and confidence score.\n    In a real scenario, this would be an actual BERT model.\n    For this simulation:\n    - Sentiment label is primarily based on the ECR's ES score to add some realism.\n      If ES is strongly positive, BERT might lean positive.\n      If ES is strongly negative, BERT might lean negative.\n      Otherwise, it might be neutral or match the default.\n    - Confidence score is semi-random, but higher if ES is strong.\n    \"\"\"\n    # Simulate BERT's predicted label (ŷ)\n    if es_score > 0.4: # Strongly positive ECR score\n        y_bert = 0 # Positive\n    elif es_score < -0.4: # Strongly negative ECR score\n        y_bert = 1 # Negative\n    else:\n        y_bert = np.random.choice([0, 1, 2]) # Otherwise, randomly pick (0:Pos, 1:Neg, 2:Neu)\n\n    # Simulate BERT's confidence score (CS_BERT)\n    # Make it higher if ECR's ES is strong, implying more certainty.\n    base_confidence = np.random.uniform(0.6, 0.9)\n    if abs(es_score) > 0.5:\n        cs_bert = min(0.99, base_confidence + np.random.uniform(0.05, 0.1))\n    else:\n        cs_bert = base_confidence\n\n    return y_bert, cs_bert\n\nprint(\"\\n--- Simulating BERT Sentiment Predictions ---\")\ndf_combined[['sentiment_label_bert', 'CS_BERT']] = df_combined.apply(\n    lambda row: pd.Series(simulate_bert_prediction(row['sentiment_label'], row['ES'])),\n    axis=1\n)\n\n# 2.2.4: Normalize CS_BERT (Eq. 19)\n# Use MinMaxScaler to scale CS_BERT to the range [0, 1]\nscaler = MinMaxScaler(feature_range=(0, 1))\ndf_combined['CS_BERT_normalized'] = scaler.fit_transform(df_combined[['CS_BERT']])\nprint(\"CS_BERT normalized using Min-Max scaling.\")\n\n# ====================================================================\n# STEP 3.3: SELF-ADAPTIVE FUSION ALGORITHM (SAFA - Algorithm 2)\n# ====================================================================\n\n# Algorithm 2: Self-Adaptive Fusion\n# Input: OPOE, PECK, NECK, ES, CS_ECR, CS_BERT_normalized, threshold\n# Output: SET\n\ndef generate_sentence_emotion_tree(original_text: str, pec_knowledge: List[Any], nec_knowledge: List[Any]) -> str:\n    \"\"\"\n    Integrates selected PECK or NECK into the original text to form a Sentence-Emotion Tree (SET).\n    This is a simplified representation of SET as a string.\n    The paper uses a more complex tree structure for BERT's input, which will be handled\n    by soft-position embedding and mask-transformer. Here we just embed it for textual representation.\n    \"\"\"\n    if not pec_knowledge and not nec_knowledge:\n        return original_text # No knowledge to embed\n\n    embedded_knowledge = []\n    if pec_knowledge:\n        embedded_knowledge.append(f\"{{PECK: {', '.join([str(item) for item in pec_knowledge])}}}\")\n    if nec_knowledge:\n        embedded_knowledge.append(f\"{{NECK: {', '.join([str(item) for item in nec_knowledge])}}}\")\n\n    # For simplicity, we'll append knowledge to the end of the text.\n    # A more sophisticated approach would be to insert near relevant tokens.\n    # Example from paper: \"My wishes are that all medical staff are healthy! All the bastards {[disasters, anger], [damned, anger]} who cause disasters will be damned.\"\n    # We'll just append to illustrate the concept.\n    return f\"{original_text} {' '.join(embedded_knowledge)}\"\n\n\ndef self_adaptive_fusion(\n    text_raw: str,\n    pec_knowledge: List[Any],\n    nec_knowledge: List[Any],\n    es: float,\n    cs_ecr: float,\n    sentiment_label_bert: int, # BERT's predicted label (0:Pos, 1:Neg, 2:Neu)\n    cs_bert_normalized: float,\n    threshold: float = 0.3 # Hyperparameter, can be tuned (e.g., from ablation study)\n) -> Tuple[str, List[Any], List[Any], str]:\n    \"\"\"\n    Implements the Self-Adaptive Fusion Algorithm (Algorithm 2).\n    Determines which knowledge (PECK/NECK) to incorporate based on confidence scores.\n    Returns the Sentence-Emotion Tree (SET) and the chosen knowledge for later explanation.\n    \"\"\"\n    chosen_pec = []\n    chosen_nec = []\n    fusion_reason = \"No ECK incorporated\"\n\n    delta = cs_bert_normalized - cs_ecr # Eq. 20 (modified to use normalized CS_BERT)\n\n    if cs_ecr >= threshold:\n        # ECR has high priority/confidence\n        if es > 0: # ECR suggests positive sentiment\n            chosen_pec = pec_knowledge\n            fusion_reason = \"ECR-preferred PECK (high CS_ECR, positive ES)\"\n        elif es < 0: # ECR suggests negative sentiment\n            chosen_nec = nec_knowledge\n            fusion_reason = \"ECR-preferred NECK (high CS_ECR, negative ES)\"\n        else:\n            # ES is 0, ECR has no strong sentiment direction, no ECK incorporated\n            pass # chosen_pec and chosen_nec remain empty\n    else:\n        # ECR has low priority/confidence, defer to BERT\n        if delta >= 0: # BERT has higher or equal confidence\n            if sentiment_label_bert == 0: # BERT predicts Positive\n                chosen_pec = pec_knowledge\n                fusion_reason = \"BERT-preferred PECK (high CS_BERT, positive BERT)\"\n            elif sentiment_label_bert == 1: # BERT predicts Negative\n                chosen_nec = nec_knowledge\n                fusion_reason = \"BERT-preferred NECK (high CS_BERT, negative BERT)\"\n            # If BERT predicts neutral (2), no ECK is incorporated by default\n        else:\n            # If delta < 0, ECR has higher confidence than BERT (unlikely given BERT's typical performance)\n            # This branch is from the paper's Algorithm 2 line 12-15\n            if es > 0:\n                chosen_pec = pec_knowledge\n                fusion_reason = \"ECR-preferred PECK (low delta, positive ES)\"\n            elif es < 0:\n                chosen_nec = nec_knowledge\n                fusion_reason = \"ECR-preferred NECK (low delta, negative ES)\"\n            # else ES is 0, no ECK\n\n    set_text = generate_sentence_emotion_tree(text_raw, chosen_pec, chosen_nec)\n    return set_text, chosen_pec, chosen_nec, fusion_reason\n\nprint(\"\\n--- Applying Self-Adaptive Fusion Algorithm (SAFA) ---\")\n# Define the threshold for SAFA (this is a hyperparameter to tune)\nsafa_threshold = 0.3\nprint(f\"Using SAFA threshold: {safa_threshold}\")\n\ndf_combined[['SET', 'SAFA_PECK', 'SAFA_NECK', 'SAFA_Reason']] = df_combined.apply(\n    lambda row: pd.Series(self_adaptive_fusion(\n        row['text_raw'],\n        row['PECK'],\n        row['NECK'],\n        row['ES'],\n        row['CS_ECR'],\n        row['sentiment_label_bert'],\n        row['CS_BERT_normalized'],\n        safa_threshold\n    )),\n    axis=1\n)\n\n# ====================================================================\n# STEP 3.4: SAVE PROCESSED DATA FOR STEP 4 (BERT FEATURE REPRESENTATION)\n# ====================================================================\n\noutput_cols = [\n    'source', 'text_raw', 'text_cleaned', 'tokens', 'sentiment_label',\n    'ES', 'CS_ECR', 'PECK', 'NECK',\n    'sentiment_label_bert', 'CS_BERT', 'CS_BERT_normalized',\n    'SET', 'SAFA_PECK', 'SAFA_NECK', 'SAFA_Reason'\n]\n\nprint(\"\\n--- Sample of SAFA Processed Data ---\")\nprint(df_combined[output_cols].head())\n\ndf_combined[output_cols].to_csv('safa_processed_mental_health_data.csv', index=False)\nprint(\"\\nProcessed data with SAFA results saved to 'safa_processed_mental_health_data.csv'.\")\nprint(\"Proceed to Step 4: Knowledge-Enabled Feature Representation (Soft-Position Embedding & Mask-Transformer).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T14:35:09.175968Z","iopub.execute_input":"2025-11-04T14:35:09.176677Z","iopub.status.idle":"2025-11-04T14:36:27.560424Z","shell.execute_reply.started":"2025-11-04T14:35:09.176651Z","shell.execute_reply":"2025-11-04T14:36:27.559632Z"}},"outputs":[{"name":"stdout","text":"Loaded ECR processed data for SAFA from 'ecr_processed_mental_health_data.csv' with 151288 rows.\n\n--- Simulating BERT Sentiment Predictions ---\nCS_BERT normalized using Min-Max scaling.\n\n--- Applying Self-Adaptive Fusion Algorithm (SAFA) ---\nUsing SAFA threshold: 0.3\n\n--- Sample of SAFA Processed Data ---\n  source                                           text_raw  \\\n0   ptsd  This year felt like literal hell. It’s over no...   \n1   ptsd  Can feel my skin tightening up as I type this ...   \n2   ptsd  I shout at my animals sometimes when they do s...   \n3   ptsd  I'm really struggling with my past and it's pr...   \n4   ptsd                                   On Snapchat call   \n\n                                        text_cleaned  \\\n0  this year felt like literal hell its over now ...   \n1  can feel my skin tightening up as i type this ...   \n2  i shout at my animals sometimes when they do s...   \n3  im really struggling with my past and its prob...   \n4                                   on snapchat call   \n\n                                              tokens  sentiment_label   ES  \\\n0  [this, year, felt, like, literal, hell, its, o...                1  0.0   \n1  [can, feel, my, skin, tightening, up, as, i, t...                1  0.0   \n2  [i, shout, at, my, animals, sometimes, when, t...                1  0.0   \n3  [im, really, struggling, with, my, past, and, ...                1 -0.6   \n4                               [on, snapchat, call]                1  0.0   \n\n   CS_ECR                  PECK  \\\n0     0.0                    []   \n1     0.0       [[better, Joy]]   \n2     0.0  [[kind, Admiration]]   \n3     0.6     [[recovery, Joy]]   \n4     0.0                    []   \n\n                                                NECK  sentiment_label_bert  \\\n0                                                 []                   2.0   \n1                                [[wrong, Reproach]]                   0.0   \n2                                [[wrong, Reproach]]                   2.0   \n3  [[anxiety, Distress], [panic, Distress], [fear...                   1.0   \n4                                                 []                   1.0   \n\n    CS_BERT  CS_BERT_normalized  \\\n0  0.888788            0.740481   \n1  0.829153            0.587568   \n2  0.892006            0.748730   \n3  0.810317            0.539272   \n4  0.623765            0.060930   \n\n                                                 SET        SAFA_PECK  \\\n0  This year felt like literal hell. It’s over no...               []   \n1  Can feel my skin tightening up as I type this ...  [[better, Joy]]   \n2  I shout at my animals sometimes when they do s...               []   \n3  I'm really struggling with my past and it's pr...               []   \n4                                   On Snapchat call               []   \n\n                                           SAFA_NECK  \\\n0                                                 []   \n1                                                 []   \n2                                                 []   \n3  [[anxiety, Distress], [panic, Distress], [fear...   \n4                                                 []   \n\n                                         SAFA_Reason  \n0                                No ECK incorporated  \n1  BERT-preferred PECK (high CS_BERT, positive BERT)  \n2                                No ECK incorporated  \n3      ECR-preferred NECK (high CS_ECR, negative ES)  \n4  BERT-preferred NECK (high CS_BERT, negative BERT)  \n\nProcessed data with SAFA results saved to 'safa_processed_mental_health_data.csv'.\nProceed to Step 4: Knowledge-Enabled Feature Representation (Soft-Position Embedding & Mask-Transformer).\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom typing import List, Dict, Any, Tuple\n\n# ====================================================================\n# STEP 4.1: LOAD SAFA PROCESSED DATA FROM STEP 3\n# ====================================================================\n\ntry:\n    df_combined = pd.read_csv('safa_processed_mental_health_data.csv')\n    # Convert 'tokens', 'PECK', 'NECK', 'SAFA_PECK', 'SAFA_NECK' back from string to actual lists/objects\n    df_combined['tokens'] = df_combined['tokens'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    df_combined['PECK'] = df_combined['PECK'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    df_combined['NECK'] = df_combined['NECK'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    df_combined['SAFA_PECK'] = df_combined['SAFA_PECK'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    df_combined['SAFA_NECK'] = df_combined['SAFA_NECK'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    print(f\"Loaded SAFA processed data for BERT integration from 'safa_processed_mental_health_data.csv' with {len(df_combined)} rows.\")\nexcept FileNotFoundError:\n    print(\"Error: 'safa_processed_mental_health_data.csv' not found. Please ensure Step 3 was run successfully.\")\n    raise\n\n# ====================================================================\n# STEP 4.2: TOKENIZATION FOR SENTENCE-EMOTION TREES (SETs)\n# ====================================================================\n\n# The SETs are strings that look like: \"original text {PECK: [[token, emotion]]} {NECK: [[token, emotion]]}\"\n# We need to tokenize this in a way that BERT can process it, and also track original token positions.\n\ndef tokenize_set_for_bert(set_text: str) -> Tuple[List[str], List[int], Dict[str, List[int]]]:\n    \"\"\"\n    Tokenizes the SET text and generates conceptual soft-position embeddings.\n    It also identifies which knowledge tokens correspond to which original word.\n    \n    Returns:\n    - bert_tokens: List of tokens suitable for BERT input (e.g., ['[CLS]', 'my', 'wishes', '{', 'healthy', 'joy', '}', ...])\n    - soft_positions: List of conceptual soft-position IDs for each bert_token.\n    - knowledge_mapping: Dict showing which original word maps to which knowledge tokens' indices.\n    \"\"\"\n    bert_tokens = ['[CLS]'] # Start token for BERT\n    soft_positions = [0] # Position for [CLS]\n    original_text_part = set_text\n    \n    # Extract embedded knowledge strings using regex\n    knowledge_blocks = re.findall(r'\\{\\S+:\\s*\\[\\[.*?\\]\\]\\}|\\{\\S+:\\s*\\[\\[.*?\\]\\].*?\\[\\[.*?\\]\\]\\}', set_text)\n    \n    # Remove knowledge blocks from original_text_part to process original tokens\n    for block in knowledge_blocks:\n        original_text_part = original_text_part.replace(block, ' ')\n        \n    original_tokens = original_text_part.lower().split()\n    \n    current_pos_id = 1 # Starting position for actual words\n\n    # Process original text tokens first\n    token_to_pos_map = {} # To link original words to their soft positions\n    for token in original_tokens:\n        if token: # Ensure token is not empty\n            bert_tokens.append(token)\n            soft_positions.append(current_pos_id)\n            token_to_pos_map[token] = current_pos_id # Store the position\n            current_pos_id += 1\n            \n    # Process knowledge blocks and assign soft positions\n    # Example: {PECK: [[healthy, Joy]]}\n    # We need to parse the knowledge to link it to the word it refers to\n    \n    knowledge_mapping = {} # {'healthy': [idx_of_healthy_in_PECK, idx_of_Joy_in_PECK]}\n\n    for block in knowledge_blocks:\n        # Example block: {PECK: [[healthy, Joy]]} or {NECK: [[struggle, Distress], [anxiety, Distress]]}\n        knowledge_type_match = re.match(r'\\{(\\S+):', block)\n        knowledge_type = knowledge_type_match.group(1) if knowledge_type_match else 'UNKNOWN'\n\n        # Extract actual knowledge tuples like [healthy, Joy]\n        knowledge_tuples = re.findall(r'\\[\\[(.*?)\\]\\]', block) # Gets 'healthy, Joy'\n        \n        for tuple_str in knowledge_tuples:\n            parts = [p.strip() for p in tuple_str.split(',')]\n            if len(parts) >= 1: # At least the word is present\n                # The first part of the tuple is usually the word it refers to\n                referred_word = parts[0].lower() # e.g., 'healthy' or 'struggle'\n                \n                # If the referred word exists in the original text, use its position\n                # Otherwise, assign a new position or just append.\n                # The paper implies using the same position as the original word.\n                pos_id_for_knowledge = token_to_pos_map.get(referred_word, current_pos_id)\n\n                # Add knowledge tokens to bert_tokens and soft_positions\n                for part in parts:\n                    if part:\n                        bert_tokens.append(part.lower())\n                        soft_positions.append(pos_id_for_knowledge)\n                        # Optionally, if this is a new position, increment current_pos_id\n                        if pos_id_for_knowledge == current_pos_id:\n                            current_pos_id += 1 # Only if it was a new, unlinked knowledge.\n                \n                # Store for conceptual masked attention if needed\n                if referred_word not in knowledge_mapping:\n                    knowledge_mapping[referred_word] = []\n                # Store the range of indices for the knowledge tokens just added\n                knowledge_mapping[referred_word].extend(\n                    range(len(bert_tokens) - len(parts), len(bert_tokens))\n                )\n    \n    bert_tokens.append('[SEP]') # End token for BERT\n    soft_positions.append(current_pos_id) # Assign final position to SEP\n    \n    return bert_tokens, soft_positions, knowledge_mapping\n\nprint(\"\\n--- Generating conceptual BERT tokens and Soft-Position Embeddings for SETs ---\")\n# Apply the function to a sample to demonstrate\nsample_index = df_combined['SET'].astype(bool).idxmax() if not df_combined['SET'].empty else 0\nsample_set = df_combined.loc[sample_index, 'SET']\nsample_text_raw = df_combined.loc[sample_index, 'text_raw']\n\nif sample_set:\n    sample_bert_tokens, sample_soft_positions, sample_knowledge_map = tokenize_set_for_bert(sample_set)\n    print(f\"\\nOriginal Text Sample:\\n'{sample_text_raw}'\")\n    print(f\"\\nGenerated SET Sample:\\n'{sample_set}'\")\n    print(f\"\\nConceptual BERT Input Tokens for SET:\\n{sample_bert_tokens}\")\n    print(f\"\\nConceptual Soft-Position Embeddings:\\n{sample_soft_positions}\")\n    print(f\"\\nConceptual Knowledge Mapping (word -> knowledge token indices):\\n{sample_knowledge_map}\")\n\n    # Demonstrate position association\n    print(\"\\n--- Soft-Positioning Demonstration ---\")\n    for i in range(len(sample_bert_tokens)):\n        print(f\"Token: '{sample_bert_tokens[i]}', Soft-Position: {sample_soft_positions[i]}\")\n\nelse:\n    print(\"No non-empty SETs found to demonstrate tokenization and soft-positioning.\")\n\n\n# ====================================================================\n# STEP 4.3: CONCEPTUAL MASK-TRANSFORMER ENCODER (Discussion)\n# ====================================================================\n\nprint(\"\\n--- Conceptual Mask-Transformer Encoder (Discussion) ---\")\nprint(\"The Mask-Transformer Encoder modifies BERT's self-attention mechanism.\")\nprint(\"It uses a 'visible matrix' (Mij, as per Equation 21 in the paper) to control\")\nprint(\"which tokens can attend to which other tokens.\")\nprint(\"\\nKey Idea:\")\nprint(\"1. Original Text Tokens: Can attend to all other original text tokens.\")\nprint(\"2. Knowledge Tokens: E.g., 'Joy' from '[[healthy, Joy]]'\")\nprint(\"   - Can attend to the original word it's associated with (e.g., 'healthy').\")\nprint(\"   - Can attend to other knowledge tokens *within the same branch* (e.g., 'healthy' can attend to 'Joy').\")\nprint(\"   - Are prevented from attending to *unrelated* original text tokens or knowledge from *different branches*.\")\nprint(\"\\nThis masking prevents irrelevant knowledge from influencing the representation\")\nprint(\"of other parts of the sentence, thus mitigating knowledge noise and preserving\")\nprint(\"the original meaning while still leveraging the enhanced features.\")\nprint(\"\\nImplementing this would require modifying the attention mask within a deep learning\")\nprint(\"framework (PyTorch/TensorFlow) for a BERT-like model.\")\n\n\n# ====================================================================\n# STEP 4.4: FINAL MODEL PREDICTION (Conceptual)\n# ====================================================================\n\nprint(\"\\n--- Conceptual Final Model Prediction ---\")\nprint(\"After the SETs are processed by the knowledge-enabled BERT (with soft-positioning\")\nprint(\"and mask-transformer), the model produces a rich feature representation for each SET.\")\nprint(\"This feature representation is then passed to a linear classification layer.\")\nprint(\"The linear layer (similar to Equation 15) uses the learned features to predict\")\nprint(\"the final sentiment polarity (positive, negative, neutral) of the OPOE.\")\nprint(\"\\nAdditionally, the SAFA_PECK and SAFA_NECK components (stored in your DataFrame)\")\nprint(\"serve as explainable emotion knowledge, detailing *how* the sentiment polarity\")\nprint(\"was derived from fine-grained emotion categories.\")\n\n# For demonstration, we'll assign a final sentiment prediction based on the chosen SAFA knowledge\ndef final_sentiment_prediction_conceptual(safa_pec: List[Any], safa_nec: List[Any], bert_label: int) -> int:\n    \"\"\"\n    Conceptual final sentiment prediction.\n    In a real model, this would come from the linear classification layer\n    after BERT processes the SET.\n    Here, we'll try to reflect the SAFA decision.\n    \"\"\"\n    if safa_pec and not safa_nec:\n        return 0 # Positive (because positive knowledge was incorporated)\n    elif safa_nec and not safa_pec:\n        return 1 # Negative (because negative knowledge was incorporated)\n    elif safa_pec and safa_nec: # Mixed knowledge, or no strong signal\n        return bert_label # Fallback to BERT's initial prediction\n    else: # No knowledge incorporated\n        return bert_label # Fallback to BERT's initial prediction\n\nprint(\"\\n--- Simulating Final Sentiment Labels based on SAFA Outcome ---\")\ndf_combined['final_sentiment_predicted'] = df_combined.apply(\n    lambda row: final_sentiment_prediction_conceptual(\n        row['SAFA_PECK'], row['SAFA_NECK'], row['sentiment_label_bert']\n    ),\n    axis=1\n)\n\n# ====================================================================\n# STEP 4.5: FINAL OUTPUT PREPARATION\n# ====================================================================\n\nfinal_output_cols = [\n    'source', 'text_raw', 'sentiment_label',\n    'sentiment_label_bert', 'final_sentiment_predicted',\n    'SAFA_Reason', 'SAFA_PECK', 'SAFA_NECK', 'SET'\n]\n\nprint(\"\\n--- Final Conceptual Output Sample with Predicted Sentiment ---\")\nprint(df_combined[final_output_cols].head())\n\ndf_combined[final_output_cols].to_csv('final_ecr_bert_conceptual_results.csv', index=False)\nprint(\"\\nFinal conceptual results saved to 'final_ecr_bert_conceptual_results.csv'.\")\nprint(\"\\nThis concludes the conceptual implementation of the ECR-BERT pipeline.\")\nprint(\"To move beyond conceptual demonstration, the next stage would involve actual deep learning framework implementation.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T14:47:00.343427Z","iopub.execute_input":"2025-11-04T14:47:00.343890Z","iopub.status.idle":"2025-11-04T14:47:35.500439Z","shell.execute_reply.started":"2025-11-04T14:47:00.343865Z","shell.execute_reply":"2025-11-04T14:47:35.499552Z"}},"outputs":[{"name":"stdout","text":"Loaded SAFA processed data for BERT integration from 'safa_processed_mental_health_data.csv' with 151288 rows.\n\n--- Generating conceptual BERT tokens and Soft-Position Embeddings for SETs ---\n\nOriginal Text Sample:\n'This year felt like literal hell. It’s over now and I’m happy it is but I’m so embarrassed about how I acted. I was living in a bug infested apartment sleeping on the floor, I couldn’t wash my hair or clothes for an embarrassing amount of time because I couldn’t afford shampoo or detergent because all of my my money was being taken by a pimp who set me up to get gang raped, would take videos without me knowing which the police ended up seeing, sold me against my will and was giving me amphetamines. I had no friends because he isolated me from them and I was constantly stressed out I went fucking insane. After he was in jail I was still living there and I would cry and scream and hit myself in the head and pull my hair out. I just wanted the images out of my fucking head and the fact that the police saw videos of me and had his phone tapped so they could hear everything that traumatized me made it so much worse. It doesn’t feel fair. I know my neighbours definitely heard me I was acting fucking insane and I’m really embarrassed about everything. How do you deal with the ptsd symptoms that embarrassed you?'\n\nGenerated SET Sample:\n'This year felt like literal hell. It’s over now and I’m happy it is but I’m so embarrassed about how I acted. I was living in a bug infested apartment sleeping on the floor, I couldn’t wash my hair or clothes for an embarrassing amount of time because I couldn’t afford shampoo or detergent because all of my my money was being taken by a pimp who set me up to get gang raped, would take videos without me knowing which the police ended up seeing, sold me against my will and was giving me amphetamines. I had no friends because he isolated me from them and I was constantly stressed out I went fucking insane. After he was in jail I was still living there and I would cry and scream and hit myself in the head and pull my hair out. I just wanted the images out of my fucking head and the fact that the police saw videos of me and had his phone tapped so they could hear everything that traumatized me made it so much worse. It doesn’t feel fair. I know my neighbours definitely heard me I was acting fucking insane and I’m really embarrassed about everything. How do you deal with the ptsd symptoms that embarrassed you?'\n\nConceptual BERT Input Tokens for SET:\n['[CLS]', 'this', 'year', 'felt', 'like', 'literal', 'hell.', 'it’s', 'over', 'now', 'and', 'i’m', 'happy', 'it', 'is', 'but', 'i’m', 'so', 'embarrassed', 'about', 'how', 'i', 'acted.', 'i', 'was', 'living', 'in', 'a', 'bug', 'infested', 'apartment', 'sleeping', 'on', 'the', 'floor,', 'i', 'couldn’t', 'wash', 'my', 'hair', 'or', 'clothes', 'for', 'an', 'embarrassing', 'amount', 'of', 'time', 'because', 'i', 'couldn’t', 'afford', 'shampoo', 'or', 'detergent', 'because', 'all', 'of', 'my', 'my', 'money', 'was', 'being', 'taken', 'by', 'a', 'pimp', 'who', 'set', 'me', 'up', 'to', 'get', 'gang', 'raped,', 'would', 'take', 'videos', 'without', 'me', 'knowing', 'which', 'the', 'police', 'ended', 'up', 'seeing,', 'sold', 'me', 'against', 'my', 'will', 'and', 'was', 'giving', 'me', 'amphetamines.', 'i', 'had', 'no', 'friends', 'because', 'he', 'isolated', 'me', 'from', 'them', 'and', 'i', 'was', 'constantly', 'stressed', 'out', 'i', 'went', 'fucking', 'insane.', 'after', 'he', 'was', 'in', 'jail', 'i', 'was', 'still', 'living', 'there', 'and', 'i', 'would', 'cry', 'and', 'scream', 'and', 'hit', 'myself', 'in', 'the', 'head', 'and', 'pull', 'my', 'hair', 'out.', 'i', 'just', 'wanted', 'the', 'images', 'out', 'of', 'my', 'fucking', 'head', 'and', 'the', 'fact', 'that', 'the', 'police', 'saw', 'videos', 'of', 'me', 'and', 'had', 'his', 'phone', 'tapped', 'so', 'they', 'could', 'hear', 'everything', 'that', 'traumatized', 'me', 'made', 'it', 'so', 'much', 'worse.', 'it', 'doesn’t', 'feel', 'fair.', 'i', 'know', 'my', 'neighbours', 'definitely', 'heard', 'me', 'i', 'was', 'acting', 'fucking', 'insane', 'and', 'i’m', 'really', 'embarrassed', 'about', 'everything.', 'how', 'do', 'you', 'deal', 'with', 'the', 'ptsd', 'symptoms', 'that', 'embarrassed', 'you?', '[SEP]']\n\nConceptual Soft-Position Embeddings:\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]\n\nConceptual Knowledge Mapping (word -> knowledge token indices):\n{}\n\n--- Soft-Positioning Demonstration ---\nToken: '[CLS]', Soft-Position: 0\nToken: 'this', Soft-Position: 1\nToken: 'year', Soft-Position: 2\nToken: 'felt', Soft-Position: 3\nToken: 'like', Soft-Position: 4\nToken: 'literal', Soft-Position: 5\nToken: 'hell.', Soft-Position: 6\nToken: 'it’s', Soft-Position: 7\nToken: 'over', Soft-Position: 8\nToken: 'now', Soft-Position: 9\nToken: 'and', Soft-Position: 10\nToken: 'i’m', Soft-Position: 11\nToken: 'happy', Soft-Position: 12\nToken: 'it', Soft-Position: 13\nToken: 'is', Soft-Position: 14\nToken: 'but', Soft-Position: 15\nToken: 'i’m', Soft-Position: 16\nToken: 'so', Soft-Position: 17\nToken: 'embarrassed', Soft-Position: 18\nToken: 'about', Soft-Position: 19\nToken: 'how', Soft-Position: 20\nToken: 'i', Soft-Position: 21\nToken: 'acted.', Soft-Position: 22\nToken: 'i', Soft-Position: 23\nToken: 'was', Soft-Position: 24\nToken: 'living', Soft-Position: 25\nToken: 'in', Soft-Position: 26\nToken: 'a', Soft-Position: 27\nToken: 'bug', Soft-Position: 28\nToken: 'infested', Soft-Position: 29\nToken: 'apartment', Soft-Position: 30\nToken: 'sleeping', Soft-Position: 31\nToken: 'on', Soft-Position: 32\nToken: 'the', Soft-Position: 33\nToken: 'floor,', Soft-Position: 34\nToken: 'i', Soft-Position: 35\nToken: 'couldn’t', Soft-Position: 36\nToken: 'wash', Soft-Position: 37\nToken: 'my', Soft-Position: 38\nToken: 'hair', Soft-Position: 39\nToken: 'or', Soft-Position: 40\nToken: 'clothes', Soft-Position: 41\nToken: 'for', Soft-Position: 42\nToken: 'an', Soft-Position: 43\nToken: 'embarrassing', Soft-Position: 44\nToken: 'amount', Soft-Position: 45\nToken: 'of', Soft-Position: 46\nToken: 'time', Soft-Position: 47\nToken: 'because', Soft-Position: 48\nToken: 'i', Soft-Position: 49\nToken: 'couldn’t', Soft-Position: 50\nToken: 'afford', Soft-Position: 51\nToken: 'shampoo', Soft-Position: 52\nToken: 'or', Soft-Position: 53\nToken: 'detergent', Soft-Position: 54\nToken: 'because', Soft-Position: 55\nToken: 'all', Soft-Position: 56\nToken: 'of', Soft-Position: 57\nToken: 'my', Soft-Position: 58\nToken: 'my', Soft-Position: 59\nToken: 'money', Soft-Position: 60\nToken: 'was', Soft-Position: 61\nToken: 'being', Soft-Position: 62\nToken: 'taken', Soft-Position: 63\nToken: 'by', Soft-Position: 64\nToken: 'a', Soft-Position: 65\nToken: 'pimp', Soft-Position: 66\nToken: 'who', Soft-Position: 67\nToken: 'set', Soft-Position: 68\nToken: 'me', Soft-Position: 69\nToken: 'up', Soft-Position: 70\nToken: 'to', Soft-Position: 71\nToken: 'get', Soft-Position: 72\nToken: 'gang', Soft-Position: 73\nToken: 'raped,', Soft-Position: 74\nToken: 'would', Soft-Position: 75\nToken: 'take', Soft-Position: 76\nToken: 'videos', Soft-Position: 77\nToken: 'without', Soft-Position: 78\nToken: 'me', Soft-Position: 79\nToken: 'knowing', Soft-Position: 80\nToken: 'which', Soft-Position: 81\nToken: 'the', Soft-Position: 82\nToken: 'police', Soft-Position: 83\nToken: 'ended', Soft-Position: 84\nToken: 'up', Soft-Position: 85\nToken: 'seeing,', Soft-Position: 86\nToken: 'sold', Soft-Position: 87\nToken: 'me', Soft-Position: 88\nToken: 'against', Soft-Position: 89\nToken: 'my', Soft-Position: 90\nToken: 'will', Soft-Position: 91\nToken: 'and', Soft-Position: 92\nToken: 'was', Soft-Position: 93\nToken: 'giving', Soft-Position: 94\nToken: 'me', Soft-Position: 95\nToken: 'amphetamines.', Soft-Position: 96\nToken: 'i', Soft-Position: 97\nToken: 'had', Soft-Position: 98\nToken: 'no', Soft-Position: 99\nToken: 'friends', Soft-Position: 100\nToken: 'because', Soft-Position: 101\nToken: 'he', Soft-Position: 102\nToken: 'isolated', Soft-Position: 103\nToken: 'me', Soft-Position: 104\nToken: 'from', Soft-Position: 105\nToken: 'them', Soft-Position: 106\nToken: 'and', Soft-Position: 107\nToken: 'i', Soft-Position: 108\nToken: 'was', Soft-Position: 109\nToken: 'constantly', Soft-Position: 110\nToken: 'stressed', Soft-Position: 111\nToken: 'out', Soft-Position: 112\nToken: 'i', Soft-Position: 113\nToken: 'went', Soft-Position: 114\nToken: 'fucking', Soft-Position: 115\nToken: 'insane.', Soft-Position: 116\nToken: 'after', Soft-Position: 117\nToken: 'he', Soft-Position: 118\nToken: 'was', Soft-Position: 119\nToken: 'in', Soft-Position: 120\nToken: 'jail', Soft-Position: 121\nToken: 'i', Soft-Position: 122\nToken: 'was', Soft-Position: 123\nToken: 'still', Soft-Position: 124\nToken: 'living', Soft-Position: 125\nToken: 'there', Soft-Position: 126\nToken: 'and', Soft-Position: 127\nToken: 'i', Soft-Position: 128\nToken: 'would', Soft-Position: 129\nToken: 'cry', Soft-Position: 130\nToken: 'and', Soft-Position: 131\nToken: 'scream', Soft-Position: 132\nToken: 'and', Soft-Position: 133\nToken: 'hit', Soft-Position: 134\nToken: 'myself', Soft-Position: 135\nToken: 'in', Soft-Position: 136\nToken: 'the', Soft-Position: 137\nToken: 'head', Soft-Position: 138\nToken: 'and', Soft-Position: 139\nToken: 'pull', Soft-Position: 140\nToken: 'my', Soft-Position: 141\nToken: 'hair', Soft-Position: 142\nToken: 'out.', Soft-Position: 143\nToken: 'i', Soft-Position: 144\nToken: 'just', Soft-Position: 145\nToken: 'wanted', Soft-Position: 146\nToken: 'the', Soft-Position: 147\nToken: 'images', Soft-Position: 148\nToken: 'out', Soft-Position: 149\nToken: 'of', Soft-Position: 150\nToken: 'my', Soft-Position: 151\nToken: 'fucking', Soft-Position: 152\nToken: 'head', Soft-Position: 153\nToken: 'and', Soft-Position: 154\nToken: 'the', Soft-Position: 155\nToken: 'fact', Soft-Position: 156\nToken: 'that', Soft-Position: 157\nToken: 'the', Soft-Position: 158\nToken: 'police', Soft-Position: 159\nToken: 'saw', Soft-Position: 160\nToken: 'videos', Soft-Position: 161\nToken: 'of', Soft-Position: 162\nToken: 'me', Soft-Position: 163\nToken: 'and', Soft-Position: 164\nToken: 'had', Soft-Position: 165\nToken: 'his', Soft-Position: 166\nToken: 'phone', Soft-Position: 167\nToken: 'tapped', Soft-Position: 168\nToken: 'so', Soft-Position: 169\nToken: 'they', Soft-Position: 170\nToken: 'could', Soft-Position: 171\nToken: 'hear', Soft-Position: 172\nToken: 'everything', Soft-Position: 173\nToken: 'that', Soft-Position: 174\nToken: 'traumatized', Soft-Position: 175\nToken: 'me', Soft-Position: 176\nToken: 'made', Soft-Position: 177\nToken: 'it', Soft-Position: 178\nToken: 'so', Soft-Position: 179\nToken: 'much', Soft-Position: 180\nToken: 'worse.', Soft-Position: 181\nToken: 'it', Soft-Position: 182\nToken: 'doesn’t', Soft-Position: 183\nToken: 'feel', Soft-Position: 184\nToken: 'fair.', Soft-Position: 185\nToken: 'i', Soft-Position: 186\nToken: 'know', Soft-Position: 187\nToken: 'my', Soft-Position: 188\nToken: 'neighbours', Soft-Position: 189\nToken: 'definitely', Soft-Position: 190\nToken: 'heard', Soft-Position: 191\nToken: 'me', Soft-Position: 192\nToken: 'i', Soft-Position: 193\nToken: 'was', Soft-Position: 194\nToken: 'acting', Soft-Position: 195\nToken: 'fucking', Soft-Position: 196\nToken: 'insane', Soft-Position: 197\nToken: 'and', Soft-Position: 198\nToken: 'i’m', Soft-Position: 199\nToken: 'really', Soft-Position: 200\nToken: 'embarrassed', Soft-Position: 201\nToken: 'about', Soft-Position: 202\nToken: 'everything.', Soft-Position: 203\nToken: 'how', Soft-Position: 204\nToken: 'do', Soft-Position: 205\nToken: 'you', Soft-Position: 206\nToken: 'deal', Soft-Position: 207\nToken: 'with', Soft-Position: 208\nToken: 'the', Soft-Position: 209\nToken: 'ptsd', Soft-Position: 210\nToken: 'symptoms', Soft-Position: 211\nToken: 'that', Soft-Position: 212\nToken: 'embarrassed', Soft-Position: 213\nToken: 'you?', Soft-Position: 214\nToken: '[SEP]', Soft-Position: 215\n\n--- Conceptual Mask-Transformer Encoder (Discussion) ---\nThe Mask-Transformer Encoder modifies BERT's self-attention mechanism.\nIt uses a 'visible matrix' (Mij, as per Equation 21 in the paper) to control\nwhich tokens can attend to which other tokens.\n\nKey Idea:\n1. Original Text Tokens: Can attend to all other original text tokens.\n2. Knowledge Tokens: E.g., 'Joy' from '[[healthy, Joy]]'\n   - Can attend to the original word it's associated with (e.g., 'healthy').\n   - Can attend to other knowledge tokens *within the same branch* (e.g., 'healthy' can attend to 'Joy').\n   - Are prevented from attending to *unrelated* original text tokens or knowledge from *different branches*.\n\nThis masking prevents irrelevant knowledge from influencing the representation\nof other parts of the sentence, thus mitigating knowledge noise and preserving\nthe original meaning while still leveraging the enhanced features.\n\nImplementing this would require modifying the attention mask within a deep learning\nframework (PyTorch/TensorFlow) for a BERT-like model.\n\n--- Conceptual Final Model Prediction ---\nAfter the SETs are processed by the knowledge-enabled BERT (with soft-positioning\nand mask-transformer), the model produces a rich feature representation for each SET.\nThis feature representation is then passed to a linear classification layer.\nThe linear layer (similar to Equation 15) uses the learned features to predict\nthe final sentiment polarity (positive, negative, neutral) of the OPOE.\n\nAdditionally, the SAFA_PECK and SAFA_NECK components (stored in your DataFrame)\nserve as explainable emotion knowledge, detailing *how* the sentiment polarity\nwas derived from fine-grained emotion categories.\n\n--- Simulating Final Sentiment Labels based on SAFA Outcome ---\n\n--- Final Conceptual Output Sample with Predicted Sentiment ---\n  source                                           text_raw  sentiment_label  \\\n0   ptsd  This year felt like literal hell. It’s over no...                1   \n1   ptsd  Can feel my skin tightening up as I type this ...                1   \n2   ptsd  I shout at my animals sometimes when they do s...                1   \n3   ptsd  I'm really struggling with my past and it's pr...                1   \n4   ptsd                                   On Snapchat call                1   \n\n   sentiment_label_bert  final_sentiment_predicted  \\\n0                   2.0                        2.0   \n1                   0.0                        0.0   \n2                   2.0                        2.0   \n3                   1.0                        1.0   \n4                   1.0                        1.0   \n\n                                         SAFA_Reason        SAFA_PECK  \\\n0                                No ECK incorporated               []   \n1  BERT-preferred PECK (high CS_BERT, positive BERT)  [[better, Joy]]   \n2                                No ECK incorporated               []   \n3      ECR-preferred NECK (high CS_ECR, negative ES)               []   \n4  BERT-preferred NECK (high CS_BERT, negative BERT)               []   \n\n                                           SAFA_NECK  \\\n0                                                 []   \n1                                                 []   \n2                                                 []   \n3  [[anxiety, Distress], [panic, Distress], [fear...   \n4                                                 []   \n\n                                                 SET  \n0  This year felt like literal hell. It’s over no...  \n1  Can feel my skin tightening up as I type this ...  \n2  I shout at my animals sometimes when they do s...  \n3  I'm really struggling with my past and it's pr...  \n4                                   On Snapchat call  \n\nFinal conceptual results saved to 'final_ecr_bert_conceptual_results.csv'.\n\nThis concludes the conceptual implementation of the ECR-BERT pipeline.\nTo move beyond conceptual demonstration, the next stage would involve actual deep learning framework implementation.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom typing import List, Dict, Any, Tuple\n\n# ====================================================================\n# STEP 5.1: LOAD FINAL CONCEPTUAL RESULTS\n# ====================================================================\n\ntry:\n    df_results = pd.read_csv('final_ecr_bert_conceptual_results.csv')\n    # Convert lists back from string representation\n    df_results['SAFA_PECK'] = df_results['SAFA_PECK'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    df_results['SAFA_NECK'] = df_results['SAFA_NECK'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n    print(f\"Loaded final conceptual results for analysis from 'final_ecr_bert_conceptual_results.csv' with {len(df_results)} rows.\")\nexcept FileNotFoundError:\n    print(\"Error: 'final_ecr_bert_conceptual_results.csv' not found. Please ensure Step 4 was run successfully.\")\n    raise\n\n# ====================================================================\n# STEP 5.2: QUALITATIVE ANALYSIS (Inspired by Table 6 in the paper)\n# ====================================================================\n\nprint(\"\\n--- QUALITATIVE ANALYSIS: Inferred Emotions and Sentiment Explanations ---\")\nprint(\"Comparing original text, SAFA's chosen knowledge, and final predicted sentiment.\")\nprint(\"The goal is to see how the SAFA_PECK/NECK provide an explanation for the sentiment.\")\n\n# Select a few diverse samples for qualitative review\n# Try to pick samples where SAFA actually incorporated some knowledge.\nsample_df = df_results[df_results['SAFA_PECK'].apply(bool) | df_results['SAFA_NECK'].apply(bool)].sample(n=5, random_state=42)\n\n# If no samples with incorporated knowledge, pick random ones\nif sample_df.empty:\n    print(\"\\nWarning: No samples found with incorporated PECK/NECK. Displaying general samples.\")\n    sample_df = df_results.sample(n=5, random_state=42)\n\n# Sentiment mapping for readability\nsentiment_map = {0: 'Positive', 1: 'Negative', 2: 'Neutral (Simulated)'}\n\nfor index, row in sample_df.iterrows():\n    print(f\"\\n----- Sample {index} (Source: {row['source'].upper()}) -----\")\n    print(f\"Original Post: {row['text_raw'][:200]}...\") # Truncate long posts\n    print(f\"Initial Sentiment Label (Default Negative): {sentiment_map[row['sentiment_label']]}\")\n    print(f\"Simulated BERT-only Prediction: {sentiment_map[row['sentiment_label_bert']]}\")\n    print(f\"Final ECR-BERT Conceptual Prediction: {sentiment_map[row['final_sentiment_predicted']]}\")\n    print(f\"SAFA Reason: {row['SAFA_Reason']}\")\n    if row['SAFA_PECK']:\n        print(f\"  Inferred Positive Knowledge (PECK): {row['SAFA_PECK']}\")\n    if row['SAFA_NECK']:\n        print(f\"  Inferred Negative Knowledge (NECK): {row['SAFA_NECK']}\")\n    print(f\"SET (Input to conceptual BERT): {row['SET'][:200]}...\") # Truncate for display\n\n# Discussion on consistency\nprint(\"\\n--- Qualitative Analysis Discussion ---\")\nprint(\"Observations from samples:\")\nprint(\"1. The 'SAFA_PECK' and 'SAFA_NECK' provide clear, fine-grained emotional categories.\")\nprint(\"2. The 'SAFA_Reason' explains *why* a particular type of knowledge was chosen for incorporation.\")\nprint(\"3. In cases where PECK or NECK were incorporated, the 'final_sentiment_predicted' often aligns\")\nprint(\"   with the polarity of the incorporated knowledge, demonstrating explainability.\")\nprint(\"4. Discrepancies between 'sentiment_label_bert' and 'final_sentiment_predicted' (when they occur)\")\nprint(\"   highlight SAFA's role in refining sentiment based on ECR insights.\")\nprint(\"   (Note: Our simulation might not produce strong discrepancies without specific rules for `simulate_bert_prediction`).\")\nprint(\"5. Cases with no SAFA_PECK/NECK mean either no emotion words were detected by ECR, or SAFA\")\nprint(\"   decided not to incorporate knowledge (e.g., low CS_ECR, BERT neutral, or mixed/conflicting ES).\")\nprint(\"   In these cases, the final prediction defaults to the BERT-only prediction.\")\n\n\n# ====================================================================\n# STEP 5.3: CONCEPTUAL ABLATION STUDY (Discussion)\n# ====================================================================\n\nprint(\"\\n--- CONCEPTUAL ABLATION STUDY (Discussion) ---\")\nprint(\"An ablation study systematically removes components of a model to understand their individual contribution.\")\nprint(\"Based on the paper's Fig. 9 and our conceptual implementation, here's what we would expect:\")\n\nprint(\"\\n**1. Baseline (B - BERT only):**\")\nprint(\"   - This would be equivalent to our `sentiment_label_bert` (the simulated BERT prediction).\")\nprint(\"   - It provides a strong baseline, leveraging BERT's pre-trained language understanding.\")\nprint(\"   - Lacks explainability in terms of fine-grained emotions.\")\n\nprint(\"\\n**2. BERT + ECR (B, E):**\")\nprint(\"   - Here, ECR-derived knowledge (PECK/NECK) would be *always* incorporated into BERT's input (SETs), without SAFA.\")\nprint(\"   - This would likely show some improvement over BERT only, as auxiliary knowledge helps.\")\nprint(\"   - However, without SAFA, it would suffer from 'knowledge noise' (incorporating conflicting or irrelevant knowledge), potentially leading to less optimal performance than the full model.\")\n\nprint(\"\\n**3. BERT + ECR + Knowledge-Enabled Feature Representation (B, E, K):**\")\nprint(\"   - This adds Soft-Position Embedding and Mask-Transformer to (B, E).\")\nprint(\"   - The paper shows this improves performance over (B, E) because the specialized feature representation better handles the SET structure and reduces noise during processing.\")\nprint(\"   - It helps BERT *understand* the tree-like structure of the SETs more effectively.\")\n\nprint(\"\\n**4. BERT + ECR + Self-Adaptive Fusion (B, E, S):**\")\nprint(\"   - This combines BERT, ECR, and the SAFA, but without the Knowledge-Enabled Feature Representation (soft-positioning/mask-transformer).\")\nprint(\"   - SAFA's selective incorporation *reduces knowledge noise* by choosing relevant knowledge based on confidence.\")\nprint(\"   - We would expect this to outperform (B, E) due to improved knowledge quality, but likely be slightly worse than (B, E, K) because the vanilla BERT might still struggle with the complex SET structure without specialized embeddings/attention.\")\n\nprint(\"\\n**5. ECR-BERT (B, E, S, K - Our Proposed Model):**\")\nprint(\"   - This is the full model, combining BERT, ECR, Self-Adaptive Fusion, and Knowledge-Enabled Feature Representation.\")\nprint(\"   - The paper's results (and our expectation) show this achieves the best performance.\")\nprint(\"   - It leverages the power of BERT, the explainability and insights from ECR, the noise reduction from SAFA, and the structural understanding from knowledge-enabled feature representation.\")\nprint(\"   - It provides both accurate *and* explainable sentiment analysis results for OPOEs (and in your case, mental health discussions).\")\n\nprint(\"\\n**Conclusion from Ablation:**\")\nprint(\"Each component (ECR for knowledge, SAFA for selective fusion, and Knowledge-Enabled Feature Representation for structural understanding) plays a crucial role in enhancing the accuracy and explainability of the ECR-BERT model.\")\n\nprint(\"\\n--- END OF CONCEPTUAL IMPLEMENTATION ---\")\nprint(\"To fully implement this ECR-BERT model, you would need to:\")\nprint(\"1. Train actual BERT models for sentiment prediction (replacing `simulate_bert_prediction`).\")\nprint(\"2. Implement the Soft-Position Embedding and Mask-Transformer within a deep learning framework (e.g., PyTorch, TensorFlow).\")\nprint(\"3. Train the full ECR-BERT model end-to-end on your dataset.\")\nprint(\"4. Conduct thorough quantitative evaluations (accuracy, F1) and fine-tune hyperparameters (like SAFA threshold).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T14:48:44.677756Z","iopub.execute_input":"2025-11-04T14:48:44.678389Z","iopub.status.idle":"2025-11-04T14:48:49.063578Z","shell.execute_reply.started":"2025-11-04T14:48:44.678365Z","shell.execute_reply":"2025-11-04T14:48:49.062818Z"}},"outputs":[{"name":"stdout","text":"Loaded final conceptual results for analysis from 'final_ecr_bert_conceptual_results.csv' with 151288 rows.\n\n--- QUALITATIVE ANALYSIS: Inferred Emotions and Sentiment Explanations ---\nComparing original text, SAFA's chosen knowledge, and final predicted sentiment.\nThe goal is to see how the SAFA_PECK/NECK provide an explanation for the sentiment.\n\n----- Sample 122201 (Source: OCD) -----\nOriginal Post: Hey guys, \n\nSo lately my intrusive thoughts have been really bad and much worse. I’d also like to note that I frequently experience depersonalization/de-realization. Lately my thoughts are trying to c...\nInitial Sentiment Label (Default Negative): Negative\nSimulated BERT-only Prediction: Negative\nFinal ECR-BERT Conceptual Prediction: Negative\nSAFA Reason: ECR-preferred NECK (high CS_ECR, negative ES)\n  Inferred Negative Knowledge (NECK): [['panic', 'Distress'], ['anxiety', 'Distress']]\nSET (Input to conceptual BERT): Hey guys, \n\nSo lately my intrusive thoughts have been really bad and much worse. I’d also like to note that I frequently experience depersonalization/de-realization. Lately my thoughts are trying to c...\n\n----- Sample 1275 (Source: PTSD) -----\nOriginal Post: So it's been 3 months since I had a traumatic event for me. I see ppl here with horrid experiences and can't help it but to constantly think about how insignificant mine was. I couldn't have sex with ...\nInitial Sentiment Label (Default Negative): Negative\nSimulated BERT-only Prediction: Negative\nFinal ECR-BERT Conceptual Prediction: Negative\nSAFA Reason: BERT-preferred NECK (high CS_BERT, negative BERT)\n  Inferred Negative Knowledge (NECK): [['anxiety', 'working', 'Fear-Confirmed']]\nSET (Input to conceptual BERT): So it's been 3 months since I had a traumatic event for me. I see ppl here with horrid experiences and can't help it but to constantly think about how insignificant mine was. I couldn't have sex with ...\n\n----- Sample 5344 (Source: PTSD) -----\nOriginal Post: But I think it made symptoms worse. I think I'm making my life even worse. I can't even read things like envision what you want. Because what I want are things that I only think of when I'm in a traum...\nInitial Sentiment Label (Default Negative): Negative\nSimulated BERT-only Prediction: Positive\nFinal ECR-BERT Conceptual Prediction: Positive\nSAFA Reason: BERT-preferred PECK (high CS_BERT, positive BERT)\n  Inferred Positive Knowledge (PECK): [['calm', 'Joy']]\nSET (Input to conceptual BERT): But I think it made symptoms worse. I think I'm making my life even worse. I can't even read things like envision what you want. Because what I want are things that I only think of when I'm in a traum...\n\n----- Sample 148116 (Source: DEPRESSION) -----\nOriginal Post: M(30), health anxiety, OCD, depression, SAD, ADHD. \n\nA bit of background: I’m currently having a lot of health anxiety. I’ve had this for a few years and my latest bout is sending me down the “I’m goi...\nInitial Sentiment Label (Default Negative): Negative\nSimulated BERT-only Prediction: Negative\nFinal ECR-BERT Conceptual Prediction: Negative\nSAFA Reason: ECR-preferred NECK (high CS_ECR, negative ES)\n  Inferred Negative Knowledge (NECK): [['anxiety', 'Distress']]\nSET (Input to conceptual BERT): M(30), health anxiety, OCD, depression, SAD, ADHD. \n\nA bit of background: I’m currently having a lot of health anxiety. I’ve had this for a few years and my latest bout is sending me down the “I’m goi...\n\n----- Sample 143352 (Source: DEPRESSION) -----\nOriginal Post: I am tired. i am tired of trying to be better when nobody seems to notice at all and continues to make me feel stupid. All my life all I've ever done is try to make everyone see I am not just a body o...\nInitial Sentiment Label (Default Negative): Negative\nSimulated BERT-only Prediction: Positive\nFinal ECR-BERT Conceptual Prediction: Positive\nSAFA Reason: ECR-preferred PECK (high CS_ECR, positive ES)\n  Inferred Positive Knowledge (PECK): [['better', 'trying', 'Gratitude/Pride'], ['accepting', 'Joy']]\nSET (Input to conceptual BERT): I am tired. i am tired of trying to be better when nobody seems to notice at all and continues to make me feel stupid. All my life all I've ever done is try to make everyone see I am not just a body o...\n\n--- Qualitative Analysis Discussion ---\nObservations from samples:\n1. The 'SAFA_PECK' and 'SAFA_NECK' provide clear, fine-grained emotional categories.\n2. The 'SAFA_Reason' explains *why* a particular type of knowledge was chosen for incorporation.\n3. In cases where PECK or NECK were incorporated, the 'final_sentiment_predicted' often aligns\n   with the polarity of the incorporated knowledge, demonstrating explainability.\n4. Discrepancies between 'sentiment_label_bert' and 'final_sentiment_predicted' (when they occur)\n   highlight SAFA's role in refining sentiment based on ECR insights.\n   (Note: Our simulation might not produce strong discrepancies without specific rules for `simulate_bert_prediction`).\n5. Cases with no SAFA_PECK/NECK mean either no emotion words were detected by ECR, or SAFA\n   decided not to incorporate knowledge (e.g., low CS_ECR, BERT neutral, or mixed/conflicting ES).\n   In these cases, the final prediction defaults to the BERT-only prediction.\n\n--- CONCEPTUAL ABLATION STUDY (Discussion) ---\nAn ablation study systematically removes components of a model to understand their individual contribution.\nBased on the paper's Fig. 9 and our conceptual implementation, here's what we would expect:\n\n**1. Baseline (B - BERT only):**\n   - This would be equivalent to our `sentiment_label_bert` (the simulated BERT prediction).\n   - It provides a strong baseline, leveraging BERT's pre-trained language understanding.\n   - Lacks explainability in terms of fine-grained emotions.\n\n**2. BERT + ECR (B, E):**\n   - Here, ECR-derived knowledge (PECK/NECK) would be *always* incorporated into BERT's input (SETs), without SAFA.\n   - This would likely show some improvement over BERT only, as auxiliary knowledge helps.\n   - However, without SAFA, it would suffer from 'knowledge noise' (incorporating conflicting or irrelevant knowledge), potentially leading to less optimal performance than the full model.\n\n**3. BERT + ECR + Knowledge-Enabled Feature Representation (B, E, K):**\n   - This adds Soft-Position Embedding and Mask-Transformer to (B, E).\n   - The paper shows this improves performance over (B, E) because the specialized feature representation better handles the SET structure and reduces noise during processing.\n   - It helps BERT *understand* the tree-like structure of the SETs more effectively.\n\n**4. BERT + ECR + Self-Adaptive Fusion (B, E, S):**\n   - This combines BERT, ECR, and the SAFA, but without the Knowledge-Enabled Feature Representation (soft-positioning/mask-transformer).\n   - SAFA's selective incorporation *reduces knowledge noise* by choosing relevant knowledge based on confidence.\n   - We would expect this to outperform (B, E) due to improved knowledge quality, but likely be slightly worse than (B, E, K) because the vanilla BERT might still struggle with the complex SET structure without specialized embeddings/attention.\n\n**5. ECR-BERT (B, E, S, K - Our Proposed Model):**\n   - This is the full model, combining BERT, ECR, Self-Adaptive Fusion, and Knowledge-Enabled Feature Representation.\n   - The paper's results (and our expectation) show this achieves the best performance.\n   - It leverages the power of BERT, the explainability and insights from ECR, the noise reduction from SAFA, and the structural understanding from knowledge-enabled feature representation.\n   - It provides both accurate *and* explainable sentiment analysis results for OPOEs (and in your case, mental health discussions).\n\n**Conclusion from Ablation:**\nEach component (ECR for knowledge, SAFA for selective fusion, and Knowledge-Enabled Feature Representation for structural understanding) plays a crucial role in enhancing the accuracy and explainability of the ECR-BERT model.\n\n--- END OF CONCEPTUAL IMPLEMENTATION ---\nTo fully implement this ECR-BERT model, you would need to:\n1. Train actual BERT models for sentiment prediction (replacing `simulate_bert_prediction`).\n2. Implement the Soft-Position Embedding and Mask-Transformer within a deep learning framework (e.g., PyTorch, TensorFlow).\n3. Train the full ECR-BERT model end-to-end on your dataset.\n4. Conduct thorough quantitative evaluations (accuracy, F1) and fine-tune hyperparameters (like SAFA threshold).\n","output_type":"stream"}],"execution_count":7}]}